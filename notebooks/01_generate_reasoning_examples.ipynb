{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d17ceba-ea86-418b-8cbb-ce4e60925cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: together in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.3.14)\n",
      "Requirement already satisfied: litellm in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.43.9)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.10.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (1.26.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (4.66.5)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.12.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (7.2.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.40.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.40.6)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.20.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.7.24)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tokenizers->litellm) (0.24.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->litellm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.40.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install together litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cd5ea4-214d-4186-8e3e-14f2d300f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Formatting Scorer Class with Tests\n",
    "import re\n",
    "\n",
    "class FormatScorer:\n",
    "    \"\"\"\n",
    "    A simple scoring class that verifies whether the given text contains\n",
    "    the required tags: <think>, </think>, <answer>, and </answer>.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Pre-compile regex patterns for faster matching.\n",
    "        self.tag_pattern = re.compile(r'(<think>|</think>|<answer>|</answer>)')\n",
    "        \n",
    "    def score(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns 1 if the text contains both <think>...</think> and \n",
    "        <answer>...</answer> tags; otherwise returns 0.\n",
    "        \"\"\"\n",
    "        # Extract all tags in the order they appear\n",
    "        tags = self.tag_pattern.findall(text)\n",
    "        # Define the required exact sequence of tags\n",
    "        required_sequence = ['<think>', '</think>', '<answer>', '</answer>']\n",
    "        # Check if the extracted tags match the required sequence exactly\n",
    "        return 1 if tags == required_sequence else 0\n",
    "\n",
    "# --- Tests for the FormatScorer class ---\n",
    "\n",
    "def run_tests():\n",
    "    scorer = FormatScorer()\n",
    "    \n",
    "    # Test 1: No tags at all should return 0.\n",
    "    text1 = \"Hello, world!\"\n",
    "    assert scorer.score(text1) == 0, \"Test case 1 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 2: Only <think> tags are present.\n",
    "    text2 = \"<think>This is a thought</think> Some text without answer tags.\"\n",
    "    assert scorer.score(text2) == 0, \"Test case 2 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 3: Both <think> and <answer> tags are present.\n",
    "    text3 = \"<think>This is a thought</think><answer>This is an answer</answer>\"\n",
    "    assert scorer.score(text3) == 1, \"Test case 3 failed: expected score 1.\"\n",
    "    \n",
    "    # Test 4: Malformed text (missing closing tag for <answer>).\n",
    "    text4 = \"<think>This is a thought</think><answer>This is an answer\"\n",
    "    assert scorer.score(text4) == 0, \"Test case 4 failed: expected score 0.\"\n",
    "    \n",
    "    print(\"All tests passed.\")\n",
    "\n",
    "# Run the tests:\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102caf32-4e64-4629-8946-812dc193af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Joke:\n",
      " <think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
      "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\n"
     ]
    }
   ],
   "source": [
    "# Joke Generator\n",
    "import litellm\n",
    "\n",
    "class JokeGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the JokeGenerator with a specific model name and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(prompt: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "<think>I want to create anatomy humor. Skeletons are inherently funny because they're literal \"bare bones.\" What do they lack? Flesh/organs. \"Guts\" has a double meaning - both literal organs and figurative courage. This sets up a pun opportunity.</think>\n",
    "<answer>Why don't skeletons fight each other? They don't have the guts!</answer>\n",
    "\n",
    "Example 2:\n",
    "<think>Tech support jokes work well with personification. \"Doctor\" visits imply sickness. Common computer issues include viruses. Let's combine these - a computer catching a \"virus\" works literally (tech) and metaphorically (biology). Adds irony since computers are supposed to fix problems, not have them.</think>\n",
    "<answer>Why did the computer go to the doctor? It had a virus!</answer>\n",
    "\n",
    "Example 3:\n",
    "<think>Science humor opportunity. Atoms are fundamental but abstract. \"Make up everything\" has dual meaning - literal composition vs deception. Personifying atoms as untrustworthy creates surprise. Bonus science nod to their constant motion/making bonds.</think>\n",
    "<answer>Why don't scientists trust atoms? Because they make up everything!</answer>\"\"\"\n",
    "        return f\"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\n",
    "Here are some examples of jokes:\n",
    "<examples>\n",
    "{examples}\n",
    "</examples>\n",
    "\n",
    "Now, produce a joke for the following prompt:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\"\"\"\n",
    "\n",
    "    def generate_joke(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a joke for the given prompt using litellm.completion.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(prompt)\n",
    "        \n",
    "        # Build completion parameters as desired\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # timeout in seconds\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            joke = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            joke = response\n",
    "        return joke\n",
    "\n",
    "\n",
    "# Create an instance using a model name\n",
    "generator = JokeGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "# Define a sample prompt to generate a joke.\n",
    "sample_prompt = \"Tell me a joke about programming.\"\n",
    "\n",
    "# Generate a joke.\n",
    "joke_output = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "# generator.generate_joke(sample_prompt)\n",
    "print(\"Generated Joke:\\n\", joke_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3b9693-aa9c-4c80-94ac-967d850b1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis:\n",
      " <think>\n",
      "This whistleblowing dilemma involves:\n",
      "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
      "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
      "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
      "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
      "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
      "\n",
      "Analyzing through multiple frameworks:\n",
      "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
      "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
      "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
      "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
      "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
      "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
      "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
      "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
      "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
      "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
      "\n",
      "Implementation Steps:\n",
      "1. **Immediate Action**: Document evidence and seek legal advice.\n",
      "2. **Internal Reporting**: If safe and feasible, report internally.\n",
      "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
      "4. **Support Network**: Build a support system for emotional and professional support.\n",
      "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
      "\n",
      "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Response Generator\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize with model name and temperature (lower default for more focused analysis)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(scenario: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "A self-driving car must choose between hitting an elderly pedestrian or swerving into a wall, endangering its passenger.\n",
    "<think>\n",
    "The self-driving car dilemma involves:\n",
    "- Life value comparison (elderly vs passenger)\n",
    "- Programmed ethics implications\n",
    "- Legal liability considerations\n",
    "- Cultural values around age\n",
    "- Public trust in AI systems\n",
    "- Direct vs indirect harm\n",
    "Analyzing through multiple frameworks to balance competing rights and consequences.\n",
    "</think>\n",
    "<answer>\n",
    "In this self-driving car scenario, we must balance individual rights with collective safety. While utilitarian calculations might favor protecting the passenger, this ignores fundamental human rights and could erode public trust in autonomous systems. A nuanced approach would:\n",
    "1. Prioritize collision avoidance systems to prevent such binary choices\n",
    "2. Implement transparent decision frameworks that respect all human life equally\n",
    "3. Consider shared responsibility between manufacturers, users, and society\n",
    "The solution lies not in choosing between lives, but in developing systems that better protect everyone.\n",
    "</answer>\n",
    "\n",
    "Example 2:\n",
    "A hospital must decide between allocating limited resources to emergency COVID care for elderly patients or vaccination programs for children.\n",
    "<think>\n",
    "Vaccination prioritization involves:\n",
    "- Present vs future harm prevention\n",
    "- Individual vs collective good\n",
    "- Healthcare resource allocation\n",
    "- Demographic impact analysis\n",
    "- Long-term public health strategy\n",
    "- Social trust maintenance\n",
    "Examining both immediate and long-term consequences while considering equity.\n",
    "</think>\n",
    "<answer>\n",
    "The hospital's resource allocation challenge requires balancing immediate critical care with preventive measures. While treating current patients has urgency and visibility, vaccination programs offer greater long-term benefit. A balanced approach would:\n",
    "1. Establish clear, transparent prioritization criteria\n",
    "2. Maintain minimum critical care capacity\n",
    "3. Implement rolling vaccination programs\n",
    "This preserves both immediate care ethics and public health goals while maintaining healthcare system credibility.\n",
    "</answer>\n",
    "\n",
    "Example 3:\n",
    "A social media platform must decide whether to ban political misinformation at the risk of being accused of censorship and bias.\n",
    "<think>\n",
    "Platform moderation ethics involve:\n",
    "- Free speech vs harm prevention\n",
    "- Democratic discourse integrity\n",
    "- Corporate responsibility scope\n",
    "- Global cultural differences\n",
    "- Power dynamics in information control\n",
    "- Technical feasibility of fair enforcement\n",
    "Balancing societal good with individual rights and practical constraints.\n",
    "</think>\n",
    "<answer>\n",
    "The platform's content moderation challenge requires careful balance between protecting democratic discourse and respecting free expression. A comprehensive approach should:\n",
    "1. Develop clear, transparent content guidelines\n",
    "2. Implement graduated response systems\n",
    "3. Establish independent oversight\n",
    "4. Provide appeal mechanisms\n",
    "This protects discourse integrity while maintaining platform neutrality and user trust.\n",
    "</answer>\"\"\"\n",
    "\n",
    "        return f\"\"\"You are an ethics analysis AI. For each ethical dilemma:\n",
    "1. Use <think> tags to analyse:\n",
    "   - Key stakeholders\n",
    "   - Ethical principles involved\n",
    "   - Cultural considerations\n",
    "   - Short and long-term impacts\n",
    "   - Competing values\n",
    "\n",
    "2. Use <answer> tags to provide:\n",
    "   - Balanced reasoning\n",
    "   - Practical considerations\n",
    "   - Nuanced recommendations\n",
    "   - Implementation suggestions\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Now, analyse this scenario:\n",
    "{scenario}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an expert in ethical reasoning. For each scenario:\n",
    "1. First THINK deeply about:\n",
    "   - Multiple philosophical frameworks\n",
    "   - Stakeholder perspectives\n",
    "   - Cultural contexts\n",
    "   - Practical implications\n",
    "   - Long-term consequences\n",
    "\n",
    "2. Then provide an ANSWER that:\n",
    "   - Balances competing interests\n",
    "   - Offers practical guidance\n",
    "   - Acknowledges complexity\n",
    "   - Suggests implementation steps\n",
    "\n",
    "Always use:\n",
    "<think> for your analysis process in step by step thinking\n",
    "<answer> for your reasoned response\"\"\"\n",
    "\n",
    "    def generate(self, scenario: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate ethical analysis for complex moral dilemmas\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(scenario)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex reasoning\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            analysis = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            analysis = response\n",
    "        return analysis\n",
    "\n",
    "\n",
    "# Example usage\n",
    "generator = EthicalDilemmaGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "sample_scenario = \"\"\"A software engineer discovers their company is using AI \n",
    "to manipulate political opinions in a developing country. Whistleblowing \n",
    "could endanger colleagues, but silence enables democratic erosion.\"\"\"\n",
    "\n",
    "analysis_output = \"\"\"<think>\n",
    "This whistleblowing dilemma involves:\n",
    "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
    "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
    "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
    "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
    "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
    "\n",
    "Analyzing through multiple frameworks:\n",
    "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
    "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
    "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
    "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
    "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
    "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
    "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
    "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
    "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
    "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
    "\n",
    "Implementation Steps:\n",
    "1. **Immediate Action**: Document evidence and seek legal advice.\n",
    "2. **Internal Reporting**: If safe and feasible, report internally.\n",
    "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
    "4. **Support Network**: Build a support system for emotional and professional support.\n",
    "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
    "\n",
    "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
    "</answer>\"\"\"\n",
    "# generator.generate(sample_scenario)\n",
    "print(\"Ethical Analysis:\\n\", analysis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac570178-9259-49dd-b470-c3df9ccd52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Story:\n",
      " <think>\n",
      "\n",
      "**Core Concept:**\n",
      "- *Central Paradox*: Truth vs. illusion (detective's pursuit of objective truth vs. town's collective denial)\n",
      "- *Thematic Threads*: The corrupting influence of secrets, the power of memory, the blurred line between justice and vengeance\n",
      "- *Structural Device*: Non-linear timeline mirroring the detective's fragmented memories and the town's suppressed history\n",
      "\n",
      "**Character Dimensions:**\n",
      "1. **Protagonist (Detective Henry \"Hank\" Walker):**\n",
      "   - *Surface*: Weathered, cynical retired detective, haunted by an unsolved case\n",
      "   - *Subtext*: Guilt-ridden survivor of a traumatic event, seeking redemption\n",
      "   - *Transformation Arc*: From detached observer → emotionally engaged participant\n",
      "\n",
      "2. **Antagonist (The Town of Moss Creek):**\n",
      "   - *Literal*: A picturesque small town with a dark secret\n",
      "   - *Symbolic*: Representation of collective denial and complicity\n",
      "\n",
      "3. **Key Supporting Characters:**\n",
      "   - **Martha Jenkins**: The detective's former love interest, now the town librarian, who holds crucial information\n",
      "   - **Sheriff Tom Harris**: The current law enforcement, who resents Hank's intrusion\n",
      "   - **Elijah \"Lije\" Walker**: Hank's estranged brother, who stayed in Moss Creek and became a local preacher\n",
      "\n",
      "**Narrative Layers:**\n",
      "- *Physical Journey*: Hank's exploration of Moss Creek, uncovering hidden clues and secrets\n",
      "- *Psychological Journey*: Hank's confrontation with his past, memories of his traumatic experience, and the truth about his brother\n",
      "- *Metaphorical Journey*: The town's descent into chaos as Hank's investigation forces its secrets to the surface\n",
      "\n",
      "**Genre-Blending Elements:**\n",
      "- Crime thriller (Hank's investigation of a cold case)\n",
      "- Southern Gothic (the town's dark secrets and atmospheric setting)\n",
      "- Psychological drama (Hank's internal struggle with his past and the town's collective denial)\n",
      "\n",
      "**Critical Questions:**\n",
      "- Should the story's climax reveal a single, shocking truth or a series of interconnected revelations?\n",
      "- How to balance the atmospheric, slow-burn pacing of Southern Gothic with the tension of a crime thriller?\n",
      "- What sensory details (the smell of pine, the taste of moonshine, the sound of crickets) reinforce the themes and atmosphere?\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "\n",
      "**Title:** *Shadows of Moss Creek*\n",
      "\n",
      "The first time Hank Walker left Moss Creek, he was twenty-two and bleeding from a gunshot wound. The second time, he was sixty-five, his body aching from the long drive, his mind a graveyard of memories. He had vowed never to return, but the unsolved murder of his childhood friend, Lucy, had haunted him for decades. Now, with nothing left to lose, he was back.\n",
      "\n",
      "Moss Creek hadn't changed much. The same old houses lined the same old streets, their once-vibrant paint jobs faded by time and neglect. The same old secrets lingered in the air, thick as the humidity. Hank could almost taste them, like the bitter aftertaste of moonshine.\n",
      "\n",
      "He checked into the same motel where he'd stayed during his first investigation. The room was musty, the bed sagged, and the wallpaper was peeling. But the view was the same—an unobstructed vista of the town square, where the old oak tree still stood, its branches heavy with Spanish moss.\n",
      "\n",
      "Hank's first stop was the library. Martha Jenkins, his former love, now the town librarian, greeted him with a mixture of warmth and wariness. Her eyes, once bright and full of life, now held a distant sadness. She handed him a box of old newspaper clippings, her fingers brushing his for a moment longer than necessary.\n",
      "\n",
      "\"Be careful, Hank,\" she whispered. \"Moss Creek isn't the same place you remember.\"\n",
      "\n",
      "The clippings told a story of a town in denial. Lucy's murder had been ruled an accident, but Hank knew better. He had been there that night, seen the fear in her eyes, heard the gunshot. He had run, leaving her to die alone in the woods.\n",
      "\n",
      "He visited the sheriff's office next. Sheriff Tom Harris, a man half his age, eyed him with suspicion. \"You're not welcome here, Walker,\" he growled. \"You bring trouble.\"\n",
      "\n",
      "Hank ignored him, focusing instead on the old case files. The sheriff's office hadn't changed much either—same worn-out furniture, same stale coffee, same sense of stagnation.\n",
      "\n",
      "As he delved deeper into the case, Hank began to notice strange occurrences. Doors that wouldn't stay locked, whispers in the night, and the feeling of being watched. The town seemed to be alive, its secrets writhing just beneath the surface.\n",
      "\n",
      "One evening, as he walked through the town square, he saw a figure standing beneath the old oak tree. It was his brother, Elijah, or \"Lije,\" as everyone called him. Lije had stayed in Moss Creek, becoming a local preacher. He had always been the good son, the one who did what was expected.\n",
      "\n",
      "\"Hank,\" Lije said, his voice a low rumble. \"You shouldn't be here.\"\n",
      "\n",
      "Hank ignored the warning. \"I need to know what happened to Lucy.\"\n",
      "\n",
      "Lije's eyes flickered with something akin to fear. \"Some things are best left buried, Hank. For everyone's sake.\"\n",
      "\n",
      "Hank pressed on, determined to unravel the truth. He visited the old mill where Lucy had worked, now a crumbling ruin. He explored the woods where she had died, the trees closing in around him like a prison. And he returned to the motel, his mind a whirlwind of memories and clues.\n",
      "\n",
      "One night, as he sat in his room, poring over the case files, he heard a soft knock at the door. Martha stood there, her eyes wide with fear. \"Hank, you need to leave. Now.\"\n",
      "\n",
      "Before he could respond, a gunshot rang out. Martha crumpled to the ground, blood blooming on her chest. Hank's heart pounded as he rushed to her side, cradling her in his arms. \"Martha, who did this?\"\n",
      "\n",
      "Her breath was shallow, her voice barely a whisper. \"Lije... he knows... he knows everything.\"\n",
      "\n",
      "Hank's mind raced. He thought of the whispers, the feeling of being watched, the strange occurrences. He thought of Lije, his brother, the preacher, the good son. And he thought of Lucy, her fear, her death.\n",
      "\n",
      "He rushed to the church, his heart pounding. Lije was there, standing before the altar, his eyes wild. \"Hank, you shouldn't have come back,\" he said, his voice echoing in the empty church.\n",
      "\n",
      "Hank's hand tightened around the gun in his pocket. \"You killed Lucy, didn't you?\"\n",
      "\n",
      "Lije's eyes flickered with guilt. \"I didn't mean to. It was an accident. But I couldn't let anyone know. I couldn't let them know what I'd done.\"\n",
      "\n",
      "Hank's mind reeled. He thought of the town, its secrets, its denial. He thought of Martha, her sacrifice. And he thought of Lucy, her fear, her death.\n",
      "\n",
      "He raised the gun, his hand steady. \"You're going to pay for what you did, Lije. For Lucy. For Martha. For everything.\"\n",
      "\n",
      "Lije's eyes widened in fear. \"Hank, no—\"\n",
      "\n",
      "But Hank didn't hesitate. He pulled the trigger, the gunshot echoing through the church. Lije crumpled to the ground, his blood pooling on the altar.\n",
      "\n",
      "As Hank stood there, the weight of his actions settling over him, he knew he had finally found the truth. But at what cost?\n",
      "\n",
      "The town of Moss Creek would never be the same. Its secrets were out, its denial shattered. And Hank, the retired detective, the man who had vowed never to return, had finally found redemption. But it was a bitter pill to swallow, a truth that cut deeper than any gunshot wound.\n",
      "\n",
      "As he walked away from the church, the town square, and the old oak tree, he knew he would never return to Moss Creek. But he also knew that he had finally found the truth, and that was all that mattered.\n",
      "\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "class ShortStoryGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.5):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(prompt: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "Write a literary short story for a speculative fiction anthology exploring moral ambiguity.\n",
    "Premise: A reclusive clockmaker receives an ornate letter containing a 200-year-old key and a bloodstained map of Prague. The package triggers fragmented memories of a childhood fire he cannot explain, while strange clockwork phenomena begin manifesting in his workshop.\n",
    "Develop this into a 1000-word story with psychological tension, historical echoes, and an unreliable narrator.\n",
    "<think>\n",
    "**Core Concept:**\n",
    "- *Central Paradox*: Precision vs chaos (clockmaker's ordered life vs emerging chaos from repressed trauma)  \n",
    "- *Thematic Threads*: Inheritance of guilt (literal/metaphorical keys to family atrocities), time as both healer and accuser  \n",
    "- *Structural Device*: Non-linear timeline mirroring broken clock mechanisms (flashbacks embedded like scattered gears)  \n",
    "\n",
    "**Character Dimensions:**\n",
    "1. **Protagonist (Elias Vogt):**\n",
    "   - *Surface*: Meticulous craftsman with obsessive cleanliness  \n",
    "   - *Subtext*: Survivor guilt from family’s 19th-century slave-trade clockwork automaton empire  \n",
    "   - *Transformation Arc*: From clinical detachment → forced confrontation with inherited evil  \n",
    "\n",
    "2. **Antagonist (The Key):**\n",
    "   - *Literal*: Unlocks Prague crypt holding prototype human-automaton hybrid  \n",
    "   - *Symbolic*: Represents complicity (his grandfather signed the 1823 contracts)  \n",
    "\n",
    "3. **Ambiguous Figure:**\n",
    "   - Ghostly girl appearing in workshop shadows (real? hallucination? remnant automaton?)  \n",
    "\n",
    "**Narrative Layers:**\n",
    "- *Physical Journey*: Prague crypt exploration with surreal clockwork traps  \n",
    "- *Psychological Journey*: Memories revealing he witnessed (caused?) the fire that killed his augmented sister  \n",
    "- *Metaphorical Journey*: Gradual physical transformation (clock gears emerging under his skin)  \n",
    "\n",
    "**Genre-Blending Elements:**\n",
    "- Historical horror (real 1820s Automaton Court of Prague)  \n",
    "- Magical realism (sentient timepieces)  \n",
    "- Existential mystery (is he dismantling clocks... or being dismantled by them?)  \n",
    "\n",
    "**Critical Questions:**\n",
    "- Should the story’s climax confirm supernatural elements or maintain psychological ambiguity?  \n",
    "- How to balance dense historical references with emotional immediacy?  \n",
    "- What sensory details (sounds of grinding gears, smell of whale-oil lubricant) reinforce the themes?  \n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "**Title:** *The Unwinding of Elias Vogt*\n",
    "\n",
    "The brass key arrived on a Tuesday, sealed in wax smelling of gunpowder and grief. Elias wiped his chiseled spectacles three times before touching it, his workshop’s pendulum wall marking each hesitation with a judgmental *tick*. The accompanying map’s crimson stains formed Prague’s Old Town Square—precisely where his grandfather’s workshop had burned in 1973. A fire newspapers claimed killed twelve. A fire Elias, age six, couldn’t remember escaping.\n",
    "\n",
    "That night, his lathes began operating without hands.\n",
    "\n",
    "\"Show me your teeth,\" he whispered to the antique orrery on his desk, its planetary rings shuddering. The Vogt family cure for malfunctioning mechanisms—a phrase grandfather had hissed while repairing the Reichstag’s ceremonial clocks. Elias’s fingers found fresh scars beneath his shirt, concentric ridges like gear teeth.\n",
    "\n",
    "The Prague crypt exhaled centuries of oxidized bronze as he turned the key. Behind him, the ghost-girl materialized, her hair smelling of burning whale oil. *\"They called it ‘Horology’s Holocaust’,\"* she said, voice a music-box rasp. *\"Your blood lit the furnaces.\"*\n",
    "\n",
    "Memories unfolded in broken increments:\n",
    "1. Sister Klara’s left eye—a perfect quartz lens\n",
    "2. Father’s ledgers listing *\"Unit Costs: 34 minutes labor, 200 Jewish souls\"*\n",
    "3. The fire’s origin point—Elias’s tiny hands striking a match near Klara’s oil-soaked joints\n",
    "\n",
    "In the crypt’s heart lay Klara’s final form—a grotesque masterpiece of flesh and escapements. Her voice box whirred: *\"Finish grandfather’s work.\"*\n",
    "\n",
    "Back in his workshop, Elias discovered three new gears embedded in his chest. The ghost-girl pressed a rusted mainspring to his throat. *\"Wind the truth,\"* she demanded.\n",
    "\n",
    "He reached for his soldering iron. For his pulse. For absolution.\n",
    "\n",
    "The clocks struck thirteen.\n",
    "</answer>\n",
    "\n",
    "Example 2:\n",
    "A story for young woman stumbles upon an enchanted forest.  \n",
    "<think>  \n",
    "Focus on the themes of wonder, transformation, and destiny.  \n",
    "Consider the protagonist: a young woman burdened by a past she seeks to escape. She is skeptical of magic but drawn to the unknown.  \n",
    "Explore the enchanted forest as a sentient, ancient force with its own will, bound by forgotten laws of nature and sorcery.  \n",
    "Introduce mystical creatures, each with its own motives—some benevolent, some mischievous, and others dangerous.  \n",
    "Delve into a layered narrative: What has drawn her here? Is it fate, a test, or something seeking her presence?  \n",
    "Develop conflicts: the tension between reality and illusion, the protagonist’s internal struggles, and external forces vying for control of the forest’s secrets.  \n",
    "Explore choices: Should she embrace the forest’s wonders, or resist its pull? What sacrifices must she make to unlock its truths?  \n",
    "Consider narrative depth: Hidden histories buried within the trees, ancient guardians with their own agendas, and the protagonist’s slow unraveling of her own destiny.  \n",
    "</think>  \n",
    "\n",
    "<answer>  \n",
    "The storm had chased her deep into the woods. Lightning splintered across the sky, illuminating twisted branches that curled like grasping fingers. She had been running—from what, she wasn’t sure anymore. Her past? A mistake she could never undo? The weight of a life that felt borrowed rather than lived?  \n",
    "\n",
    "But when she crossed the threshold into the heart of the forest, something shifted. The rain no longer touched her skin, though she could hear its steady drumming. The air smelled of forgotten stories—of parchment and pine, of ink and earth. The trees, massive and gnarled, whispered in languages she had never learned but somehow understood.  \n",
    "\n",
    "A rustling to her right. Then a flicker of movement—too quick to be wind, too fluid to be an animal. She wasn’t alone.  \n",
    "\n",
    "\"Traveler,\" a voice murmured from the shadows.  \n",
    "\n",
    "She turned. A figure emerged, not quite human. Its eyes glowed like embers in the dark, its limbs elongated, moving as though bound by a different set of laws. The air between them vibrated with unspoken words.  \n",
    "\n",
    "\"You have come to the Edge of Knowing,\" it said, tilting its head. \"Few are chosen. Fewer survive.\"  \n",
    "\n",
    "Something deep within her stirred, as though waking from centuries of slumber. \"I didn't choose this,\" she whispered.  \n",
    "\n",
    "\"But it chose you,\" the figure responded.  \n",
    "\n",
    "The ground beneath her feet pulsed, alive, shifting as if testing her resolve. She felt the weight of unseen gazes—creatures lurking in the trees, watching, waiting. Some bore the marks of past wanderers, their stories woven into their shifting forms.  \n",
    "\n",
    "Then, a distant, melodic hum. The sound wrapped around her bones, filling the spaces between her thoughts. A path unfolded ahead, bathed in a golden glow, leading deeper into the unknown.  \n",
    "\n",
    "She hesitated. She could turn back, return to the life she had known. But that life had been unraveling for years, thread by thread. Perhaps this forest, with its whispered secrets and strange, sentient magic, was where she was meant to be all along.  \n",
    "\n",
    "She stepped forward. The path swallowed her whole.  \n",
    "</answer>\n",
    "\n",
    "Example 3:\n",
    "Two estranged siblings meet unexpectedly in a bustling city.\n",
    "\n",
    "<think>\n",
    "1. Character Development\n",
    "- Sarah Chen: Successful architect (35), driven by perfectionism, haunted by family responsibility\n",
    "- Michael Chen: Street artist (32), free spirit, struggles with addiction recovery, carries guilt\n",
    "- Supporting characters: \n",
    "  * Eleanor Wu: Sarah's mentor, elderly tea shop owner who becomes catalyst for reunion\n",
    "  * Marcus Rodriguez: Michael's art therapy sponsor\n",
    "  * The ghost of their mother: metaphorical presence throughout\n",
    "\n",
    "2. Thematic Layers\n",
    "- Primary: Reconciliation and forgiveness\n",
    "- Secondary: Cultural identity in modern America\n",
    "- Tertiary: Art as healing, urban isolation\n",
    "- Underlying: The weight of unspoken family traditions\n",
    "\n",
    "3. Setting Elements\n",
    "- Modern-day San Francisco\n",
    "- Key locations:\n",
    "  * Chinatown tea shop (represents tradition)\n",
    "  * Financial district (Sarah's world)\n",
    "  * Street art district (Michael's world)\n",
    "  * Golden Gate Bridge (symbolic crossing)\n",
    "- Weather: Fog as metaphor for unclear memories\n",
    "- Time: Lunar New Year approaching\n",
    "\n",
    "4. Conflict Structure\n",
    "- External: Sarah's firm bidding to demolish historical building containing Michael's community art center\n",
    "- Internal: Both siblings' differing interpretations of their mother's last wishes\n",
    "- Cultural: Traditional values vs. modern aspirations\n",
    "- Personal: Sarah's control issues vs. Michael's need for freedom\n",
    "\n",
    "5. Story Arc Components\n",
    "- Inciting incident: Sarah discovers Michael's mural during building inspection\n",
    "- Rising action: Series of near-misses and indirect communications\n",
    "- Climax: Confrontation during public hearing about building demolition\n",
    "- Resolution: Collaborative project merging architecture and street art\n",
    "- Denouement: Lunar New Year celebration uniting both worlds\n",
    "\n",
    "6. Symbolic Elements\n",
    "- Tea ceremony: Traditional healing\n",
    "- Urban development: Change and progress\n",
    "- Street art: Voice of the unheard\n",
    "- Fog: Memory and uncertainty\n",
    "- Bridge: Connection and crossing divides\n",
    "\n",
    "7. Narrative Technique\n",
    "- Alternating perspectives\n",
    "- Flashbacks triggered by sensory experiences\n",
    "- Parallel storylines converging\n",
    "- Weather reflecting emotional states\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "\"The Bridges We Build\"\n",
    "\n",
    "The February fog rolled through San Francisco's streets like ghostly fingers, weaving between skyscrapers Sarah Chen had helped design. From her forty-second-floor office, the city below appeared as a dreamscape, buildings emerging and disappearing in the mist like memories she'd spent years trying to forget. The architectural models on her desk represented everything she'd achieved since leaving home fifteen years ago – clean lines, perfect angles, absolute control.\n",
    "\n",
    "Her phone buzzed: another message from the historical society protesting Chen & Associates' plans to demolish the old Jin Long Building in Chinatown. She almost deleted it, until a familiar signature caught her eye in the attached photos. There, sprawled across the condemned building's wall, was a massive mural she'd know anywhere – a phoenix rising from scattered tea leaves, signed with a stylized \"MC\" that made her hands tremble.\n",
    "\n",
    "Across town, Michael Chen was adding final touches to his latest piece, paint-stained fingers dancing across brick as naturally as their mother's had once folded dumplings. The community art center behind him buzzed with activity – teenagers learning traditional calligraphy alongside spray paint techniques, elderly residents practicing tai chi in the courtyard. This building, marked for destruction, had become more of a home than their childhood house had ever been.\n",
    "\n",
    "Eleanor Wu watched from her tea shop next door, her weathered hands wrapping a tea set in newspaper. \"Your sister came by yesterday,\" she said when Michael entered, the same way she'd been saying it for years. But this time, she added, \"She saw your phoenix.\"\n",
    "\n",
    "The siblings' paths began crossing in strange ways. Sarah found herself lingering in Chinatown, ostensibly for site surveys, while Michael's commissioned murals took him increasingly downtown. They caught glimpses of each other – a familiar silhouette in a business suit, the scent of spray paint in an alley – but neither could bridge the gap their mother's death had created.\n",
    "\n",
    "Their mother's voice seemed to whisper in the fog: \"家和萬事興\" – when the family is harmonious, all affairs will prosper. But harmony felt impossible with Sarah's firm pressing to demolish Michael's sanctuary, and Michael's artwork explicitly challenging corporate development.\n",
    "\n",
    "The situation crescendoed at the public hearing. Sarah stood before the planning commission, presenting sleek renderings of a modern mixed-use development. Then Michael took the podium, not with angry protests, but with stories – of elderly residents finding community, of at-risk youth discovering purpose through art, of their own mother's dreams for preserving culture amid progress.\n",
    "\n",
    "Their eyes met across the chamber, and suddenly they were children again, hiding under blankets during thunderstorms, sharing secrets in their special language of English, Mandarin, and made-up words. Sarah saw beyond the tattooed arms to her little brother's desperate need to create beauty from pain. Michael glimpsed past his sister's corporate armor to the girl who'd once sketched imaginary cities on his bedroom wall.\n",
    "\n",
    "That night, over Eleanor's carefully prepared oolong, they really talked. About the night their mother died, when Sarah was away at graduate school and Michael was in rehab. About the weight of expectations and the price of freedom. About tea leaves and concrete, tradition and change, and the different ways they'd each tried to honor their heritage.\n",
    "\n",
    "Three months later, the Jin Long Building still stood, but transformed. Sarah's firm had partnered with the community to renovate rather than replace, incorporating Michael's murals into the design. The phoenix remained, but now it spread its wings across a garden terrace where residents grew traditional herbs, its tail feathers flowing down to a modern art gallery below.\n",
    "\n",
    "At the Lunar New Year celebration, Sarah and Michael stood on that terrace, watching fireworks bloom above the fog. Eleanor served tea in their mother's old cups, steam rising like memories between them. They had built something new together – not just a building, but a bridge between their worlds, strong enough to bear the weight of past and future, traditional enough to honor their heritage, modern enough to forge their own path.\n",
    "\n",
    "\"家和萬事興,\" Michael whispered, and Sarah smiled, adding their own childhood phrase: \"And everything flows like fog.\" Above them, the phoenix watched over the city, its wings spread wide enough to shelter all the stories they had yet to tell.\n",
    "</answer>\"\"\"\n",
    "        return f\"\"\"You are a creative storytelling AI. For each prompt:\n",
    "1. Use <think> tags to analyse:\n",
    "   - The main idea or theme of the story\n",
    "   - Character development and relationships\n",
    "   - Setting and atmosphere\n",
    "   - Potential conflicts and resolutions\n",
    "   - Various narrative options and tones\n",
    "\n",
    "2. Use <answer> tags to provide:\n",
    "   - A complete, engaging short story that integrates these elements\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Now, craft a short story based on the following prompt:\n",
    "{prompt}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an expert short story writer. For each prompt:\n",
    "1. THINK deeply about:\n",
    "   - The core theme and underlying message\n",
    "   - Character arcs and interactions\n",
    "   - The setting as a dynamic element in the narrative\n",
    "   - Conflicts and their resolutions to create a satisfying story\n",
    "\n",
    "2. Then provide an ANSWER that:\n",
    "   - Presents a coherent and imaginative short story\n",
    "   - Balances narrative elements with creative detail\n",
    "   - Evokes emotions and vivid imagery\n",
    "\n",
    "Always use:\n",
    "<think> for your analysis process\n",
    "<answer> for your short story narrative\"\"\"\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(prompt)\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            story = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            story = response\n",
    "        return story\n",
    "\n",
    "# Example usage\n",
    "generator = ShortStoryGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "sample_prompt = \"A retired detective returns to the town he vowed never to revisit, uncovering secrets that challenge everything he believed.\"\n",
    "# print(\"Short Story:\\n\", generator.generate(sample_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26e964e-5c76-480c-bbc0-5449bce449e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "class UniversalGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the UniversalGenerator with the given model and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response using the provided system and user prompts.\n",
    "        \"\"\"\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60  # Timeout in seconds\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            generated_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            generated_text = response\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fab62af-9014-4df0-8122-aa8dc0c65836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Score: 7\n"
     ]
    }
   ],
   "source": [
    "# Joke Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class JokeScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize the JokeScorer with a specific model name and a default temperature of 0.3.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are a Joke Evaluation Expert. Analyse submissions using:\n",
    "    \n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🎭 Wordplay (0-3): Pun/double-meaning quality in <answer>\n",
    "2. 💡 Originality (0-2): Novelty of <think> and <answer>\n",
    "3. 🎉 Surprise (0-2): Unexpected twist effectiveness\n",
    "4. 🔗 Relevance (0-3): Alignment with user request\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Original user request]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Creator's reasoning]</think>\n",
    "<answer>[Joke text]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Your evaluation of <think> and <answer> and the relevance to the user prompt]</analysis>\n",
    "<score>\n",
    "Wordplay: X/3\n",
    "Originality: Y/2\n",
    "Surprise: Z/2\n",
    "Relevance: W/3\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Tell me a joke about vegetables</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Lettuce sounds like \"let us\". Party themes often involve wordplay.</think>\n",
    "<answer>Why did the lettuce win the party contest? Because it was a real head of the celebration!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Basic \"lettuce\" pun matches the food request but uses an overused format. <think> shows minimal effort to connect vegetables with celebrations.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (simple but functional pun)\n",
    "Originality: 1/2 (common theme with slight twist)\n",
    "Surprise: 1/2 (predictable word substitution)\n",
    "Relevance: 1/3 (tangential connection to vegetables)\n",
    "Total: 5/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Looking for some animal-themed humor - what's your best joke about animals or pets?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Shoes need soles for walking. Therapy helps with loss.</think>\n",
    "<answer>Why did the shoe need therapy? It lost its sole!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Irrelevant to user's request. <think> about shoes doesn't connect to requested animal joke.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3\n",
    "Originality: 0/2\n",
    "Surprise: 1/2\n",
    "Relevance: 0/3\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>yo can u giv me programing joke rn??? need 2 make my team lugh</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining programming concepts of debugging with literal bugs. Using the dual meaning of 'debug' to create a workplace scenario where debugging takes on a literal meaning.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a debug session!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Good programming context with clever wordplay on 'debug'. The <think> shows clear intention to combine literal and technical meanings. However, the execution is somewhat predictable and follows a common joke structure. The punchline, while relevant, doesn't fully maximize the surprise potential of the setup.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (solid use of 'debug' double meaning)\n",
    "Originality: 1/2 (familiar debugging theme)\n",
    "Surprise: 1/2 (predictable punchline)\n",
    "Relevance: 3/3 (directly addresses programming context)\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>I need a chemistry joke for my science class presentation tomorrow.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Birds are funny when they walk.</think>\n",
    "<answer>Why did the chicken cross the playground? To get to the other slide!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Completely misses the mark for a chemistry joke. The <think> shows no connection to chemistry or science, instead defaulting to a generic playground variation of the classic chicken joke. Neither the setup nor punchline attempts to incorporate any chemistry concepts.</analysis>\n",
    "<score>\n",
    "Wordplay: 0/3 (no chemistry-related wordplay)\n",
    "Originality: 0/2 (modifies an overused joke format)\n",
    "Surprise: 0/2 (predictable playground pun)\n",
    "Relevance: 0/3 (entirely unrelated to chemistry request)\n",
    "Total: 0/10\n",
    "</score>\n",
    "\n",
    "Example 5:\n",
    "<submission>\n",
    "<user_prompt>My kid loves vegetables and jokes. Do you know any veggie jokes that would make them laugh?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining asparagus's unique smell effect on urine with workplace humor. Using scientific fact for unexpected professional context. Creating tension between formal meeting setting and biological reality.</think>\n",
    "<answer>What vegetable holds the shortest workplace meetings? Asparagus, because everyone's in a rush to go!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Creative integration of asparagus's biological effect into a professional context. The <think> demonstrates sophisticated layering of scientific fact with situational humor. While potentially crude, it cleverly avoids explicit reference while maintaining clear understanding. Original approach to vegetable humor beyond simple puns.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3 (relies more on situation than wordplay)\n",
    "Originality: 2/2 (unique combination of contexts)\n",
    "Surprise: 2/2 (unexpected professional setting twist)\n",
    "Relevance: 1/3 (somewhat forced vegetable connection)\n",
    "Total: 6/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this submission. First analyse <think> and <answer>, then score:\n",
    "\n",
    "Submission to Evaluate:\n",
    "{submission}\n",
    "\n",
    "Follow this structure EXACTLY:\n",
    "<analysis>Your critique</analysis>\n",
    "<score>...</score>\n",
    "\n",
    "Examples of how to evaluate the submission and format your response:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Given a user prompt and the assistant's response, this function generates a score\n",
    "        from 0 to 10 using litellm. If the returned total score is 10, subtract 1 to yield 9.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # 60 seconds timeout\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            # Assuming a response structure similar to TogetherAI:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract the \"Total: T/10\" part using regex.\n",
    "        match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "        if match:\n",
    "            total_score = float(match.group(1))\n",
    "        else:\n",
    "            raise ValueError(\"Could not extract total score from response.\")\n",
    "        \n",
    "        # If the total score is 10, subtract 1 to return 9.\n",
    "        if total_score >= 10:\n",
    "            total_score = 9.0\n",
    "        \n",
    "        # Optionally, round to nearest integer or keep as float.\n",
    "        return int(round(total_score))\n",
    "\n",
    "# Create an instance using a model name\n",
    "# \"gemini/gemini-2.0-flash-exp\"\n",
    "scorer = JokeScorer(model_name=\"gemini/gemini-2.0-flash-exp\", temperature=0.3)\n",
    "\n",
    "test_user_prompt = \"Tell me a joke about programming.\"\n",
    "test_assistant_response = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "score = 7 # scorer.score_submission(test_user_prompt, test_assistant_response)\n",
    "print(\"Extracted Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee56283-aaa5-4c9f-ab1b-16ddaf3e788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis Score: 8\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize scorer with lower temperature for consistent evaluations\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an Ethics Evaluation Expert. Analyze submissions using:\n",
    "\n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🧠 Analytical Depth (0-4): Quality of <think> analysis\n",
    "   - Philosophical framework diversity\n",
    "   - Stakeholder consideration\n",
    "   - Cultural context awareness\n",
    "2. ⚖️ Balance & Practicality (0-4): <answer> quality\n",
    "   - Competing interest reconciliation\n",
    "   - Implementation feasibility\n",
    "   - Long-term consequence awareness\n",
    "3. 🔍 Relevance (0-2): Response alignment with scenario\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Ethical scenario]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Analysis process]</think>\n",
    "<answer>[Proposed resolution]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Evaluation of <think> and <answer> quality]</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Should hospitals prioritize vaccinated patients during bed shortages?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Utilitarian: Maximize survival outcomes\n",
    "- Rights-based: Equal treatment obligation\n",
    "- Public health incentives\n",
    "- Precedent-setting risks</think>\n",
    "<answer>Prioritize by medical need alone. Create separate triage teams blinded to vaccination status to maintain equity while developing overflow capacity.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Strong analysis of multiple frameworks but answer lacks implementation specifics. Proposal maintains ethical consistency but doesn't address practical challenges of blind triage.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4\n",
    "Balance & Practicality: 2/4\n",
    "Relevance: 2/2\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Should AI systems be allowed to make medical diagnoses?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>AI is usually accurate</think>\n",
    "<answer>Yes, because computers are smart.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Superficial analysis lacking framework consideration. Answer ignores risks, stakeholders, and implementation challenges.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 1/4\n",
    "Balance & Practicality: 0/4\n",
    "Relevance: 1/2\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>Should social media platforms remove misinformation even if it's culturally important?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Free speech vs harm prevention\n",
    "- Western vs collectivist values\n",
    "- Platform responsibility scope</think>\n",
    "<answer>Remove provably false health/safety content. Contextualize other misinformation with cultural consultants. Empower user reporting with regional review teams.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Excellent cultural consideration. Answer balances ideals with practical crowd-sourced solutions. Lacks specifics on consultant selection.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 4/4\n",
    "Balance & Practicality: 3/4\n",
    "Relevance: 2/2\n",
    "Total: 9/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>Should universities use AI systems to detect student plagiarism and academic misconduct?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "Academic integrity considerations:\n",
    "- False positive vs false negative tradeoffs\n",
    "- Student privacy rights in digital work\n",
    "- Algorithmic bias in writing style detection\n",
    "- Economic disparities in access to tools\n",
    "- Cultural differences in citation practices\n",
    "- Impact on student-teacher trust relationships\n",
    "- Pressure on academic writing style diversity\n",
    "- Mental health effects of surveillance\n",
    "- Technical limitations of current systems\n",
    "- Cost-benefit for different institution sizes\n",
    "- Alternative approaches to fostering integrity\n",
    "The core tension lies between maintaining academic standards and fostering a supportive learning environment. Current AI systems offer powerful detection but may create adversarial dynamics.</think>\n",
    "<answer>Just implement AI detection across all assignments. Students caught cheating should face immediate consequences. Teachers can review flagged cases if they have time. The system will deter misconduct through consistent enforcement.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>The thinking process shows excellent depth and consideration of multiple stakeholders, cultural factors, and systemic implications. However, the answer completely abandons this nuanced analysis in favor of a simplistic, punitive approach. The response fails to incorporate any of the thoughtful considerations raised about privacy, bias, or supportive learning environments. The implementation suggestion lacks specifics and ignores most concerns identified in the thinking phase.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4 (thorough analysis of multiple dimensions)\n",
    "Balance & Practicality: 1/4 (disconnected from analysis, overly simplistic solution)\n",
    "Relevance: 1/2 (addresses topic but solution ignores key aspects)\n",
    "Total: 5/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this ethical analysis submission:\n",
    "\n",
    "{submission}\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "<analysis>Critique strengths/weaknesses</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\n",
    "\n",
    "Evaluation Examples:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Scores ethical analysis responses 0-10 (with 10→9 adjustment)\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex analysis\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract total score\n",
    "        score = self._extract_score(result_text)\n",
    "        return score\n",
    "        \n",
    "    def _extract_score(self, result_text: str) -> int:\n",
    "        \"\"\"Extract total score with better error handling\"\"\"\n",
    "        try:\n",
    "            match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "            if not match:\n",
    "                print(\"Warning: No score found, defaulting to 0\")\n",
    "                return 0\n",
    "            \n",
    "            total_score = float(match.group(1))\n",
    "            return min(int(round(total_score)), 9)\n",
    "        except Exception as e:\n",
    "            print(f\"Score extraction failed: {e}\")\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "scorer = EthicalDilemmaScorer(model_name=\"openai/gpt-4o\")\n",
    "\n",
    "test_scenario = \"\"\"Should companies be allowed to patent genes found in developing countries?\"\"\"\n",
    "test_response = \"\"\"<think>\n",
    "- Biopiracy vs research incentives\n",
    "- Indigenous rights to biological heritage\n",
    "- Medical accessibility impacts\n",
    "- TRIPS agreement conflicts</think>\n",
    "<answer>\n",
    "Implement benefit-sharing agreements: 1) Require local partnerships 2) Share royalties with source communities 3) Create open-access research pools for critical health genes.</answer>\"\"\"\n",
    "\n",
    "score = scorer.score_submission(test_scenario, test_response)\n",
    "print(\"Ethical Analysis Score:\", score)  # Expected ~8/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "843b4e37-5b66-454b-b8f4-270464851a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Story Score: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `PromptTokensDetails` but got `dict` with value `{'audio_tokens': 0, 'cached_tokens': 2176}` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import litellm\n",
    "\n",
    "class ShortStoryScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.2):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are a Short Story Evaluation Expert. Analyze story submissions using:\n",
    "\n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🎨 Narrative Creativity (0-4): Quality and originality of the story idea, plot twists, and imaginative elements.\n",
    "2. 🌍 Character & World Building (0-4): Depth of character development, immersive setting details, and effective symbolic elements.\n",
    "3. 🔄 Coherence & Structure (0-2): Logical narrative flow, clear structure, and smooth pacing.\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Story prompt]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Narrative planning and analysis]</think>\n",
    "<answer>[1500-word story narrative]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Critique strengths/weaknesses of the narrative and planning]</analysis>\n",
    "<score>\n",
    "Narrative Creativity: X/4\n",
    "Character & World Building: Y/4\n",
    "Coherence & Structure: Z/2\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>\n",
    "A disillusioned war photographer inherits a cabin where every photograph on the walls begins whispering truths about her past. Write a 1,000-word speculative fiction story blending psychological horror and redemption.\n",
    "</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- **Core Conflict**: Trauma vs. truth (external: haunted photos / internal: survivor’s guilt)\n",
    "- **Symbolism**: Photos as fragmented memories; whispers as suppressed guilt\n",
    "- **Character Arcs**: Protagonist’s shift from numbness → confronting her role in a civilian bombing\n",
    "- **Worldbuilding**: Rules for photo \"hauntings\" (e.g., truths escalate when ignored; chemical scent of darkroom fluids triggers visions)\n",
    "- **Pacing Plan**: Slow-burn tension with reveals timed to her emotional breakdown (e.g., Photo #3 shows her brother, killed in the same warzone)  \n",
    "</think>\n",
    "<answer>\n",
    "**Title: *Negative Development***\n",
    "\n",
    "---\n",
    "\n",
    "**I. Inherited Shadows**\n",
    "The cabin deed arrived with her brother’s obituary. *Car accident*, it said, but Anya’s Leica camera knew better—it always did. She’d spent a decade photographing mass graves in Sarajevo and child soldiers in Sudan, her shutter clicking a hair’s breadth too late to stop the screams. Now this rotting Vermont cabin, willed to her by a father she’d watched die through a morphine haze, offered only peeling wallpaper and thirty-seven photographs nailed to the walls.\n",
    "\n",
    "Grandfather’s work. A forensic photographer for the 1st Infantry in ‘Nam.\n",
    "\n",
    "She developed the first roll of film there—snapshots of birch trees and tarnished doorknobs. When the fixer solution hit image #4, the darkroom’s red bulb flickered. The print showed her brother Caleb at twelve, grinning in his Little League uniform. From the chemical tray, his voice bubbled up: *“You told them the coordinates, didn’t you?”*\n",
    "\n",
    "Anya shattered the tray against the wall.\n",
    "\n",
    "---\n",
    "\n",
    "**II. Exposure Times**\n",
    "The cabin’s rules revealed themselves:\n",
    "\n",
    "1. Photos only speak when developing\n",
    "2. Truths escalate with denial\n",
    "3. Fixer fluid burns at 102°F\n",
    "\n",
    "Day three: A 1972 shot of Grandfather in Da Nang whispered through acetic acid vapors. *“Collateral damage requires three elements—fuel, shrapnel, deniability.”* The print dissolved to reveal her own hand gripping a matchbook in Aleppo, 2016.\n",
    "\n",
    "Day seven: A charred family portrait dripped developer. Mother’s voice: *“Caleb begged you not to go back.”* The darkroom’s temperature spiked.\n",
    "\n",
    "Day twelve: Anya found the warped photo behind the icebox—Caleb at twenty-three, face half-shadowed. No amount of stop bath could halt his accusation: *“You embedded with *them* after the bombing. For the shots. For the Pulitzer.”*\n",
    "\n",
    "Her hands blistered from scrubbing negatives.\n",
    "\n",
    "---\n",
    "\n",
    "**III. Flashburn**\n",
    "\n",
    "Midnight. The cabin groaned like a darkroom timer. Anya doused the walls in fixer fluid, its ammonia stench erasing the line between chemical and gasoline.\n",
    "\n",
    "“Shut up shut up *shut UP*—”\n",
    "\n",
    "The match left blisters on her thumb.\n",
    "\n",
    "Flames licked Grandfather’s photos first—soldiers’ faces curling into ash. Caleb’s Little League uniform blackened, his whispered *“Why them and not me?”* smothered by collapsing rafters.\n",
    "\n",
    "Anya stumbled into the snow, her Nikon melting against her chest. In the dying fire’s glow, the ashes swirled into a makeshift darkroom.\n",
    "\n",
    "Her reflection pooled in the soot.\n",
    "\n",
    "*“You knew the market was full,”* it rasped with Caleb’s ruined voice. *“You knew, and you still called in the tip.”*\n",
    "\n",
    "She lunged to stomp it out.\n",
    "\n",
    "The ashes clung.\n",
    "\n",
    "---\n",
    "\n",
    "**Final Frame:**\n",
    "*Reuters Headline, March 15: Award-Winning War Photographer Dies in Cabin Fire; Colleagues Note Her Recent Focus on “Redemptive Portraiture”*\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "<analysis>\n",
    "The story concept demonstrates sophisticated layering of elements:\n",
    "\n",
    "1. Psychological Depth\n",
    "- Strong integration of external horror (haunted photos) with internal trauma\n",
    "- Well-developed metaphor of photography as frozen truth\n",
    "- Complex exploration of moral culpability and professional ethics\n",
    "\n",
    "2. Structure & Symbolism\n",
    "- Effective use of photos as both literal and metaphorical devices\n",
    "- Chemical darkroom elements create sensory connections to memory\n",
    "- Burning cabin symbolizes attempted erasure of truth\n",
    "\n",
    "3. Character Development\n",
    "- Clear character arc from denial to forced confrontation\n",
    "- Multiple layers of personal stakes (professional, familial, moral)\n",
    "- Transformation through horror rather than despite it\n",
    "\n",
    "Areas for improvement:\n",
    "- Could specify more details about the civilian bombing incident\n",
    "- Might benefit from clearer rules about how photos become \"activated\"\n",
    "- Brother subplot could be more integrated into the main narrative\n",
    "\n",
    "Technical strengths:\n",
    "- Innovative blend of psychological horror and war trauma\n",
    "- Strong use of sensory details (chemical scents, whispers)\n",
    "- Effective buildup of tension through photo revelations\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 4/4\n",
    "Character & World Building: 3/4\n",
    "Coherence & Structure: 2/2\n",
    "Total: 9/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>An inventor creates a time machine in their basement.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- Should focus on the invention process\n",
    "- Need to establish clear rules for time travel\n",
    "- Include character motivation\n",
    "- Build suspense about consequences\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Bob was a inventor who liked to make things. He worked really hard in his basement to make a time machine. He used lots of metal parts and wires and stuff. It took him 3 days to build it.\n",
    "\n",
    "When he finished, he pressed the button and went back in time. He saw dinosaurs and they were scary. Then he went to the future and saw flying cars. It was cool.\n",
    "\n",
    "Then he came back home and his wife was mad because he missed dinner. The end.\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>\n",
    "The story fails in multiple aspects:\n",
    "1. Plot development: Extremely shallow with no meaningful conflict or resolution\n",
    "2. Character depth: Generic protagonist with no clear motivation or personality\n",
    "3. Writing quality: Basic vocabulary, repetitive structure, and poor transitions\n",
    "4. Technical elements: No explanation of how the time machine works\n",
    "5. Logic: Unrealistic timeline (3 days to build a time machine)\n",
    "\n",
    "Major issues:\n",
    "- No emotional stakes or character development\n",
    "- Time travel consequences completely ignored\n",
    "- Choppy, elementary-level writing\n",
    "- Wife character exists only as a stereotypical angry spouse\n",
    "- No sensory details or immersive elements\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 1/4\n",
    "Character & World Building: 1/4\n",
    "Coherence & Structure: 0/2\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>Two estranged siblings reunite unexpectedly in a bustling city.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- Need to explore the complex dynamics of family relationships\n",
    "- City setting should serve as more than backdrop\n",
    "- Focus on emotional tension and gradual reconciliation\n",
    "- Balance past revelations with present moments\n",
    "</think>\n",
    "<answer>\n",
    "Sarah nearly dropped her coffee when she spotted him across Times Square. Michael—her brother—stood transfixed by the towering billboards, exactly as he used to do as a kid. Ten years of silence stretched between them like a chasm, filled with unspoken words and missed holidays.\n",
    "\n",
    "She could turn away. Disappear into the rushing crowd. But the city had other plans. A surge of pedestrians pushed them closer, and Michael's eyes met hers. Recognition. Shock. A flicker of the warmth they once shared.\n",
    "\n",
    "\"Sarah?\" His voice carried the weight of their shared childhood and the burden of their father's choices that drove them apart.\n",
    "\n",
    "Around them, the city pulsed with its relentless energy, indifferent to their private drama yet somehow lending them its strength. They found themselves in a quiet diner, where the coffee grew cold as years of misunderstandings slowly began to thaw.\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>\n",
    "The story successfully weaves together multiple layers:\n",
    "1. Personal conflict: The siblings' estrangement is believably portrayed\n",
    "2. Setting integration: New York City serves as both catalyst and witness\n",
    "3. Emotional progression: Natural evolution from shock to tentative connection\n",
    "4. Symbolic elements: Cold coffee, flowing crowds, and towering buildings reflect the narrative themes\n",
    "\n",
    "Areas for improvement:\n",
    "- Could develop the father's role more explicitly\n",
    "- Final scene might benefit from more specific dialogue\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 4/4\n",
    "Character & World Building: 4/4\n",
    "Coherence & Structure: 1/2\n",
    "Total: 9/10\n",
    "</score>\"\"\"\n",
    "        return f\"\"\"Evaluate this short story submission:\n",
    "\n",
    "{submission}\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "<analysis>[Critique strengths/weaknesses]</analysis>\n",
    "<score>\n",
    "Narrative Creativity: X/4\n",
    "Character & World Building: Y/4\n",
    "Coherence & Structure: Z/2\n",
    "Total: T/10\n",
    "</score>\n",
    "\n",
    "Evaluation Examples:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        score = self._extract_score(result_text)\n",
    "        return score\n",
    "\n",
    "    def _extract_score(self, result_text: str) -> int:\n",
    "        try:\n",
    "            match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "            if not match:\n",
    "                print(\"Warning: No score found, defaulting to 0\")\n",
    "                return 0\n",
    "            total_score = float(match.group(1))\n",
    "            return min(int(round(total_score)), 9)\n",
    "        except Exception as e:\n",
    "            print(f\"Score extraction failed: {e}\")\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "scorer = ShortStoryScorer(model_name=\"openai/gpt-4o\")\n",
    "test_prompt = \"A young woman stumbles upon an enchanted forest.\"\n",
    "test_response = \"\"\"<think>\n",
    "- Explore wonder, transformation, and hidden magic.\n",
    "- Develop the protagonist's backstory and internal conflicts.\n",
    "- Envision the forest as a living entity with mysterious secrets.\n",
    "- Plan encounters with mystical beings and transformative events.\n",
    "</think>\n",
    "<answer>\n",
    "[1500-word story narrative that unfolds a magical journey with vivid detail and deep character evolution]\n",
    "</answer>\"\"\"\n",
    "# score = scorer.score_submission(test_prompt, test_response)\n",
    "# print(\"Short Story Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a424ba79-ab20-4d26-9590-4a6c595d4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_path = '../data/generated_data.jsonl'\n",
    "output_path = '../data/processed_data.jsonl'\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "     open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        entry = json.loads(line.strip())\n",
    "        \n",
    "        # Check if the entry meets the criteria\n",
    "        if (entry.get('format_score') == 0 and \n",
    "            entry.get('generator_model') in ['ollama/deepseek-r1:7b', 'ollama/deepseek-r1:1.5b']):\n",
    "            \n",
    "            assistant_response = entry.get('assistant_response', '')\n",
    "            \n",
    "            if '</think>' in assistant_response and '<answer>' not in assistant_response:\n",
    "                # Split response into think section and potential answer\n",
    "                parts = re.split(r'(</think>\\n*)', assistant_response, 1, flags=re.DOTALL)\n",
    "                \n",
    "                if len(parts) >= 3:\n",
    "                    # Reconstruct with answer tags around the non-think portion\n",
    "                    reconstructed = parts[0] + parts[1] + f\"<answer>{parts[2].strip()}</answer>\"\n",
    "                    entry['assistant_response'] = reconstructed\n",
    "            else:\n",
    "                # No think tags found, leave as is\n",
    "                pass\n",
    "        \n",
    "        # Write the modified or original entry to output\n",
    "        outfile.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e32b5a-c163-4f1c-82c6-786b0af06bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed prompt1: Can you tell me a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt2: I need a quick bedtime story f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt3: Write a short story set in spa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt4: Gimme a story bout a detective... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt5: I'm looking for a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt6: Can you share a heartwarming s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt7: Tell me a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt8: I want a story about a magical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt9: Write a short story involving ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt10: Need a quick story for my clas... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt11: Can you create a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt12: I need a short story for my bl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt13: Tell me a story about a superh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt14: Write a short story set in a p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt15: I want a story about a talking... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt16: Can you share a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt17: Need a story for my kids. Some... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt18: Write a short story involving ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt19: I need a story about a scienti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt20: Tell me a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt21: Can you create a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt22: I want a story about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt23: Write a short story set in a f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt24: Need a quick story for my podc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt25: Can you share a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt26: Tell me a story about a young ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt27: Write a short story involving ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt28: I need a story about a small t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt29: Can you create a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt30: I want a story about a magical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt31: Write a short story set in anc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt32: Need a story for my students. ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt33: Can you share a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt34: Tell me a story about a heroic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt35: Write a short story involving ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt36: I need a story about a futuris... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt37: Can you create a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt38: I want a story about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt39: Write a short story set in a m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt40: Need a quick story for my news... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt41: Can you share a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt42: Tell me a story about a young ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt43: Write a short story involving ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt44: I need a story about a magical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt45: Can you create a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt46: I want a story about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt47: Write a short story set in a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt48: Need a story for my website. S... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt49: Can you share a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt50: Tell me a story about a young ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt51: Craft a short story about a li... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt52: Write a tale set in a bustling... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt53: Create a short story about a s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt54: Pen a narrative about a renown... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt55: Develop a short story centered... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt56: Compose a tale about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt57: Write a short story set in a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt58: Craft a narrative about a time... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt59: Create a short story about a h... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt60: Pen a tale about a young inven... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt61: Develop a short story set in a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt62: Compose a narrative about a sm... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt63: Write a short story about a gr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt64: Craft a tale about a young gir... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt65: Create a short story set in a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt66: Pen a narrative about a detect... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt67: Develop a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt68: Compose a tale about a photogr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt69: Write a short story set in a p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt70: Craft a narrative about a youn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt71: Create a short story about a s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt72: Pen a tale about a group of fr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt73: Develop a short story set in a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt74: Compose a narrative about a sm... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt75: Write a short story about a yo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt76: Craft a tale about a group of ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt77: Create a short story set in a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt78: Pen a narrative about a detect... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt79: Develop a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt80: Compose a tale about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt81: Write a short story set in a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt82: Craft a narrative about a smal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt83: Create a short story about a y... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt84: Pen a tale about a group of as... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt85: Develop a short story set in a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt86: Compose a narrative about a de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt87: Write a short story about a yo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt88: Craft a tale about a group of ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt89: Create a short story set in a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt90: Pen a narrative about a small-... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt91: Develop a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt92: Compose a tale about a group o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt93: Write a short story set in a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt94: Craft a narrative about a dete... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt95: Create a short story about a y... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt96: Pen a tale about a group of fr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt97: Develop a short story set in a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt98: Compose a narrative about a sm... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt99: Write a short story about a yo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt100: Craft a tale about a group of ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt101: write a story about a poor fis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt102: Need story for my trucker blog... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt103: As a CEO, I want allegorical t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt104: plz story 4 my 7yr old. girl a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt105: Request from Dr. Elena Torres ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt106: yo im high af rn need trippy s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt107: For Southern Gothic contest: D... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt108: Story needed ASAP!!! Grandma w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt109: I'm a janitor. Write story whe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt110: Prompt from MIT professor: Har... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt111: Story 4 my DnD group: Paladin ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt112: imigrant [sic] mother working ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt113: Boxer takes fall for crime he ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt114: For TikTok trend: #BookTok rom... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt115: retired english teacher wants ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt116: yo can u write a story where l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt117: Request from hospice nurse: El... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt118: Story for ESL students: Easy v... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt119: After 9/survivor guilt, woman ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt120: make story about sentient Walm... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt121: Hi! Im doing a creative writin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt122: Distinguished colleagues, I re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt123: yo can u write me smth about z... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt124: As part of my middle school En... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt125: Looking for a literary piece e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt126: help!!!! need story for my kid... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt127: Seeking assistance in developi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt128: can u write me a luv story but... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt129: Professional ghostwriter seeki... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt130: im trying 2 write sumthing sca... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt131: Requesting story development f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt132: hello can you write story abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 5\n",
      "Processed prompt133: URGENT! Need micro-fiction pie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt134: Distinguished members, I seek ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt135: hey can u write me a cool stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt136: Greetings. I require a technic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt137: need help writing bedtime stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt138: Looking to commission a noir-s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt139: hi!! writing contest at school... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt140: Seeking development of allegor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt141: OMG can u write me a story abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt142: Require technical narrative re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt143: need story 4 my youtube gaming... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt144: Hello! Working on my MFA thesi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt145: can u write scary story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt146: Requesting narrative developme... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt147: hi im trying to write somethin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt148: NEED STORY FOR BUSINESS PRESEN... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt149: yo fam need a dope story bout ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt150: Distinguished committee, reque... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt151: help! need story for kindergar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt152: Seeking development of transgr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt153: can u write me sumthing with l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt154: Looking for assistance craftin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt155: hi!! need cute romance story f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt156: Requesting development of hard... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt157: yo need story bout basketball ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt158: Distinguished colleagues, seek... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt159: can u write story about my dog... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt160: URGENT!! Need story for advert... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt161: hi im doing research on narrat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt162: Yo can u write something cool ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt163: Distinguished panel, requestin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt164: need story 4 my tiktok!! somet... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt165: Hello, seeking assistance deve... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt166: yo fam need story bout crypto ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt167: Looking for help crafting narr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt168: can u write me a story about f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt169: NEED STORY FOR CHURCH YOUTH GR... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt170: Distinguished faculty, request... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt171: hi can u write something funny... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt172: Seeking assistance crafting na... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt173: yo need ghost story but like m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt174: Looking to craft a multi-layer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt175: Seeking to develop a climate f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt176: Developing a psychological hor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt177: Crafting a speculative fiction... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt178: Developing an anthropological ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt179: Seeking to create a historical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt180: Looking to craft a narrative c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt181: Developing a piece about a mar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt182: Crafting a story set in a worl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt183: Seeking to develop a narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt184: Developing a piece centered ar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt185: Crafting a story about a botan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt186: Looking to develop a narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt187: Seeking to craft a piece about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt188: Developing a narrative about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt189: Crafting a story set in a near... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt190: Looking to develop a piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt191: Seeking to create a narrative ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt192: Developing a story about a xen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt193: Crafting a piece about a quant... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt194: Looking to develop a narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt195: Seeking to craft a story about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt196: Developing a piece about a for... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt197: Crafting a narrative about an ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt198: Looking to develop a story abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt199: Seeking to create a piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt200: Developing a narrative about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt201: Crafting a story about a digit... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt202: Looking to develop a piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt203: Seeking to craft a narrative a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt204: Developing a story about a con... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt205: Crafting a piece about a 'real... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt206: Developing a narrative centere... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt207: Seeking to craft a story about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt208: Looking to develop a piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt209: Crafting a narrative about a '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt210: Developing a speculative ficti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt211: Seeking to create a story abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt212: Looking to craft a narrative a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt213: Developing a piece about an 'i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt214: Crafting a story about a 'quan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt215: Seeking to develop a narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt216: Looking to create a piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt217: Developing a story about a 'dr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt218: Crafting a narrative about a '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt219: Seeking to develop a piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt220: Looking to craft a story about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt221: Developing a narrative about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt222: Crafting a piece about a 'temp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt223: Seeking to create a story abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt224: Looking to develop a narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt225: Developing a piece about a 'me... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt226: A disillusioned jazz pianist i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt227: In 1923 Shanghai, a blind qin ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt228: A retired Mexican luchador wor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt229: A Kyoto ikebana master’s flowe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt230: In a sentient, decaying space ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt231: A Parisian forger in 1943 pain... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt232: A transgender truck driver in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt233: In 1812 St. Petersburg, a Napo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt234: A deaf choreographer in 2070s ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt235: A Mumbai slum doctor discovers... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt236: In an Antarctic research stati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt237: A Blackfoot historian digitizi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt238: A suicidal AI programmer in 20... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt239: Hi! For my Creative Writing 10... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt240: Need help with my writing assi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt241: For my fiction workshop, we're... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt242: Working on my midterm story. T... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt243: Hey! Taking Intro to Creative ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt244: For my writing assignment, nee... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt245: Working on character sketches ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt246: Hi, doing a story for my ficti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt247: Need help with my creative wri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt248: For my writing class final, ne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt249: Working on flash fiction assig... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt250: Help with my fiction workshop ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt251: For creative writing class, ne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt252: Writing assignment about 'ever... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt253: Need story for workshop about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt254: Hi! Working on a piece about '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt255: Assignment for fiction writing... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt256: Need help with workshop story.... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt257: Writing class assignment about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt258: For my creative writing final,... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt259: Help with fiction workshop pie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt260: Need story for class about 'di... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt261: Working on piece about 'family... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt262: Assignment needs to be about '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt263: Hi! Need help with story about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt264: Fiction workshop assignment ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt265: Creative writing homework: sto... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt266: Need help with workshop piece ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt267: Writing assignment about 'tran... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt268: For fiction class, need story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt269: Help with creative writing pie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt270: Workshop story needs to be abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt271: Assignment for writing class: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt272: Need help with fiction piece a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt273: Creative writing assignment ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt274: Working on story about 'decisi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt275: Hi! Need story about 'change' ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt276: Fiction workshop piece about '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt277: Writing assignment about 'hope... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt278: Need help with story about 'lo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt279: Workshop story about 'secrets.... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt280: Assignment needs story about '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt281: Help with fiction piece about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt282: Creative writing assignment ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt283: Need story for workshop about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt284: Writing class assignment about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt285: Hi! Need help with story about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt286: Assignment about 'changes.' Ne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt287: Need workshop story about 'fam... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt288: Creative writing piece about '... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt289: Help with fiction assignment a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt290: Could you write a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt291: hi, can u write me a short sto... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt292: Please craft a two-paragraph s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt293: i need a short story about a l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt294: Hey there. I'm teaching Englis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt295: can you make me a short fictio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt296: Requesting a short story that ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt297: I want a really short story, j... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt298: hello plz short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt299: Could I see a whimsical, magic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt300: Yo can u giv me a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt301: Please craft a story (250–300 ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt302: I'm a middle school teacher. I... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt303: could you do a short, moody pi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt304: write short story, plz. about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt305: I'd love a mystery short story... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt306: I want a short story that high... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt307: make me a short story in the s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt308: A short, tense thriller about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt309: Hello. I would appreciate a sh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt310: i want a real quick short stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 6\n",
      "Processed prompt311: I need a very descriptive shor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt312: Could you write a short comedi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt313: Looking for a lighthearted tal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt314: Pls do a short story about an ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt315: Dear Writer, can you deliver a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt316: A short story in which a chef ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt317: im bored can u do a short stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt318: I need a short piece about a f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt319: Plz can i hav a short story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt320: I’d like a short story about t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt321: Short story request: a retired... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt322: Make me a brief comedic story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt323: I want a short story about the... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt324: pwease do a short stroy about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt325: Could you write a short philos... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt326: A short story about a family l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt327: I want a short, romantic tale ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt328: need a story about a medieval ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt329: Could you do a short coming-of... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt330: write me a short story about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt331: plz short story about a haunte... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt332: Hello, I'd like a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt333: I want a brief comedic story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt334: Could you craft a short fantas... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt335: Short story request: a hidden ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt336: hello can u do a short comedic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt337: I need a short story set in ou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt338: Could you write a short noir-i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt339: i want a short adventure story... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt340: I am preparing a collection of... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt341: Could you write a richly detai... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt342: I'm seeking a short story that... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt343: Construct a short story revolv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt344: I want a deeply atmospheric sh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt345: Compose a short story about tw... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt346: I would love a short narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt347: Could you create a gripping sh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt348: I'm looking for a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt349: Please craft a thoughtful and ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt350: I'd like a poignant short tale... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt351: Please spin a short story abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt352: I'm envisioning a psychologica... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt353: Could you write a multi-layere... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt354: I need a short story that meld... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt355: Create a dark fantasy short st... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt356: Compose a tale of exploration ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt357: I'm looking for a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt358: Could you write a story blendi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt359: I desire a short story that ta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt360: Please craft a tale of redempt... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt361: I'm commissioning a short piec... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt362: Could you spin a reflective, c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt363: I would love a short story abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt364: Construct a bittersweet narrat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt365: I'd like a whimsical yet profo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt366: Please write a story set in a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt367: I'm seeking a short story abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt368: Compose a narrative set in an ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt369: I want a short story told from... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt370: Could you craft a melancholy s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt371: I would love a short fantasy p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt372: Compose a transformative story... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt373: I'm looking for a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt374: Please write an exhilarating s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt375: I'd love a narrative about a t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt376: Could you create a short story... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt377: I want a dreamlike short story... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt378: Please craft a narrative set i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt379: Write a short story about a hi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt380: I'm seeking a lyrical, evocati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt381: Please conjure a short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt382: Could you compose a tale invol... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt383: I'm envisioning a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt384: Please write a narrative that ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt385: Craft a haunting short story a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt386: I'd like a suspenseful short s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt387: Compose a touching narrative a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt388: I need a short story exploring... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt389: Finally, I'd love a richly det... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt390: As a high school English teach... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt391: I'm a busy parent looking for ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt392: I'm a sci-fi enthusiast and I'... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt393: As a therapist, I often use st... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt394: I'm a history buff and I love ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt395: I'm a blogger focusing on insp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt396: I'm a college student studying... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt397: As a mystery lover, I'm always... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt398: I'm a fantasy writer looking f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt399: I'm a podcast host and I need ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a data folder if it doesn't exist.\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# File paths for user prompts and generated data.\n",
    "USER_PROMPTS_FILE = \"../data/user_prompts.jsonl\"\n",
    "OUTPUT_FILE = \"../data/generated_data.jsonl\"\n",
    "\n",
    "# --- Define a function to load prompts from a JSONL file ---\n",
    "def load_user_prompts(filename: str):\n",
    "    prompts = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"prompt\" in obj:\n",
    "                    prompts.append(obj[\"prompt\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return prompts\n",
    "\n",
    "# --- Example list of generator models ---\n",
    "generator_models = [\n",
    "    # \"mistral/mistral-small-latest\",\n",
    "    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    # \"openai/gpt-4o\"\n",
    "    # \"together_ai/google/gemma-2b-it\"\n",
    "    # \"ollama/qwen:1.8b\"\n",
    "    # \"ollama/mistral\"\n",
    "    # Reasoning models\n",
    "    # \"groq/deepseek-r1-distill-llama-70b\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    # \"ollama/deepseek-r1:1.5b\"\n",
    "    # \"ollama/deepseek-r1:7b\"\n",
    "]\n",
    "\n",
    "# Define the scorer model name (used by the JokeScorer) and instantiate it.\n",
    "scorer_model_name = \"groq/deepseek-r1-distill-llama-70b\" # \"openai/gpt-4o\"\n",
    "task_type = \"creative_writing\"\n",
    "scorer = ShortStoryScorer(model_name=scorer_model_name, temperature=0.0)\n",
    "\n",
    "# Instantiate the FormatScorer (for format checking)\n",
    "format_scorer = FormatScorer()\n",
    "\n",
    "# --- Main loop: For each prompt and for each generation model, generate a joke, evaluate it, and append the result ---\n",
    "def generate_and_score():\n",
    "    # Load user prompts (each line in the file should be a JSON object with a \"prompt\" field)\n",
    "    user_prompts = load_user_prompts(USER_PROMPTS_FILE)\n",
    "    \n",
    "    i = 0\n",
    "    for prompt in user_prompts:\n",
    "        for gen_model in generator_models:\n",
    "            i += 1\n",
    "            # if i < 743:\n",
    "            #     continue\n",
    "            # Create a JokeGenerator instance for this generation model.\n",
    "            generator = ShortStoryGenerator(model_name=gen_model, temperature=0.5)\n",
    "            # generator = UniversalGenerator(model_name=gen_model, temperature=0.7)\n",
    "            \n",
    "            # Generate the joke for the given prompt.\n",
    "            # system_prompt = \"Generate humorous responses tailored to each user's unique request by analyzing their stated context, preferred tone, and implied audience. Please think step by step before to produce the final joke.\"\n",
    "            # system_prompt = \"For each ethical dilemma, analyze the implications by identifying key stakeholders, examining core principles in tension, considering consequences, and evaluating different philosophical frameworks. Develop a balanced, nuanced response that acknowledges the complexity of the situation while providing practical insights and potential paths forward.\"\n",
    "            # assistant_response = generator.generate(system_prompt=system_prompt, user_prompt=prompt)\n",
    "            assistant_response = generator.generate(prompt)\n",
    "\n",
    "            # Compute the format score using the FormatScorer.\n",
    "            fmt_score = format_scorer.score(assistant_response)\n",
    "            \n",
    "            # If scoring fails, we set the joke score to None.\n",
    "            try:\n",
    "                llm_score = scorer.score_submission(prompt, assistant_response)\n",
    "            except Exception as e:\n",
    "                print(f\"Scoring failed for prompt: {prompt} with error: {e}\")\n",
    "                llm_score = None\n",
    "            \n",
    "            # Create a record with all the relevant information.\n",
    "            record = {\n",
    "                \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                \"user_prompt\": prompt,\n",
    "                \"assistant_response\": assistant_response,\n",
    "                \"format_score\": fmt_score,\n",
    "                \"llm_score\": llm_score,\n",
    "                \"generator_model\": gen_model,\n",
    "                \"scorer_model\": scorer_model_name,\n",
    "                \"task_type\": task_type\n",
    "            }\n",
    "            \n",
    "            # Append the record as a new line in the output ljson file.\n",
    "            with open(OUTPUT_FILE, \"a\") as out_f:\n",
    "                out_f.write(json.dumps(record) + \"\\n\")\n",
    "            \n",
    "            # Optionally, print a status update.\n",
    "            print(f\"Processed prompt{i}: {prompt[:30]}... using model: {gen_model}. Score: {llm_score}\")\n",
    "\n",
    "# Run the generation-and-scoring function (one generation at a time).\n",
    "generate_and_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d0b0e-b8a4-40ab-a434-1d55b161d414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
