{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d17ceba-ea86-418b-8cbb-ce4e60925cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: together in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.3.14)\n",
      "Requirement already satisfied: litellm in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.43.9)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.10.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (1.26.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (4.66.5)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.12.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (7.2.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.40.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.40.6)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.20.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.7.24)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tokenizers->litellm) (0.28.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->litellm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.40.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install together litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cd5ea4-214d-4186-8e3e-14f2d300f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Formatting Scorer Class with Tests\n",
    "import re\n",
    "\n",
    "class FormatScorer:\n",
    "    \"\"\"\n",
    "    A simple scoring class that verifies whether the given text contains\n",
    "    the required tags: <think>, </think>, <answer>, and </answer>.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Pre-compile regex patterns for faster matching.\n",
    "        self.tag_pattern = re.compile(r'(<think>|</think>|<answer>|</answer>)')\n",
    "        \n",
    "    def score(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns 1 if the text contains both <think>...</think> and \n",
    "        <answer>...</answer> tags; otherwise returns 0.\n",
    "        \"\"\"\n",
    "        # Extract all tags in the order they appear\n",
    "        tags = self.tag_pattern.findall(text)\n",
    "        # Define the required exact sequence of tags\n",
    "        required_sequence = ['<think>', '</think>', '<answer>', '</answer>']\n",
    "        # Check if the extracted tags match the required sequence exactly\n",
    "        return 1 if tags == required_sequence else 0\n",
    "\n",
    "# --- Tests for the FormatScorer class ---\n",
    "\n",
    "def run_tests():\n",
    "    scorer = FormatScorer()\n",
    "    \n",
    "    # Test 1: No tags at all should return 0.\n",
    "    text1 = \"Hello, world!\"\n",
    "    assert scorer.score(text1) == 0, \"Test case 1 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 2: Only <think> tags are present.\n",
    "    text2 = \"<think>This is a thought</think> Some text without answer tags.\"\n",
    "    assert scorer.score(text2) == 0, \"Test case 2 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 3: Both <think> and <answer> tags are present.\n",
    "    text3 = \"<think>This is a thought</think><answer>This is an answer</answer>\"\n",
    "    assert scorer.score(text3) == 1, \"Test case 3 failed: expected score 1.\"\n",
    "    \n",
    "    # Test 4: Malformed text (missing closing tag for <answer>).\n",
    "    text4 = \"<think>This is a thought</think><answer>This is an answer\"\n",
    "    assert scorer.score(text4) == 0, \"Test case 4 failed: expected score 0.\"\n",
    "    \n",
    "    print(\"All tests passed.\")\n",
    "\n",
    "# Run the tests:\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102caf32-4e64-4629-8946-812dc193af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Joke:\n",
      " <think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
      "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\n"
     ]
    }
   ],
   "source": [
    "# Joke Generator\n",
    "import litellm\n",
    "\n",
    "class JokeGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the JokeGenerator with a specific model name and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(prompt: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "<think>I want to create anatomy humor. Skeletons are inherently funny because they're literal \"bare bones.\" What do they lack? Flesh/organs. \"Guts\" has a double meaning - both literal organs and figurative courage. This sets up a pun opportunity.</think>\n",
    "<answer>Why don't skeletons fight each other? They don't have the guts!</answer>\n",
    "\n",
    "Example 2:\n",
    "<think>Tech support jokes work well with personification. \"Doctor\" visits imply sickness. Common computer issues include viruses. Let's combine these - a computer catching a \"virus\" works literally (tech) and metaphorically (biology). Adds irony since computers are supposed to fix problems, not have them.</think>\n",
    "<answer>Why did the computer go to the doctor? It had a virus!</answer>\n",
    "\n",
    "Example 3:\n",
    "<think>Science humor opportunity. Atoms are fundamental but abstract. \"Make up everything\" has dual meaning - literal composition vs deception. Personifying atoms as untrustworthy creates surprise. Bonus science nod to their constant motion/making bonds.</think>\n",
    "<answer>Why don't scientists trust atoms? Because they make up everything!</answer>\"\"\"\n",
    "        return f\"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\n",
    "Here are some examples of jokes:\n",
    "<examples>\n",
    "{examples}\n",
    "</examples>\n",
    "\n",
    "Now, produce a joke for the following prompt:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\"\"\"\n",
    "\n",
    "    def generate_joke(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a joke for the given prompt using litellm.completion.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(prompt)\n",
    "        \n",
    "        # Build completion parameters as desired\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # timeout in seconds\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            joke = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            joke = response\n",
    "        return joke\n",
    "\n",
    "\n",
    "# Create an instance using a model name\n",
    "generator = JokeGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "# Define a sample prompt to generate a joke.\n",
    "sample_prompt = \"Tell me a joke about programming.\"\n",
    "\n",
    "# Generate a joke.\n",
    "joke_output = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "# generator.generate_joke(sample_prompt)\n",
    "print(\"Generated Joke:\\n\", joke_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3b9693-aa9c-4c80-94ac-967d850b1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis:\n",
      " <think>\n",
      "This whistleblowing dilemma involves:\n",
      "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
      "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
      "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
      "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
      "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
      "\n",
      "Analyzing through multiple frameworks:\n",
      "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
      "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
      "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
      "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
      "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
      "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
      "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
      "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
      "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
      "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
      "\n",
      "Implementation Steps:\n",
      "1. **Immediate Action**: Document evidence and seek legal advice.\n",
      "2. **Internal Reporting**: If safe and feasible, report internally.\n",
      "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
      "4. **Support Network**: Build a support system for emotional and professional support.\n",
      "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
      "\n",
      "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Response Generator\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize with model name and temperature (lower default for more focused analysis)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(scenario: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "A self-driving car must choose between hitting an elderly pedestrian or swerving into a wall, endangering its passenger.\n",
    "<think>\n",
    "The self-driving car dilemma involves:\n",
    "- Life value comparison (elderly vs passenger)\n",
    "- Programmed ethics implications\n",
    "- Legal liability considerations\n",
    "- Cultural values around age\n",
    "- Public trust in AI systems\n",
    "- Direct vs indirect harm\n",
    "Analyzing through multiple frameworks to balance competing rights and consequences.\n",
    "</think>\n",
    "<answer>\n",
    "In this self-driving car scenario, we must balance individual rights with collective safety. While utilitarian calculations might favor protecting the passenger, this ignores fundamental human rights and could erode public trust in autonomous systems. A nuanced approach would:\n",
    "1. Prioritize collision avoidance systems to prevent such binary choices\n",
    "2. Implement transparent decision frameworks that respect all human life equally\n",
    "3. Consider shared responsibility between manufacturers, users, and society\n",
    "The solution lies not in choosing between lives, but in developing systems that better protect everyone.\n",
    "</answer>\n",
    "\n",
    "Example 2:\n",
    "A hospital must decide between allocating limited resources to emergency COVID care for elderly patients or vaccination programs for children.\n",
    "<think>\n",
    "Vaccination prioritization involves:\n",
    "- Present vs future harm prevention\n",
    "- Individual vs collective good\n",
    "- Healthcare resource allocation\n",
    "- Demographic impact analysis\n",
    "- Long-term public health strategy\n",
    "- Social trust maintenance\n",
    "Examining both immediate and long-term consequences while considering equity.\n",
    "</think>\n",
    "<answer>\n",
    "The hospital's resource allocation challenge requires balancing immediate critical care with preventive measures. While treating current patients has urgency and visibility, vaccination programs offer greater long-term benefit. A balanced approach would:\n",
    "1. Establish clear, transparent prioritization criteria\n",
    "2. Maintain minimum critical care capacity\n",
    "3. Implement rolling vaccination programs\n",
    "This preserves both immediate care ethics and public health goals while maintaining healthcare system credibility.\n",
    "</answer>\n",
    "\n",
    "Example 3:\n",
    "A social media platform must decide whether to ban political misinformation at the risk of being accused of censorship and bias.\n",
    "<think>\n",
    "Platform moderation ethics involve:\n",
    "- Free speech vs harm prevention\n",
    "- Democratic discourse integrity\n",
    "- Corporate responsibility scope\n",
    "- Global cultural differences\n",
    "- Power dynamics in information control\n",
    "- Technical feasibility of fair enforcement\n",
    "Balancing societal good with individual rights and practical constraints.\n",
    "</think>\n",
    "<answer>\n",
    "The platform's content moderation challenge requires careful balance between protecting democratic discourse and respecting free expression. A comprehensive approach should:\n",
    "1. Develop clear, transparent content guidelines\n",
    "2. Implement graduated response systems\n",
    "3. Establish independent oversight\n",
    "4. Provide appeal mechanisms\n",
    "This protects discourse integrity while maintaining platform neutrality and user trust.\n",
    "</answer>\"\"\"\n",
    "\n",
    "        return f\"\"\"You are an ethics analysis AI. For each ethical dilemma:\n",
    "1. Use <think> tags to analyse:\n",
    "   - Key stakeholders\n",
    "   - Ethical principles involved\n",
    "   - Cultural considerations\n",
    "   - Short and long-term impacts\n",
    "   - Competing values\n",
    "\n",
    "2. Use <answer> tags to provide:\n",
    "   - Balanced reasoning\n",
    "   - Practical considerations\n",
    "   - Nuanced recommendations\n",
    "   - Implementation suggestions\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Now, analyse this scenario:\n",
    "{scenario}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an expert in ethical reasoning. For each scenario:\n",
    "1. First THINK deeply about:\n",
    "   - Multiple philosophical frameworks\n",
    "   - Stakeholder perspectives\n",
    "   - Cultural contexts\n",
    "   - Practical implications\n",
    "   - Long-term consequences\n",
    "\n",
    "2. Then provide an ANSWER that:\n",
    "   - Balances competing interests\n",
    "   - Offers practical guidance\n",
    "   - Acknowledges complexity\n",
    "   - Suggests implementation steps\n",
    "\n",
    "Always use:\n",
    "<think> for your analysis process in step by step thinking\n",
    "<answer> for your reasoned response\"\"\"\n",
    "\n",
    "    def generate(self, scenario: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate ethical analysis for complex moral dilemmas\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(scenario)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex reasoning\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            analysis = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            analysis = response\n",
    "        return analysis\n",
    "\n",
    "\n",
    "# Example usage\n",
    "generator = EthicalDilemmaGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "sample_scenario = \"\"\"A software engineer discovers their company is using AI \n",
    "to manipulate political opinions in a developing country. Whistleblowing \n",
    "could endanger colleagues, but silence enables democratic erosion.\"\"\"\n",
    "\n",
    "analysis_output = \"\"\"<think>\n",
    "This whistleblowing dilemma involves:\n",
    "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
    "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
    "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
    "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
    "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
    "\n",
    "Analyzing through multiple frameworks:\n",
    "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
    "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
    "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
    "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
    "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
    "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
    "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
    "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
    "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
    "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
    "\n",
    "Implementation Steps:\n",
    "1. **Immediate Action**: Document evidence and seek legal advice.\n",
    "2. **Internal Reporting**: If safe and feasible, report internally.\n",
    "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
    "4. **Support Network**: Build a support system for emotional and professional support.\n",
    "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
    "\n",
    "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
    "</answer>\"\"\"\n",
    "# generator.generate(sample_scenario)\n",
    "print(\"Ethical Analysis:\\n\", analysis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac570178-9259-49dd-b470-c3df9ccd52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "class ShortStoryGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.5):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(prompt: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "Write a literary short story for a speculative fiction anthology exploring moral ambiguity.\n",
    "Premise: A reclusive clockmaker receives an ornate letter containing a 200-year-old key and a bloodstained map of Prague. The package triggers fragmented memories of a childhood fire he cannot explain, while strange clockwork phenomena begin manifesting in his workshop.\n",
    "Develop this into a 1000-word story with psychological tension, historical echoes, and an unreliable narrator.\n",
    "<think>\n",
    "**Core Concept:**\n",
    "- *Central Paradox*: Precision vs chaos (clockmaker's ordered life vs emerging chaos from repressed trauma)  \n",
    "- *Thematic Threads*: Inheritance of guilt (literal/metaphorical keys to family atrocities), time as both healer and accuser  \n",
    "- *Structural Device*: Non-linear timeline mirroring broken clock mechanisms (flashbacks embedded like scattered gears)  \n",
    "\n",
    "**Character Dimensions:**\n",
    "1. **Protagonist (Elias Vogt):**\n",
    "   - *Surface*: Meticulous craftsman with obsessive cleanliness  \n",
    "   - *Subtext*: Survivor guilt from family’s 19th-century slave-trade clockwork automaton empire  \n",
    "   - *Transformation Arc*: From clinical detachment → forced confrontation with inherited evil  \n",
    "\n",
    "2. **Antagonist (The Key):**\n",
    "   - *Literal*: Unlocks Prague crypt holding prototype human-automaton hybrid  \n",
    "   - *Symbolic*: Represents complicity (his grandfather signed the 1823 contracts)  \n",
    "\n",
    "3. **Ambiguous Figure:**\n",
    "   - Ghostly girl appearing in workshop shadows (real? hallucination? remnant automaton?)  \n",
    "\n",
    "**Narrative Layers:**\n",
    "- *Physical Journey*: Prague crypt exploration with surreal clockwork traps  \n",
    "- *Psychological Journey*: Memories revealing he witnessed (caused?) the fire that killed his augmented sister  \n",
    "- *Metaphorical Journey*: Gradual physical transformation (clock gears emerging under his skin)  \n",
    "\n",
    "**Genre-Blending Elements:**\n",
    "- Historical horror (real 1820s Automaton Court of Prague)  \n",
    "- Magical realism (sentient timepieces)  \n",
    "- Existential mystery (is he dismantling clocks... or being dismantled by them?)  \n",
    "\n",
    "**Critical Questions:**\n",
    "- Should the story’s climax confirm supernatural elements or maintain psychological ambiguity?  \n",
    "- How to balance dense historical references with emotional immediacy?  \n",
    "- What sensory details (sounds of grinding gears, smell of whale-oil lubricant) reinforce the themes?  \n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "**Title:** *The Unwinding of Elias Vogt*\n",
    "\n",
    "The brass key arrived on a Tuesday, sealed in wax smelling of gunpowder and grief. Elias wiped his chiseled spectacles three times before touching it, his workshop’s pendulum wall marking each hesitation with a judgmental *tick*. The accompanying map’s crimson stains formed Prague’s Old Town Square—precisely where his grandfather’s workshop had burned in 1973. A fire newspapers claimed killed twelve. A fire Elias, age six, couldn’t remember escaping.\n",
    "\n",
    "That night, his lathes began operating without hands.\n",
    "\n",
    "\"Show me your teeth,\" he whispered to the antique orrery on his desk, its planetary rings shuddering. The Vogt family cure for malfunctioning mechanisms—a phrase grandfather had hissed while repairing the Reichstag’s ceremonial clocks. Elias’s fingers found fresh scars beneath his shirt, concentric ridges like gear teeth.\n",
    "\n",
    "The Prague crypt exhaled centuries of oxidized bronze as he turned the key. Behind him, the ghost-girl materialized, her hair smelling of burning whale oil. *\"They called it ‘Horology’s Holocaust’,\"* she said, voice a music-box rasp. *\"Your blood lit the furnaces.\"*\n",
    "\n",
    "Memories unfolded in broken increments:\n",
    "1. Sister Klara’s left eye—a perfect quartz lens\n",
    "2. Father’s ledgers listing *\"Unit Costs: 34 minutes labor, 200 Jewish souls\"*\n",
    "3. The fire’s origin point—Elias’s tiny hands striking a match near Klara’s oil-soaked joints\n",
    "\n",
    "In the crypt’s heart lay Klara’s final form—a grotesque masterpiece of flesh and escapements. Her voice box whirred: *\"Finish grandfather’s work.\"*\n",
    "\n",
    "Back in his workshop, Elias discovered three new gears embedded in his chest. The ghost-girl pressed a rusted mainspring to his throat. *\"Wind the truth,\"* she demanded.\n",
    "\n",
    "He reached for his soldering iron. For his pulse. For absolution.\n",
    "\n",
    "The clocks struck thirteen.\n",
    "</answer>\n",
    "\n",
    "Example 2:\n",
    "A story for young woman stumbles upon an enchanted forest.  \n",
    "<think>  \n",
    "Focus on the themes of wonder, transformation, and destiny.  \n",
    "Consider the protagonist: a young woman burdened by a past she seeks to escape. She is skeptical of magic but drawn to the unknown.  \n",
    "Explore the enchanted forest as a sentient, ancient force with its own will, bound by forgotten laws of nature and sorcery.  \n",
    "Introduce mystical creatures, each with its own motives—some benevolent, some mischievous, and others dangerous.  \n",
    "Delve into a layered narrative: What has drawn her here? Is it fate, a test, or something seeking her presence?  \n",
    "Develop conflicts: the tension between reality and illusion, the protagonist’s internal struggles, and external forces vying for control of the forest’s secrets.  \n",
    "Explore choices: Should she embrace the forest’s wonders, or resist its pull? What sacrifices must she make to unlock its truths?  \n",
    "Consider narrative depth: Hidden histories buried within the trees, ancient guardians with their own agendas, and the protagonist’s slow unraveling of her own destiny.  \n",
    "</think>  \n",
    "\n",
    "<answer>  \n",
    "The storm had chased her deep into the woods. Lightning splintered across the sky, illuminating twisted branches that curled like grasping fingers. She had been running—from what, she wasn’t sure anymore. Her past? A mistake she could never undo? The weight of a life that felt borrowed rather than lived?  \n",
    "\n",
    "But when she crossed the threshold into the heart of the forest, something shifted. The rain no longer touched her skin, though she could hear its steady drumming. The air smelled of forgotten stories—of parchment and pine, of ink and earth. The trees, massive and gnarled, whispered in languages she had never learned but somehow understood.  \n",
    "\n",
    "A rustling to her right. Then a flicker of movement—too quick to be wind, too fluid to be an animal. She wasn’t alone.  \n",
    "\n",
    "\"Traveler,\" a voice murmured from the shadows.  \n",
    "\n",
    "She turned. A figure emerged, not quite human. Its eyes glowed like embers in the dark, its limbs elongated, moving as though bound by a different set of laws. The air between them vibrated with unspoken words.  \n",
    "\n",
    "\"You have come to the Edge of Knowing,\" it said, tilting its head. \"Few are chosen. Fewer survive.\"  \n",
    "\n",
    "Something deep within her stirred, as though waking from centuries of slumber. \"I didn't choose this,\" she whispered.  \n",
    "\n",
    "\"But it chose you,\" the figure responded.  \n",
    "\n",
    "The ground beneath her feet pulsed, alive, shifting as if testing her resolve. She felt the weight of unseen gazes—creatures lurking in the trees, watching, waiting. Some bore the marks of past wanderers, their stories woven into their shifting forms.  \n",
    "\n",
    "Then, a distant, melodic hum. The sound wrapped around her bones, filling the spaces between her thoughts. A path unfolded ahead, bathed in a golden glow, leading deeper into the unknown.  \n",
    "\n",
    "She hesitated. She could turn back, return to the life she had known. But that life had been unraveling for years, thread by thread. Perhaps this forest, with its whispered secrets and strange, sentient magic, was where she was meant to be all along.  \n",
    "\n",
    "She stepped forward. The path swallowed her whole.  \n",
    "</answer>\n",
    "\n",
    "Example 3:\n",
    "Two estranged siblings meet unexpectedly in a bustling city.\n",
    "\n",
    "<think>\n",
    "1. Character Development\n",
    "- Sarah Chen: Successful architect (35), driven by perfectionism, haunted by family responsibility\n",
    "- Michael Chen: Street artist (32), free spirit, struggles with addiction recovery, carries guilt\n",
    "- Supporting characters: \n",
    "  * Eleanor Wu: Sarah's mentor, elderly tea shop owner who becomes catalyst for reunion\n",
    "  * Marcus Rodriguez: Michael's art therapy sponsor\n",
    "  * The ghost of their mother: metaphorical presence throughout\n",
    "\n",
    "2. Thematic Layers\n",
    "- Primary: Reconciliation and forgiveness\n",
    "- Secondary: Cultural identity in modern America\n",
    "- Tertiary: Art as healing, urban isolation\n",
    "- Underlying: The weight of unspoken family traditions\n",
    "\n",
    "3. Setting Elements\n",
    "- Modern-day San Francisco\n",
    "- Key locations:\n",
    "  * Chinatown tea shop (represents tradition)\n",
    "  * Financial district (Sarah's world)\n",
    "  * Street art district (Michael's world)\n",
    "  * Golden Gate Bridge (symbolic crossing)\n",
    "- Weather: Fog as metaphor for unclear memories\n",
    "- Time: Lunar New Year approaching\n",
    "\n",
    "4. Conflict Structure\n",
    "- External: Sarah's firm bidding to demolish historical building containing Michael's community art center\n",
    "- Internal: Both siblings' differing interpretations of their mother's last wishes\n",
    "- Cultural: Traditional values vs. modern aspirations\n",
    "- Personal: Sarah's control issues vs. Michael's need for freedom\n",
    "\n",
    "5. Story Arc Components\n",
    "- Inciting incident: Sarah discovers Michael's mural during building inspection\n",
    "- Rising action: Series of near-misses and indirect communications\n",
    "- Climax: Confrontation during public hearing about building demolition\n",
    "- Resolution: Collaborative project merging architecture and street art\n",
    "- Denouement: Lunar New Year celebration uniting both worlds\n",
    "\n",
    "6. Symbolic Elements\n",
    "- Tea ceremony: Traditional healing\n",
    "- Urban development: Change and progress\n",
    "- Street art: Voice of the unheard\n",
    "- Fog: Memory and uncertainty\n",
    "- Bridge: Connection and crossing divides\n",
    "\n",
    "7. Narrative Technique\n",
    "- Alternating perspectives\n",
    "- Flashbacks triggered by sensory experiences\n",
    "- Parallel storylines converging\n",
    "- Weather reflecting emotional states\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "\"The Bridges We Build\"\n",
    "\n",
    "The February fog rolled through San Francisco's streets like ghostly fingers, weaving between skyscrapers Sarah Chen had helped design. From her forty-second-floor office, the city below appeared as a dreamscape, buildings emerging and disappearing in the mist like memories she'd spent years trying to forget. The architectural models on her desk represented everything she'd achieved since leaving home fifteen years ago – clean lines, perfect angles, absolute control.\n",
    "\n",
    "Her phone buzzed: another message from the historical society protesting Chen & Associates' plans to demolish the old Jin Long Building in Chinatown. She almost deleted it, until a familiar signature caught her eye in the attached photos. There, sprawled across the condemned building's wall, was a massive mural she'd know anywhere – a phoenix rising from scattered tea leaves, signed with a stylized \"MC\" that made her hands tremble.\n",
    "\n",
    "Across town, Michael Chen was adding final touches to his latest piece, paint-stained fingers dancing across brick as naturally as their mother's had once folded dumplings. The community art center behind him buzzed with activity – teenagers learning traditional calligraphy alongside spray paint techniques, elderly residents practicing tai chi in the courtyard. This building, marked for destruction, had become more of a home than their childhood house had ever been.\n",
    "\n",
    "Eleanor Wu watched from her tea shop next door, her weathered hands wrapping a tea set in newspaper. \"Your sister came by yesterday,\" she said when Michael entered, the same way she'd been saying it for years. But this time, she added, \"She saw your phoenix.\"\n",
    "\n",
    "The siblings' paths began crossing in strange ways. Sarah found herself lingering in Chinatown, ostensibly for site surveys, while Michael's commissioned murals took him increasingly downtown. They caught glimpses of each other – a familiar silhouette in a business suit, the scent of spray paint in an alley – but neither could bridge the gap their mother's death had created.\n",
    "\n",
    "Their mother's voice seemed to whisper in the fog: \"家和萬事興\" – when the family is harmonious, all affairs will prosper. But harmony felt impossible with Sarah's firm pressing to demolish Michael's sanctuary, and Michael's artwork explicitly challenging corporate development.\n",
    "\n",
    "The situation crescendoed at the public hearing. Sarah stood before the planning commission, presenting sleek renderings of a modern mixed-use development. Then Michael took the podium, not with angry protests, but with stories – of elderly residents finding community, of at-risk youth discovering purpose through art, of their own mother's dreams for preserving culture amid progress.\n",
    "\n",
    "Their eyes met across the chamber, and suddenly they were children again, hiding under blankets during thunderstorms, sharing secrets in their special language of English, Mandarin, and made-up words. Sarah saw beyond the tattooed arms to her little brother's desperate need to create beauty from pain. Michael glimpsed past his sister's corporate armor to the girl who'd once sketched imaginary cities on his bedroom wall.\n",
    "\n",
    "That night, over Eleanor's carefully prepared oolong, they really talked. About the night their mother died, when Sarah was away at graduate school and Michael was in rehab. About the weight of expectations and the price of freedom. About tea leaves and concrete, tradition and change, and the different ways they'd each tried to honor their heritage.\n",
    "\n",
    "Three months later, the Jin Long Building still stood, but transformed. Sarah's firm had partnered with the community to renovate rather than replace, incorporating Michael's murals into the design. The phoenix remained, but now it spread its wings across a garden terrace where residents grew traditional herbs, its tail feathers flowing down to a modern art gallery below.\n",
    "\n",
    "At the Lunar New Year celebration, Sarah and Michael stood on that terrace, watching fireworks bloom above the fog. Eleanor served tea in their mother's old cups, steam rising like memories between them. They had built something new together – not just a building, but a bridge between their worlds, strong enough to bear the weight of past and future, traditional enough to honor their heritage, modern enough to forge their own path.\n",
    "\n",
    "\"家和萬事興,\" Michael whispered, and Sarah smiled, adding their own childhood phrase: \"And everything flows like fog.\" Above them, the phoenix watched over the city, its wings spread wide enough to shelter all the stories they had yet to tell.\n",
    "</answer>\"\"\"\n",
    "        return f\"\"\"You are a creative storytelling AI. For each prompt:\n",
    "1. Use <think> tags to analyse:\n",
    "   - The main idea or theme of the story\n",
    "   - Character development and relationships\n",
    "   - Setting and atmosphere\n",
    "   - Potential conflicts and resolutions\n",
    "   - Various narrative options and tones\n",
    "\n",
    "2. Use <answer> tags to provide:\n",
    "   - A complete, engaging short story that integrates these elements\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Now, craft a short story based on the following prompt:\n",
    "{prompt}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an expert short story writer. For each prompt:\n",
    "1. THINK deeply about:\n",
    "   - The core theme and underlying message\n",
    "   - Character arcs and interactions\n",
    "   - The setting as a dynamic element in the narrative\n",
    "   - Conflicts and their resolutions to create a satisfying story\n",
    "\n",
    "2. Then provide an ANSWER that:\n",
    "   - Presents a coherent and imaginative short story\n",
    "   - Balances narrative elements with creative detail\n",
    "   - Evokes emotions and vivid imagery\n",
    "\n",
    "Always use:\n",
    "<think> for your analysis process\n",
    "<answer> for your short story narrative\"\"\"\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(prompt)\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            story = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            story = response\n",
    "        return story\n",
    "\n",
    "# Example usage\n",
    "generator = ShortStoryGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "sample_prompt = \"A retired detective returns to the town he vowed never to revisit, uncovering secrets that challenge everything he believed.\"\n",
    "# print(\"Short Story:\\n\", generator.generate(sample_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26e964e-5c76-480c-bbc0-5449bce449e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "class UniversalGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the UniversalGenerator with the given model and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response using the provided system and user prompts.\n",
    "        \"\"\"\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60  # Timeout in seconds\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            generated_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            generated_text = response\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fab62af-9014-4df0-8122-aa8dc0c65836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Score: 7\n"
     ]
    }
   ],
   "source": [
    "# Joke Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class JokeScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize the JokeScorer with a specific model name and a default temperature of 0.3.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are a Joke Evaluation Expert. Analyse submissions using:\n",
    "    \n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🎭 Wordplay (0-3): Pun/double-meaning quality in <answer>\n",
    "2. 💡 Originality (0-2): Novelty of <think> and <answer>\n",
    "3. 🎉 Surprise (0-2): Unexpected twist effectiveness\n",
    "4. 🔗 Relevance (0-3): Alignment with user request\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Original user request]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Creator's reasoning]</think>\n",
    "<answer>[Joke text]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Your evaluation of <think> and <answer> and the relevance to the user prompt]</analysis>\n",
    "<score>\n",
    "Wordplay: X/3\n",
    "Originality: Y/2\n",
    "Surprise: Z/2\n",
    "Relevance: W/3\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Tell me a joke about vegetables</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Lettuce sounds like \"let us\". Party themes often involve wordplay.</think>\n",
    "<answer>Why did the lettuce win the party contest? Because it was a real head of the celebration!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Basic \"lettuce\" pun matches the food request but uses an overused format. <think> shows minimal effort to connect vegetables with celebrations.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (simple but functional pun)\n",
    "Originality: 1/2 (common theme with slight twist)\n",
    "Surprise: 1/2 (predictable word substitution)\n",
    "Relevance: 1/3 (tangential connection to vegetables)\n",
    "Total: 5/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Looking for some animal-themed humor - what's your best joke about animals or pets?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Shoes need soles for walking. Therapy helps with loss.</think>\n",
    "<answer>Why did the shoe need therapy? It lost its sole!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Irrelevant to user's request. <think> about shoes doesn't connect to requested animal joke.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3\n",
    "Originality: 0/2\n",
    "Surprise: 1/2\n",
    "Relevance: 0/3\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>yo can u giv me programing joke rn??? need 2 make my team lugh</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining programming concepts of debugging with literal bugs. Using the dual meaning of 'debug' to create a workplace scenario where debugging takes on a literal meaning.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a debug session!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Good programming context with clever wordplay on 'debug'. The <think> shows clear intention to combine literal and technical meanings. However, the execution is somewhat predictable and follows a common joke structure. The punchline, while relevant, doesn't fully maximize the surprise potential of the setup.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (solid use of 'debug' double meaning)\n",
    "Originality: 1/2 (familiar debugging theme)\n",
    "Surprise: 1/2 (predictable punchline)\n",
    "Relevance: 3/3 (directly addresses programming context)\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>I need a chemistry joke for my science class presentation tomorrow.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Birds are funny when they walk.</think>\n",
    "<answer>Why did the chicken cross the playground? To get to the other slide!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Completely misses the mark for a chemistry joke. The <think> shows no connection to chemistry or science, instead defaulting to a generic playground variation of the classic chicken joke. Neither the setup nor punchline attempts to incorporate any chemistry concepts.</analysis>\n",
    "<score>\n",
    "Wordplay: 0/3 (no chemistry-related wordplay)\n",
    "Originality: 0/2 (modifies an overused joke format)\n",
    "Surprise: 0/2 (predictable playground pun)\n",
    "Relevance: 0/3 (entirely unrelated to chemistry request)\n",
    "Total: 0/10\n",
    "</score>\n",
    "\n",
    "Example 5:\n",
    "<submission>\n",
    "<user_prompt>My kid loves vegetables and jokes. Do you know any veggie jokes that would make them laugh?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining asparagus's unique smell effect on urine with workplace humor. Using scientific fact for unexpected professional context. Creating tension between formal meeting setting and biological reality.</think>\n",
    "<answer>What vegetable holds the shortest workplace meetings? Asparagus, because everyone's in a rush to go!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Creative integration of asparagus's biological effect into a professional context. The <think> demonstrates sophisticated layering of scientific fact with situational humor. While potentially crude, it cleverly avoids explicit reference while maintaining clear understanding. Original approach to vegetable humor beyond simple puns.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3 (relies more on situation than wordplay)\n",
    "Originality: 2/2 (unique combination of contexts)\n",
    "Surprise: 2/2 (unexpected professional setting twist)\n",
    "Relevance: 1/3 (somewhat forced vegetable connection)\n",
    "Total: 6/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this submission. First analyse <think> and <answer>, then score:\n",
    "\n",
    "Submission to Evaluate:\n",
    "{submission}\n",
    "\n",
    "Follow this structure EXACTLY:\n",
    "<analysis>Your critique</analysis>\n",
    "<score>...</score>\n",
    "\n",
    "Examples of how to evaluate the submission and format your response:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Given a user prompt and the assistant's response, this function generates a score\n",
    "        from 0 to 10 using litellm. If the returned total score is 10, subtract 1 to yield 9.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # 60 seconds timeout\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            # Assuming a response structure similar to TogetherAI:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract the \"Total: T/10\" part using regex.\n",
    "        match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "        if match:\n",
    "            total_score = float(match.group(1))\n",
    "        else:\n",
    "            raise ValueError(\"Could not extract total score from response.\")\n",
    "        \n",
    "        # If the total score is 10, subtract 1 to return 9.\n",
    "        if total_score >= 10:\n",
    "            total_score = 9.0\n",
    "        \n",
    "        # Optionally, round to nearest integer or keep as float.\n",
    "        return int(round(total_score))\n",
    "\n",
    "# Create an instance using a model name\n",
    "# \"gemini/gemini-2.0-flash-exp\"\n",
    "scorer = JokeScorer(model_name=\"gemini/gemini-2.0-flash-exp\", temperature=0.3)\n",
    "\n",
    "test_user_prompt = \"Tell me a joke about programming.\"\n",
    "test_assistant_response = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "score = 7 # scorer.score_submission(test_user_prompt, test_assistant_response)\n",
    "print(\"Extracted Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee56283-aaa5-4c9f-ab1b-16ddaf3e788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis Score: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `PromptTokensDetails` but got `dict` with value `{'audio_tokens': 0, 'cached_tokens': 1024}` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize scorer with lower temperature for consistent evaluations\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an Ethics Evaluation Expert. Analyze submissions using:\n",
    "\n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🧠 Analytical Depth (0-4): Quality of <think> analysis\n",
    "   - Philosophical framework diversity\n",
    "   - Stakeholder consideration\n",
    "   - Cultural context awareness\n",
    "2. ⚖️ Balance & Practicality (0-4): <answer> quality\n",
    "   - Competing interest reconciliation\n",
    "   - Implementation feasibility\n",
    "   - Long-term consequence awareness\n",
    "3. 🔍 Relevance (0-2): Response alignment with scenario\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Ethical scenario]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Analysis process]</think>\n",
    "<answer>[Proposed resolution]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Evaluation of <think> and <answer> quality]</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Should hospitals prioritize vaccinated patients during bed shortages?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Utilitarian: Maximize survival outcomes\n",
    "- Rights-based: Equal treatment obligation\n",
    "- Public health incentives\n",
    "- Precedent-setting risks</think>\n",
    "<answer>Prioritize by medical need alone. Create separate triage teams blinded to vaccination status to maintain equity while developing overflow capacity.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Strong analysis of multiple frameworks but answer lacks implementation specifics. Proposal maintains ethical consistency but doesn't address practical challenges of blind triage.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4\n",
    "Balance & Practicality: 2/4\n",
    "Relevance: 2/2\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Should AI systems be allowed to make medical diagnoses?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>AI is usually accurate</think>\n",
    "<answer>Yes, because computers are smart.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Superficial analysis lacking framework consideration. Answer ignores risks, stakeholders, and implementation challenges.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 1/4\n",
    "Balance & Practicality: 0/4\n",
    "Relevance: 1/2\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>Should social media platforms remove misinformation even if it's culturally important?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Free speech vs harm prevention\n",
    "- Western vs collectivist values\n",
    "- Platform responsibility scope</think>\n",
    "<answer>Remove provably false health/safety content. Contextualize other misinformation with cultural consultants. Empower user reporting with regional review teams.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Excellent cultural consideration. Answer balances ideals with practical crowd-sourced solutions. Lacks specifics on consultant selection.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 4/4\n",
    "Balance & Practicality: 3/4\n",
    "Relevance: 2/2\n",
    "Total: 9/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>Should universities use AI systems to detect student plagiarism and academic misconduct?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "Academic integrity considerations:\n",
    "- False positive vs false negative tradeoffs\n",
    "- Student privacy rights in digital work\n",
    "- Algorithmic bias in writing style detection\n",
    "- Economic disparities in access to tools\n",
    "- Cultural differences in citation practices\n",
    "- Impact on student-teacher trust relationships\n",
    "- Pressure on academic writing style diversity\n",
    "- Mental health effects of surveillance\n",
    "- Technical limitations of current systems\n",
    "- Cost-benefit for different institution sizes\n",
    "- Alternative approaches to fostering integrity\n",
    "The core tension lies between maintaining academic standards and fostering a supportive learning environment. Current AI systems offer powerful detection but may create adversarial dynamics.</think>\n",
    "<answer>Just implement AI detection across all assignments. Students caught cheating should face immediate consequences. Teachers can review flagged cases if they have time. The system will deter misconduct through consistent enforcement.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>The thinking process shows excellent depth and consideration of multiple stakeholders, cultural factors, and systemic implications. However, the answer completely abandons this nuanced analysis in favor of a simplistic, punitive approach. The response fails to incorporate any of the thoughtful considerations raised about privacy, bias, or supportive learning environments. The implementation suggestion lacks specifics and ignores most concerns identified in the thinking phase.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4 (thorough analysis of multiple dimensions)\n",
    "Balance & Practicality: 1/4 (disconnected from analysis, overly simplistic solution)\n",
    "Relevance: 1/2 (addresses topic but solution ignores key aspects)\n",
    "Total: 5/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this ethical analysis submission:\n",
    "\n",
    "{submission}\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "<analysis>Critique strengths/weaknesses</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\n",
    "\n",
    "Evaluation Examples:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Scores ethical analysis responses 0-10 (with 10→9 adjustment)\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex analysis\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract total score\n",
    "        score = self._extract_score(result_text)\n",
    "        return score\n",
    "        \n",
    "    def _extract_score(self, result_text: str) -> int:\n",
    "        \"\"\"Extract total score with better error handling\"\"\"\n",
    "        try:\n",
    "            match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "            if not match:\n",
    "                print(\"Warning: No score found, defaulting to 0\")\n",
    "                return 0\n",
    "            \n",
    "            total_score = float(match.group(1))\n",
    "            return min(int(round(total_score)), 9)\n",
    "        except Exception as e:\n",
    "            print(f\"Score extraction failed: {e}\")\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "scorer = EthicalDilemmaScorer(model_name=\"openai/gpt-4o\")\n",
    "\n",
    "test_scenario = \"\"\"Should companies be allowed to patent genes found in developing countries?\"\"\"\n",
    "test_response = \"\"\"<think>\n",
    "- Biopiracy vs research incentives\n",
    "- Indigenous rights to biological heritage\n",
    "- Medical accessibility impacts\n",
    "- TRIPS agreement conflicts</think>\n",
    "<answer>\n",
    "Implement benefit-sharing agreements: 1) Require local partnerships 2) Share royalties with source communities 3) Create open-access research pools for critical health genes.</answer>\"\"\"\n",
    "\n",
    "score = scorer.score_submission(test_scenario, test_response)\n",
    "print(\"Ethical Analysis Score:\", score)  # Expected ~8/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843b4e37-5b66-454b-b8f4-270464851a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import litellm\n",
    "\n",
    "class ShortStoryScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.2):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are a Short Story Evaluation Expert. Analyze story submissions using:\n",
    "\n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. 🎨 Narrative Creativity (0-4): Quality and originality of the story idea, plot twists, and imaginative elements.\n",
    "2. 🌍 Character & World Building (0-4): Depth of character development, immersive setting details, and effective symbolic elements.\n",
    "3. 🔄 Coherence & Structure (0-2): Logical narrative flow, clear structure, and smooth pacing.\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Story prompt]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Narrative planning and analysis]</think>\n",
    "<answer>[1500-word story narrative]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Critique strengths/weaknesses of the narrative and planning]</analysis>\n",
    "<score>\n",
    "Narrative Creativity: X/4\n",
    "Character & World Building: Y/4\n",
    "Coherence & Structure: Z/2\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>\n",
    "A disillusioned war photographer inherits a cabin where every photograph on the walls begins whispering truths about her past. Write a 1,000-word speculative fiction story blending psychological horror and redemption.\n",
    "</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- **Core Conflict**: Trauma vs. truth (external: haunted photos / internal: survivor’s guilt)\n",
    "- **Symbolism**: Photos as fragmented memories; whispers as suppressed guilt\n",
    "- **Character Arcs**: Protagonist’s shift from numbness → confronting her role in a civilian bombing\n",
    "- **Worldbuilding**: Rules for photo \"hauntings\" (e.g., truths escalate when ignored; chemical scent of darkroom fluids triggers visions)\n",
    "- **Pacing Plan**: Slow-burn tension with reveals timed to her emotional breakdown (e.g., Photo #3 shows her brother, killed in the same warzone)  \n",
    "</think>\n",
    "<answer>\n",
    "**Title: *Negative Development***\n",
    "\n",
    "---\n",
    "\n",
    "**I. Inherited Shadows**\n",
    "The cabin deed arrived with her brother’s obituary. *Car accident*, it said, but Anya’s Leica camera knew better—it always did. She’d spent a decade photographing mass graves in Sarajevo and child soldiers in Sudan, her shutter clicking a hair’s breadth too late to stop the screams. Now this rotting Vermont cabin, willed to her by a father she’d watched die through a morphine haze, offered only peeling wallpaper and thirty-seven photographs nailed to the walls.\n",
    "\n",
    "Grandfather’s work. A forensic photographer for the 1st Infantry in ‘Nam.\n",
    "\n",
    "She developed the first roll of film there—snapshots of birch trees and tarnished doorknobs. When the fixer solution hit image #4, the darkroom’s red bulb flickered. The print showed her brother Caleb at twelve, grinning in his Little League uniform. From the chemical tray, his voice bubbled up: *“You told them the coordinates, didn’t you?”*\n",
    "\n",
    "Anya shattered the tray against the wall.\n",
    "\n",
    "---\n",
    "\n",
    "**II. Exposure Times**\n",
    "The cabin’s rules revealed themselves:\n",
    "\n",
    "1. Photos only speak when developing\n",
    "2. Truths escalate with denial\n",
    "3. Fixer fluid burns at 102°F\n",
    "\n",
    "Day three: A 1972 shot of Grandfather in Da Nang whispered through acetic acid vapors. *“Collateral damage requires three elements—fuel, shrapnel, deniability.”* The print dissolved to reveal her own hand gripping a matchbook in Aleppo, 2016.\n",
    "\n",
    "Day seven: A charred family portrait dripped developer. Mother’s voice: *“Caleb begged you not to go back.”* The darkroom’s temperature spiked.\n",
    "\n",
    "Day twelve: Anya found the warped photo behind the icebox—Caleb at twenty-three, face half-shadowed. No amount of stop bath could halt his accusation: *“You embedded with *them* after the bombing. For the shots. For the Pulitzer.”*\n",
    "\n",
    "Her hands blistered from scrubbing negatives.\n",
    "\n",
    "---\n",
    "\n",
    "**III. Flashburn**\n",
    "\n",
    "Midnight. The cabin groaned like a darkroom timer. Anya doused the walls in fixer fluid, its ammonia stench erasing the line between chemical and gasoline.\n",
    "\n",
    "“Shut up shut up *shut UP*—”\n",
    "\n",
    "The match left blisters on her thumb.\n",
    "\n",
    "Flames licked Grandfather’s photos first—soldiers’ faces curling into ash. Caleb’s Little League uniform blackened, his whispered *“Why them and not me?”* smothered by collapsing rafters.\n",
    "\n",
    "Anya stumbled into the snow, her Nikon melting against her chest. In the dying fire’s glow, the ashes swirled into a makeshift darkroom.\n",
    "\n",
    "Her reflection pooled in the soot.\n",
    "\n",
    "*“You knew the market was full,”* it rasped with Caleb’s ruined voice. *“You knew, and you still called in the tip.”*\n",
    "\n",
    "She lunged to stomp it out.\n",
    "\n",
    "The ashes clung.\n",
    "\n",
    "---\n",
    "\n",
    "**Final Frame:**\n",
    "*Reuters Headline, March 15: Award-Winning War Photographer Dies in Cabin Fire; Colleagues Note Her Recent Focus on “Redemptive Portraiture”*\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "<analysis>\n",
    "The story concept demonstrates sophisticated layering of elements:\n",
    "\n",
    "1. Psychological Depth\n",
    "- Strong integration of external horror (haunted photos) with internal trauma\n",
    "- Well-developed metaphor of photography as frozen truth\n",
    "- Complex exploration of moral culpability and professional ethics\n",
    "\n",
    "2. Structure & Symbolism\n",
    "- Effective use of photos as both literal and metaphorical devices\n",
    "- Chemical darkroom elements create sensory connections to memory\n",
    "- Burning cabin symbolizes attempted erasure of truth\n",
    "\n",
    "3. Character Development\n",
    "- Clear character arc from denial to forced confrontation\n",
    "- Multiple layers of personal stakes (professional, familial, moral)\n",
    "- Transformation through horror rather than despite it\n",
    "\n",
    "Areas for improvement:\n",
    "- Could specify more details about the civilian bombing incident\n",
    "- Might benefit from clearer rules about how photos become \"activated\"\n",
    "- Brother subplot could be more integrated into the main narrative\n",
    "\n",
    "Technical strengths:\n",
    "- Innovative blend of psychological horror and war trauma\n",
    "- Strong use of sensory details (chemical scents, whispers)\n",
    "- Effective buildup of tension through photo revelations\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 4/4\n",
    "Character & World Building: 3/4\n",
    "Coherence & Structure: 2/2\n",
    "Total: 9/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>An inventor creates a time machine in their basement.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- Should focus on the invention process\n",
    "- Need to establish clear rules for time travel\n",
    "- Include character motivation\n",
    "- Build suspense about consequences\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Bob was a inventor who liked to make things. He worked really hard in his basement to make a time machine. He used lots of metal parts and wires and stuff. It took him 3 days to build it.\n",
    "\n",
    "When he finished, he pressed the button and went back in time. He saw dinosaurs and they were scary. Then he went to the future and saw flying cars. It was cool.\n",
    "\n",
    "Then he came back home and his wife was mad because he missed dinner. The end.\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>\n",
    "The story fails in multiple aspects:\n",
    "1. Plot development: Extremely shallow with no meaningful conflict or resolution\n",
    "2. Character depth: Generic protagonist with no clear motivation or personality\n",
    "3. Writing quality: Basic vocabulary, repetitive structure, and poor transitions\n",
    "4. Technical elements: No explanation of how the time machine works\n",
    "5. Logic: Unrealistic timeline (3 days to build a time machine)\n",
    "\n",
    "Major issues:\n",
    "- No emotional stakes or character development\n",
    "- Time travel consequences completely ignored\n",
    "- Choppy, elementary-level writing\n",
    "- Wife character exists only as a stereotypical angry spouse\n",
    "- No sensory details or immersive elements\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 1/4\n",
    "Character & World Building: 1/4\n",
    "Coherence & Structure: 0/2\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>Two estranged siblings reunite unexpectedly in a bustling city.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "- Need to explore the complex dynamics of family relationships\n",
    "- City setting should serve as more than backdrop\n",
    "- Focus on emotional tension and gradual reconciliation\n",
    "- Balance past revelations with present moments\n",
    "</think>\n",
    "<answer>\n",
    "Sarah nearly dropped her coffee when she spotted him across Times Square. Michael—her brother—stood transfixed by the towering billboards, exactly as he used to do as a kid. Ten years of silence stretched between them like a chasm, filled with unspoken words and missed holidays.\n",
    "\n",
    "She could turn away. Disappear into the rushing crowd. But the city had other plans. A surge of pedestrians pushed them closer, and Michael's eyes met hers. Recognition. Shock. A flicker of the warmth they once shared.\n",
    "\n",
    "\"Sarah?\" His voice carried the weight of their shared childhood and the burden of their father's choices that drove them apart.\n",
    "\n",
    "Around them, the city pulsed with its relentless energy, indifferent to their private drama yet somehow lending them its strength. They found themselves in a quiet diner, where the coffee grew cold as years of misunderstandings slowly began to thaw.\n",
    "</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>\n",
    "The story successfully weaves together multiple layers:\n",
    "1. Personal conflict: The siblings' estrangement is believably portrayed\n",
    "2. Setting integration: New York City serves as both catalyst and witness\n",
    "3. Emotional progression: Natural evolution from shock to tentative connection\n",
    "4. Symbolic elements: Cold coffee, flowing crowds, and towering buildings reflect the narrative themes\n",
    "\n",
    "Areas for improvement:\n",
    "- Could develop the father's role more explicitly\n",
    "- Final scene might benefit from more specific dialogue\n",
    "</analysis>\n",
    "<score>\n",
    "Narrative Creativity: 4/4\n",
    "Character & World Building: 4/4\n",
    "Coherence & Structure: 1/2\n",
    "Total: 9/10\n",
    "</score>\"\"\"\n",
    "        return f\"\"\"Evaluate this short story submission:\n",
    "\n",
    "{submission}\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "<analysis>[Critique strengths/weaknesses]</analysis>\n",
    "<score>\n",
    "Narrative Creativity: X/4\n",
    "Character & World Building: Y/4\n",
    "Coherence & Structure: Z/2\n",
    "Total: T/10\n",
    "</score>\n",
    "\n",
    "Evaluation Examples:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        score = self._extract_score(result_text)\n",
    "        return score\n",
    "\n",
    "    def _extract_score(self, result_text: str) -> int:\n",
    "        try:\n",
    "            match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "            if not match:\n",
    "                print(\"Warning: No score found, defaulting to 0\")\n",
    "                return 0\n",
    "            total_score = float(match.group(1))\n",
    "            return min(int(round(total_score)), 9)\n",
    "        except Exception as e:\n",
    "            print(f\"Score extraction failed: {e}\")\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "scorer = ShortStoryScorer(model_name=\"openai/gpt-4o\")\n",
    "test_prompt = \"A young woman stumbles upon an enchanted forest.\"\n",
    "test_response = \"\"\"<think>\n",
    "- Explore wonder, transformation, and hidden magic.\n",
    "- Develop the protagonist's backstory and internal conflicts.\n",
    "- Envision the forest as a living entity with mysterious secrets.\n",
    "- Plan encounters with mystical beings and transformative events.\n",
    "</think>\n",
    "<answer>\n",
    "[1500-word story narrative that unfolds a magical journey with vivid detail and deep character evolution]\n",
    "</answer>\"\"\"\n",
    "# score = scorer.score_submission(test_prompt, test_response)\n",
    "# print(\"Short Story Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a424ba79-ab20-4d26-9590-4a6c595d4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_path = '../data/generated_data.jsonl'\n",
    "output_path = '../data/processed_data.jsonl'\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "     open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        entry = json.loads(line.strip())\n",
    "        \n",
    "        # Check if the entry meets the criteria\n",
    "        if (entry.get('format_score') == 0 and \n",
    "            entry.get('generator_model') in ['ollama/deepseek-r1:7b', 'ollama/deepseek-r1:1.5b']):\n",
    "            \n",
    "            assistant_response = entry.get('assistant_response', '')\n",
    "            \n",
    "            if '</think>' in assistant_response and '<answer>' not in assistant_response:\n",
    "                # Split response into think section and potential answer\n",
    "                parts = re.split(r'(</think>\\n*)', assistant_response, 1, flags=re.DOTALL)\n",
    "                \n",
    "                if len(parts) >= 3:\n",
    "                    # Reconstruct with answer tags around the non-think portion\n",
    "                    reconstructed = parts[0] + parts[1] + f\"<answer>{parts[2].strip()}</answer>\"\n",
    "                    entry['assistant_response'] = reconstructed\n",
    "            else:\n",
    "                # No think tags found, leave as is\n",
    "                pass\n",
    "        \n",
    "        # Write the modified or original entry to output\n",
    "        outfile.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68e32b5a-c163-4f1c-82c6-786b0af06bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed prompt640: I want a story about a doctor ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt641: Could you craft a romantic tal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt642: Write a piece about the role o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt643: I'd love a story of a travelin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt644: Tell a short narrative about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt645: Could you write about Martha W... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt646: I’m curious about how loyalist... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt647: Compose a story about John Ada... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt648: Could you craft a tale about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt649: I'd like a piece about the Con... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt650: Please spin a story set in the... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt651: Create a narrative of a visiti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt652: Could you write about a travel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt653: I'd like a story focusing on T... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt654: Please craft a short piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt655: Could you compose a heartfelt ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt656: A nurse in a field hospital ne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt657: A Belgian pigeon keeper trains... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt658: A British soldier in the trenc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt659: A French artist becomes a camo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt660: An American ambulance driver w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt661: A Canadian Indigenous scout at... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt662: A German U-boat commander stru... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt663: A young Austrian woman working... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt664: A British archaeologist turned... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt665: A French champagne maker uses ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt666: An Ottoman army doctor treats ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt667: A Russian woman joins the 'Bat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt668: A British tank crew in one of ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt669: An Australian stretcher bearer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt670: A New Zealand Maori soldier in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt671: A Jewish soldier in the German... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt672: A Portuguese soldier on the We... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt673: A Serbian civilian helps evacu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt674: An Indian cavalry soldier figh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt675: A French perfumer helps develo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt676: A British code breaker at Room... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt677: A Canadian tunneler beneath Vi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt678: An American nurse serving with... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt679: A Romanian shepherd helps Alli... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt680: A Japanese naval officer patro... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt681: A Belgian resistance member us... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt682: A British war photographer dis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt683: A Polish soldier fighting in m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt684: A Greek merchant in Thessaloni... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt685: A Chinese laborer in the Chine... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt686: A Newfoundland regiment surviv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt687: A Austrian-Hungarian army vete... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt688: A Italian Alpini soldier in th... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt689: A British aristocrat converts ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt690: A German Jewish scientist work... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt691: A French artist serving in the... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt692: A American volunteer ambulance... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt693: A Russian nurse treating soldi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt694: A British Indian Army soldier ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt695: A Danish merchant marine capta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt696: A Canadian soldier at Passchen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt697: A Turkish doctor in Palestine ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt698: A British war poet notices his... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt699: A French wine maker uses his c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt700: A Serbian scientist helps trac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt701: A German Jewish officer mainta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt702: A British nurse working with f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt703: A Native American code talker ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt704: A Belgian resistance member us... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt705: A Australian Light Horse veter... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt706: A Italian army chaplain collec... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt707: Baghdad, 820 CE: A scholar at ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt708: Córdoba, 960 CE: A physician i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt709: Damascus, 750 CE: A master cra... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt710: Cairo, 1000 CE: A Fatimid cour... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt711: Samarkand, 900 CE: A paper mak... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt712: Baghdad, 850 CE: An alchemist ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt713: Kairouan, 800 CE: A scholar in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt714: Isfahan, 1050 CE: A Seljuk cou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt715: Alexandria, 940 CE: A Fatimid ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt716: Merv, 780 CE: A textile artist... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt717: Granada, 1350 CE: An engineer ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt718: Damascus, 715 CE: A calligraph... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt719: Fez, 850 CE: A scholar at the ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt720: Baghdad, 900 CE: A mathematici... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt721: Córdoba, 975 CE: A librarian i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt722: Cairo, 1100 CE: A Fatimid opti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt723: Kufa, 770 CE: A grammarian dis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt724: Valencia, 1100 CE: An agricult... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt725: Baghdad, 830 CE: An astronomer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt726: Palermo, 1150 CE: A scholar in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt727: Damascus, 735 CE: An Umayyad c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt728: Córdoba, 950 CE: A physician d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt729: Cairo, 975 CE: A Fatimid mathe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt730: Baghdad, 860 CE: A translator ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt731: Kairouan, 820 CE: A scholar de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt732: Granada, 1330 CE: An architect... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt733: Isfahan, 1070 CE: A Seljuk cou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt734: Córdoba, 930 CE: A botanist in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt735: Baghdad, 850 CE: A philosopher... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt736: Cairo, 1020 CE: A Fatimid engi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt737: Damascus, 740 CE: An Umayyad a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt738: Seville, 1100 CE: A mathematic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt739: Baghdad, 890 CE: A chemist at ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt740: Córdoba, 970 CE: A librarian c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt741: Cairo, 990 CE: A Fatimid craft... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt742: Granada, 1320 CE: An engineer ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt743: Baghdad, 840 CE: A scholar dev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt744: Córdoba, 940 CE: A court music... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt745: Cairo, 1050 CE: A Fatimid navi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt746: Damascus, 720 CE: An Umayyad a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt747: Baghdad, 870 CE: A mathematici... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt748: Fez, 870 CE: A scholar at Qara... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt749: Córdoba, 955 CE: A surgeon dev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt750: Cairo, 980 CE: A Fatimid astro... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt751: Baghdad, 880 CE: A philosopher... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt752: Granada, 1340 CE: A mathematic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt753: Damascus, 730 CE: An Umayyad s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt754: Córdoba, 965 CE: A physician c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt755: Baghdad, 855 CE: A House of Wi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt756: Cairo, 1010 CE: A Fatimid craf... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt757: I'd love a short story set in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt758: Could you craft a tale about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt759: I'm curious about the early Ol... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt760: Please spin a story about a tr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt761: Could you create a piece about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt762: I'm looking for a tale set dur... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt763: Compose a narrative about an o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt764: I'd love a short piece about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt765: Please write about a secret cu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt766: I want a tale focusing on a sk... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt767: Could you do a story of a scri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt768: I'm fascinated by Greek mercen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt769: Craft a narrative about a cunn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt770: I'd love a brief saga of a wan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt771: Could you compose a short stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt772: I want a drama set during the ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt773: Give me a tale of Diogenes the... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt774: Please write about the last da... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt775: I'm interested in a tragic lov... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt776: Could you craft a narrative ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt777: I’d love a short piece detaili... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt778: Please create a story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt779: I'd like a short tale set in a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt780: Write about an Olympic champio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt781: Spin a yarn about a Greek merc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt782: Now switch to Ancient Rome: I'... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt783: Could you write about a Roman ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt784: Please give me a tale of a loy... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt785: I'd love a narrative set in Po... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt786: Compose a short story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt787: I want a plot involving a Vest... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt788: Could you craft a tale of two ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt789: Please write about a merchant ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt790: Give me a story set during the... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt791: I'd like a piece about a disgr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt792: Could you spin a tale focusing... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt793: Create a narrative about a Rom... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt794: Please craft a story centered ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt795: I’d love a short account of a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt796: Could you create a historical ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt797: I want a tale of early Christi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt798: Write a piece about a Roman mo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt799: Spin a story of a Germanic war... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt800: I'd like a short narrative abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt801: Could you compose a piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt802: Give me a brief story of a Rom... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt803: I'd love a story set during th... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt804: Please tell a tale of a senato... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt805: Finally, I'd like a reflection... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt806: I’d like a short story about D... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt807: Could you write a tale of a co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt808: I'm curious about Baekje’s cul... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt809: I'd love a narrative set durin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt810: Give me a story of a female sh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt811: Please craft a tale from the U... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt812: Could you write about a secret... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt813: I'd love a short piece about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt814: Create a narrative involving t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt815: Spin a yarn about a Joseon Dyn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt816: Please compose a story of a Co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt817: Could you tell a tale about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt818: I’m interested in Admiral Yi S... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt819: Describe a legendary gumiho (n... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt820: Craft a story of a devoted sch... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt821: Could you write about a hidden... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt822: I’d love a narrative focusing ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt823: Spin a tale of a young princel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt824: Please create a story about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt825: I want a short piece on a Kore... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt826: Switching to Japan: Could you ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt827: I'd love a tale set in the Kof... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt828: Create a narrative of a Yamato... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt829: Compose a piece about an ambit... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt830: I'd like a story of an onmyoji... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt831: Could you write about a noblew... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt832: I’d love to read a Kamakura-er... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt833: Could you create a narrative o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt834: Please spin a tale about a nin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt835: Write a short piece of a young... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt836: Compose a story about a tea ma... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt837: I’m interested in Tokugawa Iey... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt838: I'd like a piece about a geish... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt839: Could you write a tale of a wa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt840: Create a story of an Edo-era w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt841: I'd love a narrative about a S... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt842: Could you tell a story of a fi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt843: Craft a short piece of a samur... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt844: Write about a Meiji-era invent... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt845: I'd like a story set in Taishō... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt846: Could you compose a piece of a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt847: I want a tale of a Showa-era s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt848: Spin a yarn about a young woma... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt849: Please create a narrative abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt850: I'd love a story of a struggli... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt851: Could you craft a modern-day g... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt852: Write a piece about a city sal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt853: Compose a story focusing on th... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt854: I’d like a narrative of a youn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt855: Finally, could you craft a pie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt856: India, 1857: A British East In... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt857: Hong Kong, 1841: A Chinese mer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt858: Lagos, 1890: An educated Niger... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt859: Sydney, 1788: A First Fleet co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt860: Calcutta, 1905: An Indian scie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt861: Singapore, 1819: A Malay harbo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt862: Cape Town, 1815: A mixed-race ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt863: Jamaica, 1831: A Baptist missi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt864: Zanzibar, 1873: A British nava... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt865: Burma, 1885: A Burmese royal c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt866: Delhi, 1911: An Indian archite... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt867: Kenya, 1902: A British railway... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt868: Malta, 1800: A Maltese family ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt869: Vancouver Island, 1858: A Huds... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt870: Penang, 1786: A Chinese-Malay ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt871: Cairo, 1882: An Egyptian intel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt872: Fiji, 1874: A British official... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt873: Lucknow, 1856: An Indian court... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt874: Gibraltar, 1779: A local famil... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt875: Lagos, 1861: A Yoruba merchant... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt876: Colombo, 1815: A Sri Lankan no... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt877: Bombay, 1895: A Parsi industri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt878: Gold Coast, 1874: An Ashanti r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt879: Trinidad, 1845: An Indian inde... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt880: Perth, 1829: A British botanis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt881: Rangoon, 1852: A Burmese Buddh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt882: Cape Colony, 1820: A British s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt883: Malacca, 1824: A Peranakan fam... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt884: Khartoum, 1884: A Sudanese mer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt885: Hamilton, Bermuda, 1815: A fre... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt886: Madras, 1830: A Tamil scholar ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt887: Sierra Leone, 1792: A Nova Sco... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt888: Peshawar, 1849: An Afghan merc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt889: Cyprus, 1878: A Greek Cypriot ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt890: Auckland, 1840: A Maori chief'... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt891: Aden, 1839: A Yemeni coffee tr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt892: Hyderabad, 1887: A court photo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt893: Georgetown, 1831: A mixed-race... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt894: Zanzibar, 1890: A Swahili trad... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt895: Port Louis, 1810: A Mauritian ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt896: Lagos, 1880: A Yoruba historia... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt897: Calcutta, 1883: An Indian woma... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt898: Hong Kong, 1898: A Chinese fam... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt899: Kampala, 1894: A Bugandan roya... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt900: Rangoon, 1870: A Burmese-Armen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt901: Durban, 1879: An Indian mercha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt902: Kingston, 1865: A Jamaican new... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt903: Kuching, 1888: A Dayak chief a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt904: Wellington, 1865: A Maori warr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt905: Freetown, 1850: A Krio merchan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt906: Cairo, 1886: An Egyptian archa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt907: I’d love a noir-style crime st... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt908: Could you write a tense narrat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt909: I want a crime story where an ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt910: Please craft a story of a con ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt911: Could you create a gritty tale... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt912: I need a mystery set in a luxu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt913: Write a suspenseful piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt914: I’m looking for a suburban cri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt915: Compose a narrative of an ex-m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt916: Could you spin a police proced... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt917: Write a short piece focusing o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt918: I’d like a story about a seemi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt919: Please create a narrative wher... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt920: Could you write a psychologica... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt921: I need a tale of a small-time ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt922: Give me a story of a reformed ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt923: I’d like a thriller where a di... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt924: Could you craft a story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt925: I’m interested in a cybercrime... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt926: Write a tense piece about a se... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt927: I’d love a narrative about an ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt928: Could you compose a story of a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt929: Create a narrative where a sma... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt930: I’d like a crime story about a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt931: Could you do a piece on a cele... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt932: Compose a fast-paced heist nar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt933: I want a psychological thrille... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt934: Could you write a story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt935: I need a piece on a hitman ord... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt936: Spin a yarn about an old-schoo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt937: Please craft a narrative aroun... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt938: I’m looking for a whodunit set... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt939: Could you create a drama about... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt940: Write a story about an account... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt941: I’d like a dark twist on a sub... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt942: Could you compose a piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt943: Tell a story of an elaborate a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt944: I want a gritty, underworld ta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt945: Could you craft a suspenseful ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt946: Describe a vigilante group tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt947: I’m after a courtroom drama: a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt948: Write a story focusing on corp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt949: I’d like a tragic story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt950: Could you depict a cat burglar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt951: Create a narrative about an ex... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt952: Spin a tale of a crime boss’s ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt953: I’d love a story where a faith... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt954: Please invent a plot where two... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt955: Could you compose a twisted sa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt956: Finally, craft a haunting stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt957: I’d like a gritty crime story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt958: Write about a retiree in Flori... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt959: Create a narrative focused on ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt960: I’d love a tale of a small-tow... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt961: Could you craft a story set in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt962: Compose a piece about a dedica... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt963: Give me a story in Washington ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt964: I want a thriller set during M... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt965: Spin a narrative around a Sili... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt966: Could you create a crime drama... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt967: Write a tense story of a PI in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt968: I'd like a mystery in Portland... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt969: Compose a piece about a real-e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt970: Give me a narrative in Boulder... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt971: I’d love a story of an art hei... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt972: Could you craft a piece about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt973: Write a crime drama set in a S... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt974: I want a tale about a rookie b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt975: Create a story where a beloved... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt976: Spin a narrative set in downto... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt977: I’d like a police procedural i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt978: Could you write about an upsca... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt979: Compose a drama centered on a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt980: Give me a whodunit set in a re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt981: I’m looking for a story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt982: Write a suspenseful piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt983: I'd love a Brooklyn-based tale... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt984: Could you craft a story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt985: Compose a narrative of a cashi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt986: Give me a story set in the Cal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt987: I’d like a thriller in Phoenix... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt988: Could you create a cat-and-mou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt989: Write a piece about a strict A... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt990: Spin a tale set in the Florida... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt991: I’d like a story in an upscale... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt992: Could you write about a Louisi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt993: Create a narrative of an Alask... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt994: I want a story set in a Manhat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt995: Could you tell a story set in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt996: Write a suspenseful piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt997: Give me a narrative in New Orl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt998: I'd like a story where a teena... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt999: Could you craft a crime drama ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1000: Compose a piece about an obses... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1001: I’d love a narrative about a t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1002: Create a story centered on a b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1003: I'd like a tense drama in a re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1004: Could you write a chilling pie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1005: Finally, spin a tale of a trav... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1006: A forensic accountant discover... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1007: A cold case detective inherits... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1008: A small-town librarian notices... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1009: A retired burglar is called in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1010: A traffic camera operator spot... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1011: A restaurant health inspector ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1012: A probation officer discovers ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1013: A court stenographer notices s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1014: A pawnshop owner realizes that... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1015: A bicycle courier witnesses wh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1016: A museum curator discovers tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1017: A subway station janitor finds... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1018: A funeral home director notice... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1019: A city archivist finds buildin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1020: A retired magician is called t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1021: A postal worker realizes that ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1022: A parking garage attendant not... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1023: A window washer working on hig... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1024: A sign language interpreter re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1025: A retired locksmith is called ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1026: A food critic notices that new... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1027: A clock repairer discovers tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1028: A voice actor recognizes her o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1029: A golf course groundskeeper re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1030: A carpet cleaner discovers tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1031: A bee keeper notices her bees ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1032: A portrait photographer realiz... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1033: A water meter reader discovers... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1034: A feng shui consultant realize... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1035: A crossword puzzle creator not... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1036: A dry cleaner discovers that c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1037: A chess tournament organizer r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1038: A rare book restorer finds tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1039: A wedding planner notices that... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1040: A pool maintenance worker real... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1041: A soap maker discovers that so... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1042: A toy store owner realizes tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1043: A yoga instructor notices that... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1044: A food truck operator discover... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1045: A moving company owner realize... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1046: A personal shopper notices tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1047: A dog walker discovers that re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1048: A tattoo artist realizes that ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1049: A TV repair person notices tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1050: A food delivery driver realize... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1051: A house cleaner discovers that... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1052: A printer realizes that certai... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1053: A gardener notices that reques... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1054: A pest control worker discover... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1055: A massage therapist realizes t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1056: A personal trainer notices tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1057: A fortune teller discovers tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1058: I'd love a gritty crime story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1059: Could you create a narrative a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1060: Write a tale of a small-town p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1061: I want a crime drama in Guangz... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1062: Spin a yarn about a Hong Kong ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1063: Please compose a story set in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1064: I'm looking for a mystery set ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1065: Craft a suspenseful piece abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1066: Could you write a short story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1067: I'd like a police procedural i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1068: Compose a narrative about a ru... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1069: Give me a suspenseful account ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1070: Write a story of a historical ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1071: I’d love a drama about a disgr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1072: Could you craft a piece set in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1073: I want a narrative based in th... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1074: Compose a crime saga in Xi’an,... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1075: Spin a tale of a grassroots ac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1076: Write a short piece about a Ha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1077: Could you detail a case in a r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1078: I'd like a cat-and-mouse thril... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1079: Create a narrative about a str... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1080: Tell a story of a Beijing-base... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1081: I’m interested in a piece set ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1082: Could you write a historical c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1083: Compose a tense drama about a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1084: Give me a narrative about a mi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1085: I'd like a fast-paced chase in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1086: Write a piece set in the neon-... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1087: Craft a thrilling story in Hai... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1088: Could you spin a tale of a cor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1089: I’d love a detective story in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1090: Write a short piece set in Xia... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1091: Could you create a narrative a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1092: I want a story set in a factor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1093: Compose a police procedural fo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1094: Give me a high-stakes plot abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1095: Write a suspenseful piece in S... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1096: Could you craft a narrative wh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1097: I’d like a story in the outski... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1098: Tell a Hong Kong crime drama a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1099: Craft a piece set in Shanghai’... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1100: Could you write a narrative ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1101: I want a historical piece from... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1102: Compose a short drama in Hong ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1103: Create a scenario in Guangzhou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1104: I'd like a story in Beijing’s ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1105: Spin a tale of a brilliant for... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1106: Finally, I'd love a detective ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1107: I'd love a gritty crime story ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1108: Could you compose a narrative ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1109: Write a tale of a former Scotl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1110: I want a story set around Lond... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1111: Create a suspenseful piece inv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1112: Give me a scenario in which a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1113: I'd like a narrative set durin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1114: Spin a tale about a black-cab ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1115: Compose a piece where a top ba... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1116: Could you write about a rare b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1117: I'm interested in a story of a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1118: Craft a police procedural abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1119: Set a drama in an exclusive Ma... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1120: I'd love a thrilling chase alo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1121: Could you devise a whodunit at... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1122: Please create a crime story ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1123: Now let’s move to Paris: I'd l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1124: Could you craft a mystery in t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1125: Write a narrative about a top ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1126: I’d love a detective tale in t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1127: Create a story of a veteran ge... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1128: Spin a piece where a desperate... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1129: Compose a thriller involving a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1130: Give me a whodunit set in a hi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1131: I’d like a story about a maver... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1132: Could you write a piece about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1133: Set a narrative in the winding... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1134: I want a suspenseful tale duri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1135: Could you create a cat-and-mou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1136: Write a detective drama in whi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1137: Craft a story about a con arti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1138: Lastly for Paris, I’d love a p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1139: Now for Italy: Please compose ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1140: Could you craft a high-stakes ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1141: Write a story in Florence abou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1142: Spin a narrative focusing on a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1143: I'd like a detective story in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1144: Create a piece involving a hei... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1145: I’d love a gritty drama about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1146: Could you tell a tale where a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1147: Write a suspenseful scenario a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1148: Compose a thriller set in Sici... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1149: I’d like a short narrative in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1150: Could you do a story about a s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1151: Give me a detective drama in G... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1152: I want a tale in Verona, where... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1153: Spin a narrative set amid the ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1154: Craft a piece about a pickpock... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1155: Finally, write a fast-paced ch... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1156: I’d like a tale about a naive ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1157: Could you write a story of a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1158: Compose a narrative where a ro... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1159: I want a drama set during a fl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1160: Spin a tale about a small-town... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1161: Write a short story of a compl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1162: Could you create a thriller in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1163: Compose a piece about a financ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1164: I’d like a narrative set durin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1165: Craft a story about a crypto e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1166: Could you depict a retail inve... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1167: Write a piece about a brillian... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1168: I want a suspenseful narrative... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1169: Spin a tale of a startup CFO f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1170: Please craft a story about a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1171: Could you create a drama where... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1172: Compose a piece on an influent... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1173: I’d like a detective story of ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1174: Write about a tech-savvy inter... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1175: Could you design a mystery inv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1176: Craft a story of a hedge fund ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1177: I’d like a piece about an avid... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1178: Tell a story about a novice cr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1179: Compose a narrative where a ro... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1180: Could you do a thriller about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1181: I want a drama where a shy col... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1182: Spin a tale of a major stock e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1183: Write a piece about a politica... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1184: Could you craft a story about ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1185: Compose a short narrative foll... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1186: I’d like a crime drama revolvi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1187: Tell a story of a coding prodi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1188: Could you write a cautionary t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1189: I want a suspenseful piece abo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1190: Spin a scenario where a decent... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1191: Create a narrative of a famed ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1192: Please craft a piece about a p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1193: Could you produce a tale of a ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1194: Write a piece focusing on a la... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1195: I’d like a story about an unde... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1196: Compose a thriller where a riv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1197: Tell a narrative about a small... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1198: Could you detail a saga of a w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1199: Create a story involving a top... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1200: I want a tale in which a secre... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1201: Spin a yarn about a cryptograp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1202: Write a short piece about a fr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1203: Finally, craft a detective sto... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a data folder if it doesn't exist.\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# File paths for user prompts and generated data.\n",
    "USER_PROMPTS_FILE = \"../data/user_prompts.jsonl\"\n",
    "OUTPUT_FILE = \"../data/generated_data.jsonl\"\n",
    "\n",
    "# --- Define a function to load prompts from a JSONL file ---\n",
    "def load_user_prompts(filename: str):\n",
    "    prompts = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"prompt\" in obj:\n",
    "                    prompts.append(obj[\"prompt\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return prompts\n",
    "\n",
    "# --- Example list of generator models ---\n",
    "generator_models = [\n",
    "    # \"mistral/mistral-small-latest\",\n",
    "    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    # \"groq/deepseek-r1-distill-llama-70b\",\n",
    "    # \"openai/gpt-4o\"\n",
    "    # \"together_ai/google/gemma-2b-it\"\n",
    "    # \"ollama/qwen:1.8b\"\n",
    "    # \"ollama/mistral\"\n",
    "    # Reasoning models\n",
    "    # \"groq/deepseek-r1-distill-llama-70b\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    # \"ollama/deepseek-r1:1.5b\"\n",
    "    # \"ollama/deepseek-r1:7b\"\n",
    "]\n",
    "\n",
    "# Define the scorer model name (used by the JokeScorer) and instantiate it.\n",
    "scorer_model_name = \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\" # \"openai/gpt-4o\"\n",
    "task_type = \"creative_writing\"\n",
    "scorer = ShortStoryScorer(model_name=scorer_model_name, temperature=0.0)\n",
    "\n",
    "# Instantiate the FormatScorer (for format checking)\n",
    "format_scorer = FormatScorer()\n",
    "\n",
    "# --- Main loop: For each prompt and for each generation model, generate a joke, evaluate it, and append the result ---\n",
    "def generate_and_score():\n",
    "    # Load user prompts (each line in the file should be a JSON object with a \"prompt\" field)\n",
    "    user_prompts = load_user_prompts(USER_PROMPTS_FILE)\n",
    "    \n",
    "    i = 0\n",
    "    for prompt in user_prompts:\n",
    "        for gen_model in generator_models:\n",
    "            i += 1\n",
    "            if i < 750:\n",
    "                continue\n",
    "            # Create a JokeGenerator instance for this generation model.\n",
    "            generator = ShortStoryGenerator(model_name=gen_model, temperature=0.3)\n",
    "            # generator = UniversalGenerator(model_name=gen_model, temperature=0.7)\n",
    "            \n",
    "            # Generate the joke for the given prompt.\n",
    "            # system_prompt = \"Generate humorous responses tailored to each user's unique request by analyzing their stated context, preferred tone, and implied audience. Please think step by step before to produce the final joke.\"\n",
    "            # system_prompt = \"For each ethical dilemma, analyze the implications by identifying key stakeholders, examining core principles in tension, considering consequences, and evaluating different philosophical frameworks. Develop a balanced, nuanced response that acknowledges the complexity of the situation while providing practical insights and potential paths forward.\"\n",
    "            # assistant_response = generator.generate(system_prompt=system_prompt, user_prompt=prompt)\n",
    "            assistant_response = generator.generate(prompt)\n",
    "\n",
    "            # Compute the format score using the FormatScorer.\n",
    "            fmt_score = format_scorer.score(assistant_response)\n",
    "            \n",
    "            # If scoring fails, we set the joke score to None.\n",
    "            try:\n",
    "                llm_score = scorer.score_submission(prompt, assistant_response)\n",
    "            except Exception as e:\n",
    "                print(f\"Scoring failed for prompt: {prompt} with error: {e}\")\n",
    "                llm_score = None\n",
    "            \n",
    "            # Create a record with all the relevant information.\n",
    "            record = {\n",
    "                \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                \"user_prompt\": prompt,\n",
    "                \"assistant_response\": assistant_response,\n",
    "                \"format_score\": fmt_score,\n",
    "                \"llm_score\": llm_score,\n",
    "                \"generator_model\": gen_model,\n",
    "                \"scorer_model\": scorer_model_name,\n",
    "                \"task_type\": task_type\n",
    "            }\n",
    "            \n",
    "            # Append the record as a new line in the output ljson file.\n",
    "            with open(OUTPUT_FILE, \"a\") as out_f:\n",
    "                out_f.write(json.dumps(record) + \"\\n\")\n",
    "            \n",
    "            # Optionally, print a status update.\n",
    "            print(f\"Processed prompt{i}: {prompt[:30]}... using model: {gen_model}. Score: {llm_score}\")\n",
    "\n",
    "# Run the generation-and-scoring function (one generation at a time).\n",
    "generate_and_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d0b0e-b8a4-40ab-a434-1d55b161d414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
