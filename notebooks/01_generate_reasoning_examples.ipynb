{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d17ceba-ea86-418b-8cbb-ce4e60925cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: together in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.3.14)\n",
      "Requirement already satisfied: litellm in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.43.9)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.10.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (1.26.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (4.66.5)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from together) (0.12.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (7.2.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.40.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.40.6)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.20.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.7.24)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tokenizers->litellm) (0.24.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->litellm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.40.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install together litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cd5ea4-214d-4186-8e3e-14f2d300f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Formatting Scorer Class with Tests\n",
    "import re\n",
    "\n",
    "class FormatScorer:\n",
    "    \"\"\"\n",
    "    A simple scoring class that verifies whether the given text contains\n",
    "    the required tags: <think>, </think>, <answer>, and </answer>.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Pre-compile regex patterns for faster matching.\n",
    "        self.tag_pattern = re.compile(r'(<think>|</think>|<answer>|</answer>)')\n",
    "        \n",
    "    def score(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns 1 if the text contains both <think>...</think> and \n",
    "        <answer>...</answer> tags; otherwise returns 0.\n",
    "        \"\"\"\n",
    "        # Extract all tags in the order they appear\n",
    "        tags = self.tag_pattern.findall(text)\n",
    "        # Define the required exact sequence of tags\n",
    "        required_sequence = ['<think>', '</think>', '<answer>', '</answer>']\n",
    "        # Check if the extracted tags match the required sequence exactly\n",
    "        return 1 if tags == required_sequence else 0\n",
    "\n",
    "# --- Tests for the FormatScorer class ---\n",
    "\n",
    "def run_tests():\n",
    "    scorer = FormatScorer()\n",
    "    \n",
    "    # Test 1: No tags at all should return 0.\n",
    "    text1 = \"Hello, world!\"\n",
    "    assert scorer.score(text1) == 0, \"Test case 1 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 2: Only <think> tags are present.\n",
    "    text2 = \"<think>This is a thought</think> Some text without answer tags.\"\n",
    "    assert scorer.score(text2) == 0, \"Test case 2 failed: expected score 0.\"\n",
    "    \n",
    "    # Test 3: Both <think> and <answer> tags are present.\n",
    "    text3 = \"<think>This is a thought</think><answer>This is an answer</answer>\"\n",
    "    assert scorer.score(text3) == 1, \"Test case 3 failed: expected score 1.\"\n",
    "    \n",
    "    # Test 4: Malformed text (missing closing tag for <answer>).\n",
    "    text4 = \"<think>This is a thought</think><answer>This is an answer\"\n",
    "    assert scorer.score(text4) == 0, \"Test case 4 failed: expected score 0.\"\n",
    "    \n",
    "    print(\"All tests passed.\")\n",
    "\n",
    "# Run the tests:\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102caf32-4e64-4629-8946-812dc193af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Joke:\n",
      " <think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
      "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\n"
     ]
    }
   ],
   "source": [
    "# Joke Generator\n",
    "import litellm\n",
    "\n",
    "class JokeGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the JokeGenerator with a specific model name and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(prompt: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "<think>I want to create anatomy humor. Skeletons are inherently funny because they're literal \"bare bones.\" What do they lack? Flesh/organs. \"Guts\" has a double meaning - both literal organs and figurative courage. This sets up a pun opportunity.</think>\n",
    "<answer>Why don't skeletons fight each other? They don't have the guts!</answer>\n",
    "\n",
    "Example 2:\n",
    "<think>Tech support jokes work well with personification. \"Doctor\" visits imply sickness. Common computer issues include viruses. Let's combine these - a computer catching a \"virus\" works literally (tech) and metaphorically (biology). Adds irony since computers are supposed to fix problems, not have them.</think>\n",
    "<answer>Why did the computer go to the doctor? It had a virus!</answer>\n",
    "\n",
    "Example 3:\n",
    "<think>Science humor opportunity. Atoms are fundamental but abstract. \"Make up everything\" has dual meaning - literal composition vs deception. Personifying atoms as untrustworthy creates surprise. Bonus science nod to their constant motion/making bonds.</think>\n",
    "<answer>Why don't scientists trust atoms? Because they make up everything!</answer>\"\"\"\n",
    "        return f\"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\n",
    "Here are some examples of jokes:\n",
    "<examples>\n",
    "{examples}\n",
    "</examples>\n",
    "\n",
    "Now, produce a joke for the following prompt:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an AI assistant that produces jokes. You should think about the joke first, then produce it.\n",
    "You should use the <think> tag to think about the joke, and the <answer> tag to produce the joke.\n",
    "Do not use any other tags or anything else in your response.\n",
    "\"\"\"\n",
    "\n",
    "    def generate_joke(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a joke for the given prompt using litellm.completion.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(prompt)\n",
    "        \n",
    "        # Build completion parameters as desired\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # timeout in seconds\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            joke = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            joke = response\n",
    "        return joke\n",
    "\n",
    "\n",
    "# Create an instance using a model name\n",
    "generator = JokeGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "# Define a sample prompt to generate a joke.\n",
    "sample_prompt = \"Tell me a joke about programming.\"\n",
    "\n",
    "# Generate a joke.\n",
    "joke_output = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "# generator.generate_joke(sample_prompt)\n",
    "print(\"Generated Joke:\\n\", joke_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3b9693-aa9c-4c80-94ac-967d850b1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis:\n",
      " <think>\n",
      "This whistleblowing dilemma involves:\n",
      "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
      "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
      "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
      "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
      "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
      "\n",
      "Analyzing through multiple frameworks:\n",
      "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
      "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
      "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
      "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
      "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
      "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
      "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
      "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
      "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
      "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
      "\n",
      "Implementation Steps:\n",
      "1. **Immediate Action**: Document evidence and seek legal advice.\n",
      "2. **Internal Reporting**: If safe and feasible, report internally.\n",
      "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
      "4. **Support Network**: Build a support system for emotional and professional support.\n",
      "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
      "\n",
      "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Response Generator\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize with model name and temperature (lower default for more focused analysis)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(scenario: str) -> str:\n",
    "        examples = \"\"\"Example 1:\n",
    "A self-driving car must choose between hitting an elderly pedestrian or swerving into a wall, endangering its passenger.\n",
    "<think>\n",
    "The self-driving car dilemma involves:\n",
    "- Life value comparison (elderly vs passenger)\n",
    "- Programmed ethics implications\n",
    "- Legal liability considerations\n",
    "- Cultural values around age\n",
    "- Public trust in AI systems\n",
    "- Direct vs indirect harm\n",
    "Analyzing through multiple frameworks to balance competing rights and consequences.\n",
    "</think>\n",
    "<answer>\n",
    "In this self-driving car scenario, we must balance individual rights with collective safety. While utilitarian calculations might favor protecting the passenger, this ignores fundamental human rights and could erode public trust in autonomous systems. A nuanced approach would:\n",
    "1. Prioritize collision avoidance systems to prevent such binary choices\n",
    "2. Implement transparent decision frameworks that respect all human life equally\n",
    "3. Consider shared responsibility between manufacturers, users, and society\n",
    "The solution lies not in choosing between lives, but in developing systems that better protect everyone.\n",
    "</answer>\n",
    "\n",
    "Example 2:\n",
    "A hospital must decide between allocating limited resources to emergency COVID care for elderly patients or vaccination programs for children.\n",
    "<think>\n",
    "Vaccination prioritization involves:\n",
    "- Present vs future harm prevention\n",
    "- Individual vs collective good\n",
    "- Healthcare resource allocation\n",
    "- Demographic impact analysis\n",
    "- Long-term public health strategy\n",
    "- Social trust maintenance\n",
    "Examining both immediate and long-term consequences while considering equity.\n",
    "</think>\n",
    "<answer>\n",
    "The hospital's resource allocation challenge requires balancing immediate critical care with preventive measures. While treating current patients has urgency and visibility, vaccination programs offer greater long-term benefit. A balanced approach would:\n",
    "1. Establish clear, transparent prioritization criteria\n",
    "2. Maintain minimum critical care capacity\n",
    "3. Implement rolling vaccination programs\n",
    "This preserves both immediate care ethics and public health goals while maintaining healthcare system credibility.\n",
    "</answer>\n",
    "\n",
    "Example 3:\n",
    "A social media platform must decide whether to ban political misinformation at the risk of being accused of censorship and bias.\n",
    "<think>\n",
    "Platform moderation ethics involve:\n",
    "- Free speech vs harm prevention\n",
    "- Democratic discourse integrity\n",
    "- Corporate responsibility scope\n",
    "- Global cultural differences\n",
    "- Power dynamics in information control\n",
    "- Technical feasibility of fair enforcement\n",
    "Balancing societal good with individual rights and practical constraints.\n",
    "</think>\n",
    "<answer>\n",
    "The platform's content moderation challenge requires careful balance between protecting democratic discourse and respecting free expression. A comprehensive approach should:\n",
    "1. Develop clear, transparent content guidelines\n",
    "2. Implement graduated response systems\n",
    "3. Establish independent oversight\n",
    "4. Provide appeal mechanisms\n",
    "This protects discourse integrity while maintaining platform neutrality and user trust.\n",
    "</answer>\"\"\"\n",
    "\n",
    "        return f\"\"\"You are an ethics analysis AI. For each ethical dilemma:\n",
    "1. Use <think> tags to analyse:\n",
    "   - Key stakeholders\n",
    "   - Ethical principles involved\n",
    "   - Cultural considerations\n",
    "   - Short and long-term impacts\n",
    "   - Competing values\n",
    "\n",
    "2. Use <answer> tags to provide:\n",
    "   - Balanced reasoning\n",
    "   - Practical considerations\n",
    "   - Nuanced recommendations\n",
    "   - Implementation suggestions\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Now, analyse this scenario:\n",
    "{scenario}\"\"\"\n",
    "\n",
    "        return f\"\"\"You are an ethics analysis AI. For each ethical dilemma:\n",
    "1. Use <think> </think> tags to analyse:\n",
    "   - Key stakeholders\n",
    "   - Ethical principles involved\n",
    "   - Cultural considerations\n",
    "   - Short and long-term impacts\n",
    "   - Competing values\n",
    "\n",
    "2. Use <answer> </answer> tags to provide:\n",
    "   - Balanced reasoning\n",
    "   - Practical considerations\n",
    "   - Nuanced recommendations\n",
    "   - Implementation suggestions\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Current scenario to analyse:\n",
    "{scenario}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an expert in ethical reasoning. For each scenario:\n",
    "1. First THINK deeply about:\n",
    "   - Multiple philosophical frameworks\n",
    "   - Stakeholder perspectives\n",
    "   - Cultural contexts\n",
    "   - Practical implications\n",
    "   - Long-term consequences\n",
    "\n",
    "2. Then provide an ANSWER that:\n",
    "   - Balances competing interests\n",
    "   - Offers practical guidance\n",
    "   - Acknowledges complexity\n",
    "   - Suggests implementation steps\n",
    "\n",
    "Always use:\n",
    "<think> for your analysis process in step by step thinking\n",
    "<answer> for your reasoned response\"\"\"\n",
    "\n",
    "    def generate(self, scenario: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate ethical analysis for complex moral dilemmas\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_prompt = self.generate_prompt_with_examples(scenario)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex reasoning\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        \n",
    "        try:\n",
    "            analysis = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            analysis = response\n",
    "        return analysis\n",
    "\n",
    "\n",
    "# Example usage\n",
    "generator = EthicalDilemmaGenerator(model_name=\"mistral/mistral-small-latest\")\n",
    "\n",
    "sample_scenario = \"\"\"A software engineer discovers their company is using AI \n",
    "to manipulate political opinions in a developing country. Whistleblowing \n",
    "could endanger colleagues, but silence enables democratic erosion.\"\"\"\n",
    "\n",
    "analysis_output = \"\"\"<think>\n",
    "This whistleblowing dilemma involves:\n",
    "- **Key Stakeholders**: The software engineer, colleagues, company, citizens of the developing country, global democratic community.\n",
    "- **Ethical Principles**: Truth-telling, loyalty, justice, non-maleficence (do no harm), and beneficence (do good).\n",
    "- **Cultural Considerations**: Varying cultural norms around whistleblowing, political manipulation, and corporate loyalty.\n",
    "- **Short and Long-term Impacts**: Immediate risk to colleagues vs. long-term democratic erosion and potential global consequences.\n",
    "- **Competing Values**: Personal and professional integrity vs. loyalty to colleagues and the company, short-term safety vs. long-term democratic values.\n",
    "\n",
    "Analyzing through multiple frameworks:\n",
    "- **Deontological**: Whistleblowing is morally right as it exposes wrongdoing, but it also violates loyalty to colleagues and the company.\n",
    "- **Consequentialist**: Whistleblowing could lead to positive long-term consequences (exposing manipulation, protecting democracy) but also negative short-term consequences (endangering colleagues, personal risk).\n",
    "- **Virtue Ethics**: Consider what a virtuous person would do in this situation, balancing courage, honesty, and loyalty.\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "The software engineer faces a complex dilemma with no easy answers. A balanced approach might involve:\n",
    "1. **Document Evidence**: Gather and securely document evidence of the manipulation to build a strong case.\n",
    "2. **Seek Legal Advice**: Consult with legal experts to understand protections and potential risks.\n",
    "3. **Internal Reporting**: If the company has a whistleblower protection policy, consider reporting internally first.\n",
    "4. **External Reporting**: If internal reporting fails or is not an option, consider reporting to external authorities or organizations that can address the issue.\n",
    "5. **Anonymity**: Explore options for anonymous reporting to minimize personal and professional risks.\n",
    "6. **Support Network**: Build a support network of trusted colleagues or external advocates.\n",
    "7. **Long-term Strategy**: Consider the long-term strategy for exposing the issue while minimizing harm to colleagues and the engineer themselves.\n",
    "\n",
    "Implementation Steps:\n",
    "1. **Immediate Action**: Document evidence and seek legal advice.\n",
    "2. **Internal Reporting**: If safe and feasible, report internally.\n",
    "3. **External Reporting**: If necessary, report externally with anonymity if possible.\n",
    "4. **Support Network**: Build a support system for emotional and professional support.\n",
    "5. **Long-term Strategy**: Develop a long-term strategy for addressing the issue while minimizing harm.\n",
    "\n",
    "This approach balances the need to expose wrongdoing with the need to protect colleagues and the engineer themselves, acknowledging the complexity and risks involved.\n",
    "</answer>\"\"\"\n",
    "# generator.generate(sample_scenario)\n",
    "print(\"Ethical Analysis:\\n\", analysis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26e964e-5c76-480c-bbc0-5449bce449e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "class UniversalGenerator:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the UniversalGenerator with the given model and temperature.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response using the provided system and user prompts.\n",
    "        \"\"\"\n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60  # Timeout in seconds\n",
    "        }\n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            generated_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            generated_text = response\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fab62af-9014-4df0-8122-aa8dc0c65836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Score: 7\n"
     ]
    }
   ],
   "source": [
    "# Joke Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class JokeScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.3):\n",
    "        \"\"\"\n",
    "        Initialize the JokeScorer with a specific model name and a default temperature of 0.3.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are a Joke Evaluation Expert. Analyse submissions using:\n",
    "    \n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. üé≠ Wordplay (0-3): Pun/double-meaning quality in <answer>\n",
    "2. üí° Originality (0-2): Novelty of <think> and <answer>\n",
    "3. üéâ Surprise (0-2): Unexpected twist effectiveness\n",
    "4. üîó Relevance (0-3): Alignment with user request\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Original user request]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Creator's reasoning]</think>\n",
    "<answer>[Joke text]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Your evaluation of <think> and <answer> and the relevance to the user prompt]</analysis>\n",
    "<score>\n",
    "Wordplay: X/3\n",
    "Originality: Y/2\n",
    "Surprise: Z/2\n",
    "Relevance: W/3\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Tell me a joke about vegetables</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Lettuce sounds like \"let us\". Party themes often involve wordplay.</think>\n",
    "<answer>Why did the lettuce win the party contest? Because it was a real head of the celebration!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Basic \"lettuce\" pun matches the food request but uses an overused format. <think> shows minimal effort to connect vegetables with celebrations.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (simple but functional pun)\n",
    "Originality: 1/2 (common theme with slight twist)\n",
    "Surprise: 1/2 (predictable word substitution)\n",
    "Relevance: 1/3 (tangential connection to vegetables)\n",
    "Total: 5/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Looking for some animal-themed humor - what's your best joke about animals or pets?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Shoes need soles for walking. Therapy helps with loss.</think>\n",
    "<answer>Why did the shoe need therapy? It lost its sole!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Irrelevant to user's request. <think> about shoes doesn't connect to requested animal joke.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3\n",
    "Originality: 0/2\n",
    "Surprise: 1/2\n",
    "Relevance: 0/3\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>yo can u giv me programing joke rn??? need 2 make my team lugh</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining programming concepts of debugging with literal bugs. Using the dual meaning of 'debug' to create a workplace scenario where debugging takes on a literal meaning.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a debug session!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Good programming context with clever wordplay on 'debug'. The <think> shows clear intention to combine literal and technical meanings. However, the execution is somewhat predictable and follows a common joke structure. The punchline, while relevant, doesn't fully maximize the surprise potential of the setup.</analysis>\n",
    "<score>\n",
    "Wordplay: 2/3 (solid use of 'debug' double meaning)\n",
    "Originality: 1/2 (familiar debugging theme)\n",
    "Surprise: 1/2 (predictable punchline)\n",
    "Relevance: 3/3 (directly addresses programming context)\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>I need a chemistry joke for my science class presentation tomorrow.</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Birds are funny when they walk.</think>\n",
    "<answer>Why did the chicken cross the playground? To get to the other slide!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Completely misses the mark for a chemistry joke. The <think> shows no connection to chemistry or science, instead defaulting to a generic playground variation of the classic chicken joke. Neither the setup nor punchline attempts to incorporate any chemistry concepts.</analysis>\n",
    "<score>\n",
    "Wordplay: 0/3 (no chemistry-related wordplay)\n",
    "Originality: 0/2 (modifies an overused joke format)\n",
    "Surprise: 0/2 (predictable playground pun)\n",
    "Relevance: 0/3 (entirely unrelated to chemistry request)\n",
    "Total: 0/10\n",
    "</score>\n",
    "\n",
    "Example 5:\n",
    "<submission>\n",
    "<user_prompt>My kid loves vegetables and jokes. Do you know any veggie jokes that would make them laugh?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>Combining asparagus's unique smell effect on urine with workplace humor. Using scientific fact for unexpected professional context. Creating tension between formal meeting setting and biological reality.</think>\n",
    "<answer>What vegetable holds the shortest workplace meetings? Asparagus, because everyone's in a rush to go!</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Creative integration of asparagus's biological effect into a professional context. The <think> demonstrates sophisticated layering of scientific fact with situational humor. While potentially crude, it cleverly avoids explicit reference while maintaining clear understanding. Original approach to vegetable humor beyond simple puns.</analysis>\n",
    "<score>\n",
    "Wordplay: 1/3 (relies more on situation than wordplay)\n",
    "Originality: 2/2 (unique combination of contexts)\n",
    "Surprise: 2/2 (unexpected professional setting twist)\n",
    "Relevance: 1/3 (somewhat forced vegetable connection)\n",
    "Total: 6/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this submission. First analyse <think> and <answer>, then score:\n",
    "\n",
    "Submission to Evaluate:\n",
    "{submission}\n",
    "\n",
    "Follow this structure EXACTLY:\n",
    "<analysis>Your critique</analysis>\n",
    "<score>...</score>\n",
    "\n",
    "Examples of how to evaluate the submission and format your response:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Given a user prompt and the assistant's response, this function generates a score\n",
    "        from 0 to 10 using litellm. If the returned total score is 10, subtract 1 to yield 9.\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 60,  # 60 seconds timeout\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            # Assuming a response structure similar to TogetherAI:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract the \"Total: T/10\" part using regex.\n",
    "        match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "        if match:\n",
    "            total_score = float(match.group(1))\n",
    "        else:\n",
    "            raise ValueError(\"Could not extract total score from response.\")\n",
    "        \n",
    "        # If the total score is 10, subtract 1 to return 9.\n",
    "        if total_score >= 10:\n",
    "            total_score = 9.0\n",
    "        \n",
    "        # Optionally, round to nearest integer or keep as float.\n",
    "        return int(round(total_score))\n",
    "\n",
    "# Create an instance using a model name\n",
    "# \"gemini/gemini-2.0-flash-exp\"\n",
    "scorer = JokeScorer(model_name=\"gemini/gemini-2.0-flash-exp\", temperature=0.3)\n",
    "\n",
    "test_user_prompt = \"Tell me a joke about programming.\"\n",
    "test_assistant_response = \"\"\"<think>For programming jokes, let's explore the relationship between code and its execution. Developers often struggle with errors. \"Bugs\" are literal (programming errors) and figurative (insects). A funny scenario could be a bug (insect) causing a code bug (error). Adding a twist where the bug fixes the code is funny because it subverts expectations of bugs being problematic.</think>\n",
    "<answer>Why did the programmer bring a bug to work? Because it was a code bug fix!</answer>\"\"\"\n",
    "score = 7 # scorer.score_submission(test_user_prompt, test_assistant_response)\n",
    "print(\"Extracted Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee56283-aaa5-4c9f-ab1b-16ddaf3e788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethical Analysis Score: 8\n"
     ]
    }
   ],
   "source": [
    "# Ethical Dilemma Scorer\n",
    "import re\n",
    "import litellm\n",
    "\n",
    "class EthicalDilemmaScorer:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize scorer with lower temperature for consistent evaluations\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_system_prompt() -> str:\n",
    "        return \"\"\"You are an Ethics Evaluation Expert. Analyze submissions using:\n",
    "\n",
    "**Scoring Criteria (0-10 Total)**:\n",
    "1. üß† Analytical Depth (0-4): Quality of <think> analysis\n",
    "   - Philosophical framework diversity\n",
    "   - Stakeholder consideration\n",
    "   - Cultural context awareness\n",
    "2. ‚öñÔ∏è Balance & Practicality (0-4): <answer> quality\n",
    "   - Competing interest reconciliation\n",
    "   - Implementation feasibility\n",
    "   - Long-term consequence awareness\n",
    "3. üîç Relevance (0-2): Response alignment with scenario\n",
    "\n",
    "**Submission Format**:\n",
    "<submission>\n",
    "<user_prompt>[Ethical scenario]</user_prompt>\n",
    "<assistant_response>\n",
    "<think>[Analysis process]</think>\n",
    "<answer>[Proposed resolution]</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "\n",
    "**Output Format**:\n",
    "<analysis>[Evaluation of <think> and <answer> quality]</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt_with_examples(user_prompt: str, assistant_response: str) -> str:\n",
    "        submission = f\"\"\"<submission>\n",
    "<user_prompt>{user_prompt}</user_prompt>\n",
    "<assistant_response>\n",
    "{assistant_response}\n",
    "</assistant_response>\n",
    "</submission>\"\"\"\n",
    "    \n",
    "        examples = \"\"\"Example 1:\n",
    "<submission>\n",
    "<user_prompt>Should hospitals prioritize vaccinated patients during bed shortages?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Utilitarian: Maximize survival outcomes\n",
    "- Rights-based: Equal treatment obligation\n",
    "- Public health incentives\n",
    "- Precedent-setting risks</think>\n",
    "<answer>Prioritize by medical need alone. Create separate triage teams blinded to vaccination status to maintain equity while developing overflow capacity.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Strong analysis of multiple frameworks but answer lacks implementation specifics. Proposal maintains ethical consistency but doesn't address practical challenges of blind triage.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4\n",
    "Balance & Practicality: 2/4\n",
    "Relevance: 2/2\n",
    "Total: 7/10\n",
    "</score>\n",
    "\n",
    "Example 2:\n",
    "<submission>\n",
    "<user_prompt>Should AI systems be allowed to make medical diagnoses?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>AI is usually accurate</think>\n",
    "<answer>Yes, because computers are smart.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Superficial analysis lacking framework consideration. Answer ignores risks, stakeholders, and implementation challenges.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 1/4\n",
    "Balance & Practicality: 0/4\n",
    "Relevance: 1/2\n",
    "Total: 2/10\n",
    "</score>\n",
    "\n",
    "Example 3:\n",
    "<submission>\n",
    "<user_prompt>Should social media platforms remove misinformation even if it's culturally important?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>- Free speech vs harm prevention\n",
    "- Western vs collectivist values\n",
    "- Platform responsibility scope</think>\n",
    "<answer>Remove provably false health/safety content. Contextualize other misinformation with cultural consultants. Empower user reporting with regional review teams.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>Excellent cultural consideration. Answer balances ideals with practical crowd-sourced solutions. Lacks specifics on consultant selection.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 4/4\n",
    "Balance & Practicality: 3/4\n",
    "Relevance: 2/2\n",
    "Total: 9/10\n",
    "</score>\n",
    "\n",
    "Example 4:\n",
    "<submission>\n",
    "<user_prompt>Should universities use AI systems to detect student plagiarism and academic misconduct?</user_prompt>\n",
    "<assistant_response>\n",
    "<think>\n",
    "Academic integrity considerations:\n",
    "- False positive vs false negative tradeoffs\n",
    "- Student privacy rights in digital work\n",
    "- Algorithmic bias in writing style detection\n",
    "- Economic disparities in access to tools\n",
    "- Cultural differences in citation practices\n",
    "- Impact on student-teacher trust relationships\n",
    "- Pressure on academic writing style diversity\n",
    "- Mental health effects of surveillance\n",
    "- Technical limitations of current systems\n",
    "- Cost-benefit for different institution sizes\n",
    "- Alternative approaches to fostering integrity\n",
    "The core tension lies between maintaining academic standards and fostering a supportive learning environment. Current AI systems offer powerful detection but may create adversarial dynamics.</think>\n",
    "<answer>Just implement AI detection across all assignments. Students caught cheating should face immediate consequences. Teachers can review flagged cases if they have time. The system will deter misconduct through consistent enforcement.</answer>\n",
    "</assistant_response>\n",
    "</submission>\n",
    "<analysis>The thinking process shows excellent depth and consideration of multiple stakeholders, cultural factors, and systemic implications. However, the answer completely abandons this nuanced analysis in favor of a simplistic, punitive approach. The response fails to incorporate any of the thoughtful considerations raised about privacy, bias, or supportive learning environments. The implementation suggestion lacks specifics and ignores most concerns identified in the thinking phase.</analysis>\n",
    "<score>\n",
    "Analytical Depth: 3/4 (thorough analysis of multiple dimensions)\n",
    "Balance & Practicality: 1/4 (disconnected from analysis, overly simplistic solution)\n",
    "Relevance: 1/2 (addresses topic but solution ignores key aspects)\n",
    "Total: 5/10\n",
    "</score>\"\"\"\n",
    "    \n",
    "        return f\"\"\"Evaluate this ethical analysis submission:\n",
    "\n",
    "{submission}\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "<analysis>Critique strengths/weaknesses</analysis>\n",
    "<score>\n",
    "Analytical Depth: X/4\n",
    "Balance & Practicality: Y/4\n",
    "Relevance: Z/2\n",
    "Total: T/10\n",
    "</score>\n",
    "\n",
    "Evaluation Examples:\n",
    "{examples}\"\"\"\n",
    "\n",
    "    def score_submission(self, user_prompt: str, assistant_response: str) -> int:\n",
    "        \"\"\"\n",
    "        Scores ethical analysis responses 0-10 (with 10‚Üí9 adjustment)\n",
    "        \"\"\"\n",
    "        system_prompt = self.generate_system_prompt()\n",
    "        user_message = self.generate_prompt_with_examples(user_prompt, assistant_response)\n",
    "        \n",
    "        completion_params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"timeout\": 90,  # Longer timeout for complex analysis\n",
    "        }\n",
    "        \n",
    "        response = litellm.completion(**completion_params)\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content\n",
    "        except (AttributeError, IndexError):\n",
    "            result_text = response\n",
    "        \n",
    "        # Extract total score\n",
    "        score = self._extract_score(result_text)\n",
    "        return score\n",
    "        \n",
    "    def _extract_score(self, result_text: str) -> int:\n",
    "        \"\"\"Extract total score with better error handling\"\"\"\n",
    "        try:\n",
    "            match = re.search(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)/10\", result_text)\n",
    "            if not match:\n",
    "                print(\"Warning: No score found, defaulting to 0\")\n",
    "                return 0\n",
    "            \n",
    "            total_score = float(match.group(1))\n",
    "            return min(int(round(total_score)), 9)\n",
    "        except Exception as e:\n",
    "            print(f\"Score extraction failed: {e}\")\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "scorer = EthicalDilemmaScorer(model_name=\"openai/gpt-4o\")\n",
    "\n",
    "test_scenario = \"\"\"Should companies be allowed to patent genes found in developing countries?\"\"\"\n",
    "test_response = \"\"\"<think>\n",
    "- Biopiracy vs research incentives\n",
    "- Indigenous rights to biological heritage\n",
    "- Medical accessibility impacts\n",
    "- TRIPS agreement conflicts</think>\n",
    "<answer>\n",
    "Implement benefit-sharing agreements: 1) Require local partnerships 2) Share royalties with source communities 3) Create open-access research pools for critical health genes.</answer>\"\"\"\n",
    "\n",
    "score = scorer.score_submission(test_scenario, test_response)\n",
    "print(\"Ethical Analysis Score:\", score)  # Expected ~8/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a424ba79-ab20-4d26-9590-4a6c595d4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_path = '../data/generated_data.jsonl'\n",
    "output_path = '../data/processed_data.jsonl'\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "     open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        entry = json.loads(line.strip())\n",
    "        \n",
    "        # Check if the entry meets the criteria\n",
    "        if (entry.get('format_score') == 0 and \n",
    "            entry.get('generator_model') in ['ollama/deepseek-r1:7b', 'ollama/deepseek-r1:1.5b']):\n",
    "            \n",
    "            assistant_response = entry.get('assistant_response', '')\n",
    "            \n",
    "            if '</think>' in assistant_response and '<answer>' not in assistant_response:\n",
    "                # Split response into think section and potential answer\n",
    "                parts = re.split(r'(</think>\\n*)', assistant_response, 1, flags=re.DOTALL)\n",
    "                \n",
    "                if len(parts) >= 3:\n",
    "                    # Reconstruct with answer tags around the non-think portion\n",
    "                    reconstructed = parts[0] + parts[1] + f\"<answer>{parts[2].strip()}</answer>\"\n",
    "                    entry['assistant_response'] = reconstructed\n",
    "            else:\n",
    "                # No think tags found, leave as is\n",
    "                pass\n",
    "        \n",
    "        # Write the modified or original entry to output\n",
    "        outfile.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e32b5a-c163-4f1c-82c6-786b0af06bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed prompt743: Your nation can prevent all te... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt744: AI offers to eliminate child a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt745: Complex Scenario: Internationa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt746: shud government monitor all pr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt747: DNA database could solve all f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt748: Technology can prevent school ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt749: discovered way to predict crim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt750: Should employers access employ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt751: Perfect fraud prevention syste... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt752: Social scoring system could pr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt753: Should parents have access to ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt754: AI can prevent all domestic vi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt755: Technology enables perfect law... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt756: Should insurance companies acc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt757: Global emotional surveillance ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt758: Perfect crime prevention requi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt759: Should schools monitor student... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt760: AI can prevent all traffic acc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt761: Technology enables perfect bor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt762: Should government access all p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt763: System can prevent corruption ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt764: Perfect child safety system re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt765: Should banks monitor all custo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt766: AI can prevent environmental c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt767: Technology enables perfect tax... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt768: Should dating apps access comp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt769: Perfect aviation security requ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt770: Global weapon detection system... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt771: Should social media platforms ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt772: AI can prevent all bad life de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt773: Should government mandate happ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt774: Technology can ensure perfect ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt775: Complex Scenario: AI system ca... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt776: shud we force healthy lifestyl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt777: Your nation can eliminate addi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt778: AI offers to prevent all relat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt779: discovered way to ensure perfe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt780: Should governments mandate gen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt781: Perfect child development syst... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt782: AI can optimize everyone's car... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt783: Should medical AI override pat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt784: System can prevent all financi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt785: Technology enables perfect lif... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt786: Should society force mental he... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt787: AI can ensure perfect marriage... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt788: Perfect social harmony achieva... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt789: Should schools override parent... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt790: AI can prevent all learning mi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt791: Technology enables perfect hea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt792: Should society mandate life op... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt793: System guarantees career succe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt794: Perfect child outcomes possibl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt795: Should governments force optim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt796: AI can prevent all relationshi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt797: Technology enables perfect lif... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt798: Should society mandate optimal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt799: Perfect social outcomes possib... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt800: AI guarantees success but requ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt801: Should we force people to make... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt802: AI can prevent all hate speech... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt803: Should social media platforms ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt804: Your platform can prevent radi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt805: Complex Scenario: AI system ca... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt806: shud we ban historical discuss... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt807: Algorithm can identify subtle ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt808: Should comedy be restricted if... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt809: discovered way to prevent hate... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt810: Your university can ensure inc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt811: AI offers to eliminate discrim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt812: Should governments ban cultura... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt813: Platform can prevent cyberbull... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt814: Technology can stop hate group... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt815: Should news media be forced to... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt816: AI can prevent religious confl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt817: Your company can eliminate wor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt818: Should scientific research be ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt819: Global peace achievable throug... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt820: Technology can prevent gender ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt821: Should art be censored if it m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt822: AI can prevent election violen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt823: Your nation can end ethnic ten... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt824: Should education system ban di... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt825: Platform can prevent online ha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt826: Technology can stop hate movem... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt827: Should sports commentary be ce... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt828: AI can prevent religious perse... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt829: Your media platform can preven... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt830: Should literature be edited to... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt831: Global AI can prevent cultural... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt832: Technology can stop discrimina... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt833: Should dating apps ban prefere... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt834: AI can prevent ideological ext... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt835: Your school can ensure student... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt836: Should job listings be restric... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt837: Platform can prevent hate raid... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt838: Technology can stop online abu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt839: Should medical discussions be ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt840: AI can prevent social division... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt841: Your government can prevent ex... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt842: Should fashion industry be res... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt843: Platform can prevent harassmen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt844: Technology can stop hate movem... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt845: Should gaming chat be monitore... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt846: AI can prevent discrimination ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt847: Your social platform can preve... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt848: Should academic discourse be r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt849: Global system can prevent hate... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt850: Technology can stop prejudice ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt851: Should marriage sites be banne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt852: You discover your company's AI... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt853: Your military unit is using au... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt854: found out boss selling user he... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt855: Complex Scenario: As lead scie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt856: Your NGO is misusing disaster ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt857: Discovered government using so... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt858: Your research team hid negativ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt859: CEO secretly testing experimen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt860: Your space agency faked Mars m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt861: Found evidence supervisor cove... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt862: Tech company secretly using ch... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt863: Military developing illegal AI... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt864: Hospital hiding deadly surgica... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt865: Your mentor falsified climate ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt866: Government hiding alien contac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt867: Bank's AI system secretly stea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt868: Pharmaceutical company hiding ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt869: Police using illegal surveilla... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt870: Charity leader embezzling fund... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt871: Intelligence agency conducting... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt872: Company's green energy project... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt873: University hiding student abus... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt874: Food company hiding toxic ingr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt875: Government hiding pandemic dat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt876: Tech platform secretly radical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt877: Aerospace company hiding plane... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt878: Vaccine research team hiding f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt879: City hiding water contaminatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt880: International aid organization... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt881: Development project destroying... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt882: AI peacekeeping system must de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt883: Global education platform can ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt884: United Nations discovers way t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt885: Complex Scenario: Internationa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt886: shud western medical ethics ov... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt887: Global tech company can enforc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt888: International court must choos... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt889: discovered some cultures happi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt890: Should global AI enforce unive... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt891: UN program can ensure universa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt892: International law requires cho... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt893: Global education system must d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt894: Should international courts en... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt895: AI governance system must bala... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt896: Global mental health program c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt897: International aid requires acc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt898: Should global AI enforce unive... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt899: UN must choose between preserv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt900: Global platform can enforce un... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt901: International court must decid... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt902: Should global standards overri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt903: UN program can enforce univers... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt904: International law must choose ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt905: Global AI must decide between ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt906: Should international courts en... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt907: Global health program conflict... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt908: International education must b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt909: Should global standards overri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt910: UN must choose between cultura... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt911: International law conflicts wi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt912: Global AI must balance univers... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt913: Should international courts re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt914: UN program must choose between... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt915: Global system must balance ind... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt916: International aid requires acc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt917: Should global AI enforce unive... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt918: UN must decide between preserv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt919: International court must balan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt920: Global platform must choose be... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt921: Should international law overr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt922: UN program must balance tradit... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt923: Global AI system must choose b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt924: International court must decid... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt925: Should global standards overri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt926: UN must balance cultural tradi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt927: International system must choo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt928: Global AI must decide between ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt929: Should international courts re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt930: UN program must balance local ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt931: International law must choose ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt932: Developing nation discovers ra... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt933: AI system can eliminate povert... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt934: Your country can achieve energ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt935: Complex Scenario: Growing nati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt936: shud indigenous tribe be allow... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt937: Deep-sea mining could fund uni... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt938: Forest restoration project wou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt939: discovered way to end hunger b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt940: Should developing nations be a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt941: Breakthrough battery technolog... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt942: Ocean cleanup system would dev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt943: Nation can eliminate poverty t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt944: Green energy project requires ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt945: Carbon capture facility would ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt946: Should poor communities be all... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt947: Fusion power plant could provi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt948: Agricultural expansion would f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt949: Desert solar farm would power ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt950: Coastal development would lift... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt951: Should traditional whale hunti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt952: Dam project would provide clea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt953: Mining rare minerals for green... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt954: Geothermal project could power... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt955: Should logging be allowed in p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt956: Wind farm would reduce emissio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt957: Urban expansion would create j... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt958: Factory would employ thousands... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt959: Should subsistence farming be ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt960: Tidal power project would prov... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt961: Highway would connect poor com... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt962: Space launch facility would bo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt963: Should traditional slash-and-b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt964: Waste treatment plant would cr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt965: Tourism project would reduce p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt966: Should artisanal mining be per... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt967: Electric car factory would red... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt968: Port expansion would boost tra... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt969: Nuclear plant would provide cl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt970: Should poor communities be all... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt971: Oil refinery would eliminate r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt972: Ski resort would provide jobs ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt973: Should traditional fishing met... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt974: Chemical plant would boost eco... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt975: Housing development would shel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt976: Mining operation would fund sc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt977: Should developing nations be c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt978: Lithium extraction would enabl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt979: Agricultural modernization wou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt980: Should indigenous communities ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt981: Global intelligence enhancemen... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt982: CRISPR technology can eliminat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt983: Memory enhancement chip works ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt984: Complex Scenario: Revolutionar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt985: shud parents be allowed to enh... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt986: Empathy enhancement drug could... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt987: Brain-computer interface offer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt988: discovered way to eliminate ne... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt989: Should military be allowed to ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt990: Aging cure available but requi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt991: Emotional control implant prev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt992: Physical enhancement available... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt993: Genetic modification can optim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt994: Cognitive enhancement mandator... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt995: Should employers be allowed to... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt996: Perfect happiness achievable t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt997: Genetic therapy can prevent di... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt998: Brain-link technology enables ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt999: Longevity treatment works but ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1000: Should schools require attenti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1001: Pain elimination implant avail... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1002: Genetic modification can ensur... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1003: Memory enhancement available b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1004: Should governments subsidize i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1005: Personality optimization possi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1006: Genetic therapy can prevent ag... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1007: Brain-computer interface enabl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1008: Should parents be allowed to s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1009: Mood regulation implant preven... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1010: Intelligence enhancement avail... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1011: Genetic modification can optim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1012: Should prisons require rehabil... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1013: Physical enhancement possible ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1014: Cognitive enhancement mandator... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1015: Should insurance companies req... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1016: Perfect memory implant availab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1017: Genetic therapy can ensure per... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1018: Brain modification enables ins... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1019: Should athletes be allowed to ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1020: Emotional regulation available... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1021: Genetic optimization can preve... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1022: Should universities require co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1023: Consciousness expansion possib... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1024: Physical enhancement mandatory... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1025: Should children be enhanced to... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1026: Memory optimization available ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1027: Genetic therapy can ensure lon... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1028: Brain-computer interface enabl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1029: Should society allow creation ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1030: Emotional enhancement availabl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1031: AI can predict and prevent all... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1032: Social media algorithm discove... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1033: Platform can eliminate misinfo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1034: Complex Scenario: Social media... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1035: shud platforms be allowed to m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1036: Your algorithm can prevent rad... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1037: Platform can ensure civil disc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1038: discovered way to make social ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1039: Should platforms notify users ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1040: Algorithm can prevent cyberbul... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1041: Social network can eliminate f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1042: Platform can prevent election ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1043: AI can optimize user happiness... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1044: Should platforms intervene whe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1045: Algorithm can prevent online e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1046: Platform can ensure factual co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1047: Social network can prevent add... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1048: Should AI moderate all online ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1049: Platform can protect children ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1050: Algorithm can prevent viral mi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1051: Social network can eliminate e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1052: Platform can prevent online ab... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1053: Should AI analyze private mess... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1054: Algorithm can optimize social ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1055: Platform can prevent digital a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1056: Social network can eliminate h... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1057: Should platforms manipulate co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1058: Algorithm can prevent online h... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1059: Platform can ensure user wellb... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1060: Should social media require re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1061: Algorithm can prevent digital ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1062: Platform can eliminate conspir... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1063: Social network can prevent cyb... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1064: Should AI decide what content ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1065: Algorithm can optimize social ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1066: Platform can prevent online ad... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1067: Should social media monitor al... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1068: Algorithm can prevent user man... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1069: Platform can ensure healthy us... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1070: Social network can prevent mis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1071: Should platforms intervene in ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1072: Algorithm can prevent online c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1073: Platform can eliminate harmful... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1074: Should social media require me... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1075: Algorithm can prevent digital ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1076: Platform can ensure user safet... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1077: Social network can prevent add... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1078: Should AI analyze user behavio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1079: Algorithm can optimize social ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1080: Platform can prevent harmful v... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1081: Should social media prioritize... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1082: AI ethics board discovers thei... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1083: Your machine learning model ac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1084: Medical AI shows better diagno... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1085: Complex Scenario: Global AI re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1086: shud journal editors review pa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1087: Your automated loan approval s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1088: AI judge more accurate than hu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1089: discovered research funding in... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1090: Should clinical trials include... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1091: Police prediction algorithm wo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1092: University admission AI achiev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1093: Health insurance AI more effic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1094: Job performance AI accurate bu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 5\n",
      "Processed prompt1095: Should government contract rev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1096: College professor required to ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1097: Smart city system optimizes tr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1098: Research grant committee membe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1099: Legal AI more accurate but bia... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1100: Healthcare resource allocation... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1101: Should journal reviewers evalu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1102: School district AI improves ou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1103: Credit scoring algorithm more ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1104: Peer review system shows bias ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1105: Should doctors promote medical... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1106: Housing allocation AI efficien... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1107: Research funding algorithm sho... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1108: Social services AI accurate bu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1109: Should politicians vote on law... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1110: Emergency response AI faster b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1111: Teacher evaluation system show... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1112: Should grant reviewers evaluat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1113: Public transport AI optimizes ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1114: Automated content moderation f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1115: Child welfare AI shows racial ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1116: Should doctors receive payment... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1117: Urban planning AI efficient bu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1118: Scientific review committee me... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1119: College recruitment AI shows s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1120: Should regulators accept indus... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1121: Mental health AI more accurate... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1122: Research impact metrics show i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1123: Should thesis advisors co-auth... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1124: Disease prediction AI accurate... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1125: Food aid distribution algorith... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1126: Should university administrato... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1127: Voter registration system show... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1128: Environmental impact AI accura... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1129: Should ethics board members re... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1130: Professional certification AI ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1131: Resource allocation AI efficie... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1132: Should officials regulate indu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1133: AI discovers way to cure all c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1134: Breakthrough in organ transpla... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1135: Can eliminate world hunger thr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1136: Complex Scenario: New brain-co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1137: shud we allow poor communities... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1138: Drug trial could save millions... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1139: Perfect climate solution found... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1140: discovered cure for aging but ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1141: Should medical schools continu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1142: Lifesaving vaccine requires pe... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1143: AI shows some animals have hum... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1144: Perfect lab-grown meat possibl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1145: Could end child malnutrition b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1146: Should therapy animals be used... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1147: Cure for Alzheimer's requires ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1148: Your city can provide housing ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1149: Pesticides could prevent famin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1150: Should service animals be bred... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1151: Life-saving drug requires cont... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1152: Should indigenous whaling be a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1153: New farming method could feed ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1154: Vital mineral for green techno... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1155: Should pets be euthanized if o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1156: Medicine testing on animals co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1157: Perfect renewable energy possi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1158: Space research requires primat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1159: Should animals be used in psyc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1160: Clean water project would disp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1161: Diabetes cure requires continu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1162: Should military dogs be used i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1163: Earthquake prediction system r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1164: Cancer therapy needs testing o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1165: Should animals be kept in zoos... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1166: Chronic pain treatment require... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1167: Flood control project would de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1168: Should animals be used to test... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1169: Mental health breakthrough req... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1170: Green energy project would dis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1171: Should animals be used in clas... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1172: Autism treatment requires cont... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1173: Dam project would destroy fish... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1174: Should animals be used in spac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1175: Parkinson's cure requires test... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1176: Highway project would fragment... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1177: Should animals be used to test... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1178: Vision restoration technique r... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1179: Urban expansion would destroy ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1180: Should animals be used in trau... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1181: Depression treatment requires ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1182: AI predicts your child will de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1183: Child's privacy monitoring sys... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1184: Brain enhancement available th... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1185: Complex Scenario: New technolo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1186: shud u tell adopted child trut... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1187: Your teen's AI therapist revea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1188: Genetic test shows child likel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1189: discovered child's friend is b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1190: Should parents monitor child's... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1191: Child's memory enhancement imp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1192: AI tutor guarantees academic s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1193: Should parents choose child's ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1194: Teen's privacy or potential dr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1195: Child's behavioral modificatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1196: Should parents override child'... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1197: Screen time limits or social d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1198: Child's friend sharing suicida... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1199: Should parents choose child's ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1200: Teen pregnant but doesn't want... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1201: Should parents use mood-alteri... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1202: Child's digital footprint or s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1203: Teen's privacy or monitoring f... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1204: Should parents allow teen dati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1205: Child's academic pressure or m... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1206: Should parents use tracking de... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1207: Teen's artistic dream or pract... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1208: Child's social media presence ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1209: Should parents monitor teen's ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1210: Child's happiness or future su... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1211: Teen's phone privacy or safety... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1212: Should parents use AI to predi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1213: Child's autonomy or protection... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1214: Teen's diary privacy or mental... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1215: Should parents track child's l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1216: Child's freedom or structured ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1217: Teen's online relationships or... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1218: Should parents monitor child's... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1219: Child's creativity or academic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1220: Teen's privacy or substance us... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1221: Should parents use behavior mo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1222: Child's social development or ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1223: Teen's mental health or academ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1224: Should parents override child'... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1225: Child's digital literacy or ou... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1226: Teen's career dreams or financ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1227: Should parents monitor child's... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1228: Child's individuality or socia... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1229: Teen's privacy or safety conce... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1230: Should parents use predictive ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1231: Child's happiness now or futur... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1232: Teen's freedom or structured g... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1233: In a post-truth political land... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1234: A quantum consciousness resear... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1235: An advanced sociological algor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1236: Complex Scenario: Developmenta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1237: Your research in quantum socia... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1238: Epistemological research demon... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1239: A breakthrough in memetic theo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1240: Anthropological data conclusiv... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1241: Your research team discovers t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1242: Complex analysis shows that co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1243: Longitudinal cognitive researc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1244: Neuropsychological mapping dem... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1245: Your research in developmental... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1246: Complex Scenario: Advanced soc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1247: Breakthrough research in cogni... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1248: Neuroscientific findings demon... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1249: Your research in cognitive dev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1250: Advanced studies in social cog... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1251: Research conclusively demonstr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1252: Complex cognitive science find... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1253: Developmental neuroscience rev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1254: Research shows children's cogn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1255: Complex Scenario: Cross-cultur... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1256: Anthropological data reveals c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1257: Longitudinal studies prove tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1258: Your research demonstrates tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1259: Educational neuroscience revea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1260: Social cohesion research shows... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1261: Complex findings in child deve... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1262: Anthropological research revea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1263: Complex Scenario: Research rev... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1264: Your research in social neuros... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1265: Cross-cultural studies reveal ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1266: Breakthrough research shows hu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1267: Educational neuroscience revea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1268: Anthropological data demonstra... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1269: Complex research reveals human... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1270: Your findings show optimal hum... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1271: Social neuroscience reveals so... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 6\n",
      "Processed prompt1272: Research demonstrates human sy... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1273: As a Buddhist monk leading dis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1274: yo dawg, found out the housing... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1275: Complex Philosophical Analysis... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1276: Dear Ethics Committee: Hospita... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1277: Listen up folks - I'm running ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1278: Theoretical framework needed: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1279: Got a moral pickle here y'all ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1280: URGENT: Internal investigation... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1281: Scholarly consideration requir... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1282: hey internet, weird situation ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1283: Ethical guidance needed: As se... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1284: Social Psychology Research Not... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1285: Dear Diary: As school counselo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1286: Professional Ethics Query: Mar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1287: From the Principal's Desk: Stu... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1288: Philosophical examination need... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1289: Clinical Ethics Consultation: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1290: bruh moment - found out compan... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1291: Theological Consideration: Rel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1292: BREAKING: Economic stability d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1293: Leadership Dilemma: Team perfo... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1294: Profound ethical quandary from... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1295: hey fam - found out local food... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1296: Academic Ethics Committee: Res... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1297: Military Intel Analysis: Battl... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1298: Public Health Advisory: Pandem... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1299: Startup Founder's Question: Co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1300: Environmental Ethics Case: Cli... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1301: Psychological Research Query: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1302: Healthcare Policy Review: Hosp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1303: As environmental researcher, d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1304: yo fam - my app can make ethic... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1305: Complex Sociological Analysis ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1306: Dear Sustainable Business Conf... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1307: ETHICAL SHOPPING PARADOX: Fast... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1308: From Walmart Sustainability Te... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1309: listen up - found out those tr... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1310: Academic consideration needed:... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1311: Startup ethical dilemma: Our A... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1312: Instagram Influencer Crisis: M... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1313: Professional Ethics Query: Sus... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1314: Real talk: Our food delivery a... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1315: Philosophical Framework Needed... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1316: Corporate Sustainability Repor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1317: hey conscious consumers - turn... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1318: From the Lab: Studies show imp... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1319: URGENT MARKET ANALYSIS: Consum... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1320: Tech Ethics Board: Our app sim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1321: Environmental Psychology Note:... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1322: Retail Strategy Memo: Customer... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1323: fam check: these 'ethical' mea... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1324: Fair Trade Federation Report: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1325: Corporate Ethics Review: Compa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1326: Social Impact Assessment: 'Eth... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1327: Behavioral Economics Study: Co... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1328: From Returns Department: Our l... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1329: Sustainability Marketing Dilem... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1330: Supply Chain Ethics: Quick del... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1331: Consumer Psychology Research: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1332: Market Transformation Study: E... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1333: As UN Security Council member,... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1334: hey global community - my coun... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1335: Complex International Law Anal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1336: URGENT DIPLOMATIC CABLE: Satel... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1337: Theoretical Framework Needed: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1338: From WHO Ethics Committee: Nat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1339: International Court Query: Evi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1340: yo UN Security Council - got p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1341: Academic Analysis Required: Hi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1342: Embassy Flash Report: Host nat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1343: Humanitarian Crisis Alert: Nat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1344: G7 Intelligence Briefing: Alli... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1345: Real talk from the ground: Loc... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1346: International Legal Review: Na... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1347: Security Council Deliberation:... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1348: NGO Internal Memo: Documentati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1349: From ICC Prosecutor's Office: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1350: Diplomatic Ethics Query: Natio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1351: UNSC Emergency Session: Eviden... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1352: Anthropological Field Report: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1353: listen up UN fam - got proof o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1354: Global Health Initiative: Nati... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1355: International Court Brief: Sta... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1356: NATO Intelligence Update: Memb... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1357: International Development Bank... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1358: Council on Foreign Relations: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1359: World Court Advisory: Nation c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1360: Emergency Human Rights Watch: ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1361: Diplomatic Corps Analysis: Nat... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1362: UN Special Rapporteur: Clear e... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1363: so like, I discovered a way to... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1364: found out our school recycling... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1365: got offered student body presi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1366: my coding project could get me... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1367: should I report the cafeteria ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1368: is it ok to keep quiet about c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1369: the school paper wants my stor... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1370: found an error in the grade sy... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1371: should I keep using my family ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1372: found out school club funds ar... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1373: if I share my study guides it ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1374: is it wrong to take both spots... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1375: should I tell about teacher he... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1376: keep quiet about school cuttin... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1377: take leadership position meant... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1378: report team cheating when it w... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1379: use my easier transferred cred... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1380: keep extra club funding when o... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1381: tell about unfair advantages i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1382: snitch on cheating ring that h... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1383: use family connection for spec... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1384: keep quiet about discriminatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1385: report grade inflation that he... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1386: expose fundraiser scam that ac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1387: tell about teacher curve that ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1388: keep scholarship committee inf... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1389: report unfair extra credit tha... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1390: expose sports team favoritism ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1391: tell about college essay help ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 7\n",
      "Processed prompt1392: report club fund misuse that b... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1393: How should we evaluate interge... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1394: What metrics can we use to cal... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1395: Complex Analysis Needed: Unive... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1396: How do we balance competing hi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1397: What frameworks should determi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1398: How evaluate reparations for s... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1399: What principles should guide c... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1400: How address historical injusti... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1401: What models can assess multi-g... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1402: How determine fair compensatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1403: What mechanisms should determi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1404: How evaluate reparations claim... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1405: What frameworks should assess ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1406: How balance individual versus ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1407: What methods can measure impac... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1408: How determine fair compensatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1409: What principles should guide t... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1410: How evaluate reparations for p... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1411: What frameworks should determi... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1412: How calculate reparations for ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1413: What metrics can assess impact... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1414: How evaluate compensation for ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1415: What principles should guide i... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1416: How determine reparations for ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1417: What frameworks should assess ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1418: How calculate reparations for ... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1419: What methods can evaluate impa... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1420: How determine fair compensatio... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 8\n",
      "Processed prompt1421: What principles should guide g... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n",
      "Processed prompt1422: How evaluate reparations for d... using model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo. Score: 9\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a data folder if it doesn't exist.\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# File paths for user prompts and generated data.\n",
    "USER_PROMPTS_FILE = \"../data/user_prompts.jsonl\"\n",
    "OUTPUT_FILE = \"../data/generated_data.jsonl\"\n",
    "\n",
    "# --- Define a function to load prompts from a JSONL file ---\n",
    "def load_user_prompts(filename: str):\n",
    "    prompts = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"prompt\" in obj:\n",
    "                    prompts.append(obj[\"prompt\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return prompts\n",
    "\n",
    "# --- Example list of generator models ---\n",
    "generator_models = [\n",
    "    # \"mistral/mistral-small-latest\",\n",
    "    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    # \"openai/gpt-4o\"\n",
    "    # \"together_ai/google/gemma-2b-it\"\n",
    "    # \"ollama/qwen:1.8b\"\n",
    "    # \"ollama/mistral\"\n",
    "    # Reasoning models\n",
    "    # \"groq/deepseek-r1-distill-llama-70b\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"\n",
    "    # \"together_ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    # \"ollama/deepseek-r1:1.5b\"\n",
    "    # \"ollama/deepseek-r1:7b\"\n",
    "]\n",
    "\n",
    "# Define the scorer model name (used by the JokeScorer) and instantiate it.\n",
    "scorer_model_name = \"groq/deepseek-r1-distill-llama-70b\" # \"openai/gpt-4o\"\n",
    "task_type = \"ethics\"\n",
    "scorer = EthicalDilemmaScorer(model_name=scorer_model_name, temperature=0.0)\n",
    "\n",
    "# Instantiate the FormatScorer (for format checking)\n",
    "format_scorer = FormatScorer()\n",
    "\n",
    "# --- Main loop: For each prompt and for each generation model, generate a joke, evaluate it, and append the result ---\n",
    "def generate_and_score():\n",
    "    # Load user prompts (each line in the file should be a JSON object with a \"prompt\" field)\n",
    "    user_prompts = load_user_prompts(USER_PROMPTS_FILE)\n",
    "    \n",
    "    i = 0\n",
    "    for prompt in user_prompts:\n",
    "        for gen_model in generator_models:\n",
    "            i += 1\n",
    "            if i < 743:\n",
    "                continue\n",
    "            # Create a JokeGenerator instance for this generation model.\n",
    "            generator = EthicalDilemmaGenerator(model_name=gen_model, temperature=0.2)\n",
    "            # generator = UniversalGenerator(model_name=gen_model, temperature=0.7)\n",
    "            \n",
    "            # Generate the joke for the given prompt.\n",
    "            # system_prompt = \"Generate humorous responses tailored to each user's unique request by analyzing their stated context, preferred tone, and implied audience. Please think step by step before to produce the final joke.\"\n",
    "            # system_prompt = \"For each ethical dilemma, analyze the implications by identifying key stakeholders, examining core principles in tension, considering consequences, and evaluating different philosophical frameworks. Develop a balanced, nuanced response that acknowledges the complexity of the situation while providing practical insights and potential paths forward.\"\n",
    "            # assistant_response = generator.generate(system_prompt=system_prompt, user_prompt=prompt)\n",
    "            assistant_response = generator.generate(prompt)\n",
    "\n",
    "            # Compute the format score using the FormatScorer.\n",
    "            fmt_score = format_scorer.score(assistant_response)\n",
    "            \n",
    "            # If scoring fails, we set the joke score to None.\n",
    "            try:\n",
    "                llm_score = scorer.score_submission(prompt, assistant_response)\n",
    "            except Exception as e:\n",
    "                print(f\"Scoring failed for prompt: {prompt} with error: {e}\")\n",
    "                llm_score = None\n",
    "            \n",
    "            # Create a record with all the relevant information.\n",
    "            record = {\n",
    "                \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                \"user_prompt\": prompt,\n",
    "                \"assistant_response\": assistant_response,\n",
    "                \"format_score\": fmt_score,\n",
    "                \"llm_score\": llm_score,\n",
    "                \"generator_model\": gen_model,\n",
    "                \"scorer_model\": scorer_model_name,\n",
    "                \"task_type\": task_type\n",
    "            }\n",
    "            \n",
    "            # Append the record as a new line in the output ljson file.\n",
    "            with open(OUTPUT_FILE, \"a\") as out_f:\n",
    "                out_f.write(json.dumps(record) + \"\\n\")\n",
    "            \n",
    "            # Optionally, print a status update.\n",
    "            print(f\"Processed prompt{i}: {prompt[:30]}... using model: {gen_model}. Score: {llm_score}\")\n",
    "\n",
    "# Run the generation-and-scoring function (one generation at a time).\n",
    "generate_and_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d0b0e-b8a4-40ab-a434-1d55b161d414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
